<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Qubit Quants]]></title><description><![CDATA[Welcome to Qubit Quants. The blogging platform to elevate your algorithmic and quantitative trading endeavours.]]></description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Qubit Quants</title><link>http://localhost:2368/</link></image><generator>Ghost 5.24</generator><lastBuildDate>Tue, 18 Apr 2023 14:09:07 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[VectorBT Pro - Custom Simulator 3: CandleStick Strategy + StopLoss + TakeProfit + Partial Profits]]></title><description><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing The Dependencies</h2>
<pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_</code></pre>]]></description><link>http://localhost:2368/customsim_3/</link><guid isPermaLink="false">643e998528c00f113e763a69</guid><category><![CDATA[algorithmic trading]]></category><category><![CDATA[python]]></category><category><![CDATA[vectorBT]]></category><category><![CDATA[customsimulator]]></category><dc:creator><![CDATA[Bhavin Siddhapura]]></dc:creator><pubDate>Tue, 18 Apr 2023 13:29:37 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1530893609608-32a9af3aa95c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEzfHxsYXB0b3B8ZW58MHx8fHwxNjgxODIxMTg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing The Dependencies</h2>
<pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_nb, enums as pf_enums
import plotly.io as pio
from numba import njit
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="strategy-rules-%F0%9F%93%90">Strategy Rules &#x1F4D0;</h2>
<blockquote>
<img src="https://images.unsplash.com/photo-1530893609608-32a9af3aa95c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEzfHxsYXB0b3B8ZW58MHx8fHwxNjgxODIxMTg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Custom Simulator 3: CandleStick Strategy + StopLoss + TakeProfit + Partial Profits"><p>In addition to the previous rules , the only additional rule here is to close 50 % of the position when the price hits the first take profit <code>tp1</code> (RRR of 1)  moving the stop loss to breakeven (<code>entry_price</code>)</p>
<hr>
<p>The tracking dictionary here does exactly what it says , it will keep track of  the <code>entry_price</code> , <code>stop_loss</code> , <code>tp1</code> (take profit 1) , <code>tp2</code> (take profit 2) for both <code>long</code> &#x1F7E9; and <code>short</code> &#x1F7E5; positions.</p>
<hr>
<p>&#x1F40C; Indexing into a dictionary to update / retrieve values that will subsequently be used in the trading logic will be undoubtly be computationally slow however it is very easy to understand.</p>
<hr>
<p>&#x26A1;The dictionary variables can be unpacked and be used independently to increase the speed.</p>
<hr>
</blockquote>
<pre><code class="language-python">tracking_dict = {&apos;long&apos; : {&apos;entry_price&apos;: None,&apos;stop_loss&apos;: None,&apos;tp1&apos;: None,&apos;tp2&apos;: None},
                &apos;short&apos;: {&apos;entry_price&apos;: None,&apos;stop_loss&apos;: None,&apos;tp1&apos;: None,&apos;tp2&apos;: None}}
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<p>When <code>tp1</code> (first take profit) the tracking dictionary (<code>tracking_dict</code>) must be updated to reflect this change (set to <code>None</code>).</p>
<hr>
<p>In conjunction to this when <code>tp1</code> is hit the <code>stop_loss</code> should be moved to breakeven (<code>stop_loss</code> price is set to <code>entry_price</code>)</p>
<hr>
<p>When the <code>stop_loss</code> or <code>tp2</code> is hit every variable in the <code>tracking_dict</code> is set to <code>None</code> to reflect that we are no longer in that position.</p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="custom-simulator">Custom Simulator</h2>
<pre><code class="language-python">def custom_simulator_candlestick_partial_profs(open_ , high_ , low_ , close_ , IsBullArray, init_cash = 10000):
    
    order_records = np.empty((2663,1), dtype = vbt.pf_enums.order_dt)
    order_counts = np.full(1,0, dtype = np.int_)
    
    
    tracking_dict = {&apos;long&apos; : {&apos;entry_price&apos;: None,&apos;stop_loss&apos;: None,&apos;tp1&apos;: None,&apos;tp2&apos;: None},
                     &apos;short&apos;: {&apos;entry_price&apos;: None,&apos;stop_loss&apos;: None,&apos;tp1&apos;: None,&apos;tp2&apos;: None}}

    exec_state = vbt.pf_enums.ExecState(
                        cash = float(init_cash),
                        position = 0.0,
                        debt = 0.0,
                        locked_cash = 0.0,
                        free_cash = float(init_cash),
                        val_price = np.nan,
                        value = np.nan)
     
    for i in range(len(close_)):
        price_area = vbt.pf_enums.PriceArea(open = open_[i], 
                                            high = high_[i], 
                                            low = low_[i], 
                                            close = close_[i])
        
        value_price = price_area.close
        value = exec_state.cash + (exec_state.position * value_price)
        
        current_price = price_area.close
        
        exec_state = vbt.pf_enums.ExecState(
                                            cash = exec_state.cash,
                                            position = exec_state.position,
                                            debt = exec_state.debt,
                                            locked_cash = exec_state.locked_cash,
                                            free_cash = exec_state.free_cash,
                                            val_price = value_price,
                                            value = value)
        
        if IsBullArray[i] and exec_state.position == 0:
            long_stop_loss = price_area.low #Long Stop loss
            long_entry_price = price_area.close #Long Entry Price
            long_tp1 = price_area.close + ( 1 * (price_area.close - long_stop_loss) ) #1RRR
            long_tp2 = price_area.close + ( 2 * (price_area.close - long_stop_loss) ) #2RRR
            
            tracking_dict[&apos;long&apos;][&apos;entry_price&apos;] = long_entry_price
            tracking_dict[&apos;long&apos;][&apos;stop_loss&apos;] = long_stop_loss
            tracking_dict[&apos;long&apos;][&apos;tp1&apos;] = long_tp1
            tracking_dict[&apos;long&apos;][&apos;tp2&apos;] = long_tp2
            
            
            
            order_result , exec_state = enter_position(
                                                        execution_state_ = exec_state,
                                                        price_area_ = price_area,
                                                        percent_risk_ = 1,
                                                        group_ = 0, column_= 0, bar_ = i,
                                                        direction = &apos;Buy&apos;,
                                                        order_records_= order_records,
                                                        order_counts_ = order_counts)
            
        elif not IsBullArray[i] and exec_state.position == 0:
            short_stop_loss = price_area.high #Short Stop Loss
            short_entry_price = price_area.close #Short Entry Price
            short_tp1 = price_area.close - ( 1 * (price_area.high - short_stop_loss) ) #1RRR
            short_tp2 = price_area.close - ( 2 * (price_area.high - short_stop_loss) ) #2RRR
            
            tracking_dict[&apos;short&apos;][&apos;entry_price&apos;] = short_entry_price
            tracking_dict[&apos;short&apos;][&apos;stop_loss&apos;] = short_stop_loss
            tracking_dict[&apos;short&apos;][&apos;tp1&apos;] = short_tp1
            tracking_dict[&apos;short&apos;][&apos;tp2&apos;] = short_tp2
            
            order_result , exec_state = enter_position(
                                                        execution_state_ = exec_state,
                                                        price_area_ = price_area,
                                                        percent_risk_ = 1,
                                                        group_ = 0, column_= 0, bar_ = i,
                                                        direction = &apos;Sell&apos;,
                                                        order_records_= order_records,
                                                        order_counts_ = order_counts)
        
        
        
        elif not IsBullArray[i] and exec_state.position &gt; 0:
            
            tracking_dict[&apos;long&apos;][&apos;entry_price&apos;] = None
            tracking_dict[&apos;long&apos;][&apos;stop_loss&apos;] = None
            tracking_dict[&apos;long&apos;][&apos;tp1&apos;] = None
            tracking_dict[&apos;long&apos;][&apos;tp2&apos;] = None
            
            order_result , exec_state = close_full_position(
                                                            execution_state_ = exec_state,
                                                            price_area_ = price_area,
                                                            group_ = 0, column_= 0, bar_ = i,
                                                            order_records_= order_records,
                                                            order_counts_ = order_counts)
            
            
        elif IsBullArray[i] and exec_state.position &lt; 0:
            
            tracking_dict[&apos;short&apos;][&apos;entry_price&apos;] = None
            tracking_dict[&apos;short&apos;][&apos;stop_loss&apos;] = None
            tracking_dict[&apos;short&apos;][&apos;tp1&apos;] = None
            tracking_dict[&apos;short&apos;][&apos;tp2&apos;] = None
            
            order_result , exec_state = close_full_position(
                                                            execution_state_ = exec_state,
                                                            price_area_ = price_area,
                                                            group_ = 0, column_= 0, bar_ = i,
                                                            order_records_= order_records,
                                                            order_counts_ = order_counts)
  
        else:
            
            if exec_state.position &gt; 0: #In Long 
                entry_price = tracking_dict[&apos;long&apos;][&apos;entry_price&apos;]
                
                if (price_area.low &lt;= long_stop_loss):
                    #Long Stop Loss Has Been Hit
                    tracking_dict[&apos;long&apos;][&apos;entry_price&apos;] = None
                    tracking_dict[&apos;long&apos;][&apos;stop_loss&apos;] = None
                    tracking_dict[&apos;long&apos;][&apos;tp1&apos;] = None
                    tracking_dict[&apos;long&apos;][&apos;tp2&apos;] = None
                    
                    
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                    
                    
                    
                
                elif (price_area.high &gt;= tracking_dict[&apos;long&apos;][&apos;tp1&apos;]):
                    # First Long Take Profit Has Been Hit
                    # Move The Stop Loss To Break Even (Entry Price) &amp; Close 50% of The Position
                    tracking_dict[&apos;long&apos;][&apos;stop_loss&apos;] = entry_price #SL Moved To Entry Price (BreakEven)
                    tracking_dict[&apos;tp1&apos;] = None #take profit 1 has been hit
                    
                    order_result, exec_state = close_partial_pos(
                                                        execution_state_ = exec_state,
                                                        price_area_ = price_area,
                                                        closing_percent = 50, 
                                                        group_ = 0 , column_ = 0, bar_ = None,
                                                        update_value_ = False, order_records_ = None, 
                                                        order_counts_ = None, log_records_ = None,
                                                        log_counts_ = None)
                    
                
                
                elif (price_area.high &gt;= tracking_dict[&apos;long&apos;][&apos;tp2&apos;]):
                    # Second Take Profit Has Been Hit
                    tracking_dict[&apos;long&apos;][&apos;stop_loss&apos;] = None
                    tracking_dict[&apos;long&apos;][&apos;tp2&apos;] = None
                    
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                
                else:
                    continue
            
            elif exec_state.position &lt; 0:
                
                entry_price = tracking_dict[&apos;short&apos;][&apos;entry_price&apos;]
                
                if (price_area.high &gt;= tracking_dict[&apos;short&apos;][&apos;stop_loss&apos;]):
                    #Short Stop Loss Has Been Hit
                    tracking_dict[&apos;short&apos;][&apos;entry_price&apos;] = None
                    tracking_dict[&apos;short&apos;][&apos;stop_loss&apos;] = None
                    tracking_dict[&apos;short&apos;][&apos;tp1&apos;] = None
                    tracking_dict[&apos;short&apos;][&apos;tp2&apos;] = None
                    
                    
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                
                elif (price_area.low &lt;= tracking_dict[&apos;short&apos;][&apos;tp1&apos;]):
                    # Frist Take Profit Has Been Hit
                    
                    tracking_dict[&apos;stop_loss&apos;] = entry_price #SL Moved To Entry Price (BreakEven)
                    tracking_dict[&apos;tp1&apos;] = None
                    
                    order_result, exec_state = close_partial_pos(
                                                            execution_state_ = exec_state,
                                                            price_area_ = price_area,
                                                            closing_percent = 50, 
                                                            group_ = 0 , column_ = 0, bar_ = None,
                                                            update_value_ = False, order_records_ = None, 
                                                            order_counts_ = None, log_records_ = None,
                                                            log_counts_ = None)
                
                elif (price_area.low &lt;= tracking_dict[&apos;short&apos;][&apos;tp2&apos;]):
                    # Second Take Profit Has Been Hit
                    tracking_dict[&apos;short&apos;][&apos;entry_price&apos;] = None
                    tracking_dict[&apos;short&apos;][&apos;stop_loss&apos;] = None
                    tracking_dict[&apos;short&apos;][&apos;tp1&apos;] = None
                    tracking_dict[&apos;short&apos;][&apos;tp2&apos;] = None
                    
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                
                else:
                    continue
        
        
        
                
    return vbt.nb.repartition_nb(order_records, order_counts)         
                
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="key-points-summary-%F0%9F%92%A1">Key Points / Summary &#x1F4A1;</h2>
<blockquote>
<hr>
<p>As you can see there is not a whole lot of differences when looking at partial profits and moving stop loss to breakeven.</p>
<hr>
<p>These are just simple examples to demonstrate how one can do these things that are quite common amongst most strategies.</p>
<hr>
<p>You can use this code as a point of reference and get creative &#x1F3A8; when you are coding your own strategies &#x26A1;</p>
</blockquote>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Custom Simulator 2: Candlestick Strategy + StopLoss + TakeProfit]]></title><description><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing the Dependencies</h2>
<pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_</code></pre>]]></description><link>http://localhost:2368/customsim_2/</link><guid isPermaLink="false">643e928d28c00f113e7639d7</guid><category><![CDATA[algorithmic trading]]></category><category><![CDATA[customsimulator]]></category><category><![CDATA[python]]></category><category><![CDATA[backtesting]]></category><category><![CDATA[vectorBT]]></category><dc:creator><![CDATA[Bhavin Siddhapura]]></dc:creator><pubDate>Tue, 18 Apr 2023 13:18:45 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1530893609608-32a9af3aa95c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEzfHxsYXB0b3B8ZW58MHx8fHwxNjgxODIxMTg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing the Dependencies</h2>
<pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_nb, enums as pf_enums
import plotly.io as pio
from numba import njit
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="strategy-rules-%F0%9F%93%90">Strategy Rules &#x1F4D0;</h2>
<blockquote>
<img src="https://images.unsplash.com/photo-1530893609608-32a9af3aa95c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEzfHxsYXB0b3B8ZW58MHx8fHwxNjgxODIxMTg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Custom Simulator 2: Candlestick Strategy + StopLoss + TakeProfit"><p>We will build upon the previous strategy</p>
<p>Stop Loss Below / Above The Entry Candle</p>
<p>Take Profit Level at a RRR (Risk and Reward Ratio of 2)</p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="long-%F0%9F%9F%A9-stop-loss-%E2%AC%87-and-take-profit-%E2%AC%86">Long &#x1F7E9; Stop Loss &#x2B07; and Take Profit &#x2B06;</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<p>The <code>stop loss</code> for the <code>long</code> position is placed below the <code>low</code> of the   candle</p>
</blockquote>
<pre><code class="language-python">    long_stop_loss = price_area.low
</code></pre>
<blockquote>
<p>The <code>take profit</code> for the <code>long</code> position is placed at a RRR of 2.</p>
<p>We find the difference between the <code>close</code> and <code>stoploss</code> prices.</p>
<p>Multiply it by 2 and then add the the <code>closing</code> price.</p>
<p>This gives us the price for the <code>take profit</code> level corresponding to a     RRR of 2.</p>
</blockquote>
<pre><code class="language-python">long_take_profit = price_area.close + ( 2 * (price_area.close - long_stop_loss) )
</code></pre>
<hr>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="short-%F0%9F%9F%A5-stop-loss-%E2%AC%86-and-take-profit-%E2%AC%87">Short &#x1F7E5; Stop Loss &#x2B06; and Take Profit &#x2B07;</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<p>The <code>stop loss</code> for the <code>short</code> position is above the <code>high</code> of the candle.</p>
</blockquote>
<pre><code class="language-python">short_stop_loss = price_area.high
</code></pre>
<blockquote>
<p>The <code>take profit</code> for the <code>short</code> position is placed at a RRR of 2.</p>
<p>Similarly the <code>short take profit</code> is placed at a RRR of 2 below the closing price.</p>
<p>The calculation can be seen below.</p>
</blockquote>
<pre><code class="language-python">short_take_profit = price_area.close - ( 2 * (price_area.high - short_stop_loss) )
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="detecting-when-stop-loss-and-take-profit-is-hit">Detecting When Stop Loss and Take Profit Is Hit</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><em>Long</em> &#x1F7E9;</p>
<blockquote>
<p>The Long  <code>stop loss</code> is hit when the <code>low</code> of the current candle is less than the stop loss price.</p>
<blockquote>
<p><code>price_area.low &lt;= long_stop_loss</code></p>
</blockquote>
<hr>
<p>The Long <code>take profit</code> is hit &#x1F3AF; when the <code>high</code> of the current candle is greater than the <code>take profit</code> price.</p>
<blockquote>
<p><code>price_area.high &gt;= long_take_profit</code></p>
</blockquote>
<hr>
</blockquote>
<p><em>Short</em> &#x1F7E5;</p>
<blockquote>
<p>The Short <code>stop loss</code> is hit when the <code>high</code> of the current candle is greater than the stop loss price</p>
<blockquote>
<p><code>price_area.high &gt;= short_stop_loss</code></p>
</blockquote>
<hr>
<p>The Short <code>take profit</code> is hit when the <code>low</code> of the current candle is less than the <code>take profit</code> price.</p>
<blockquote>
<p><code>price_area.low &lt;= short_take_profit</code></p>
</blockquote>
<hr>
<p>In the code below you can see the implmentation of the <code>stop loss</code> and <code>take profit</code> as part of the entire strategy.</p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="custom-simulator">Custom Simulator</h2>
<pre><code class="language-python">def custom_simulator_candlestick_sl_tp(open_ , high_ , low_ , close_ , IsBullArray, init_cash = 10000):

    order_records = np.empty((2663,1), dtype = vbt.pf_enums.order_dt)
    order_counts = np.full(1, 0, dtype=np.int_)

    long_stop_loss = None
    long_take_profit = None
    
    short_stop_loss = None
    short_take_profit = None
    
    exec_state = vbt.pf_enums.ExecState(
                        cash = float(init_cash),
                        position = 0.0,
                        debt = 0.0,
                        locked_cash = 0.0,
                        free_cash = float(init_cash),
                        val_price = np.nan,
                        value = np.nan)
    
    
    
    for i in range(len(close_)):
        price_area = vbt.pf_enums.PriceArea(open = open_[i], 
                                            high = high_[i], 
                                            low = low_[i], 
                                            close = close_[i])
        
        value_price = price_area.close
        value = exec_state.cash + (exec_state.position * value_price)
        
        exec_state = vbt.pf_enums.ExecState(
                                            cash = exec_state.cash,
                                            position = exec_state.position,
                                            debt = exec_state.debt,
                                            locked_cash = exec_state.locked_cash,
                                            free_cash = exec_state.free_cash,
                                            val_price = value_price,
                                            value = value)


        if IsBullArray[i] and exec_state.position == 0:
            long_stop_loss = price_area.low #Stop Loss Placed Below The Low Of The Candle
            long_take_profit = price_area.close + ( 2 * (price_area.close - long_stop_loss) ) 
            
            order_result , exec_state = enter_position(
                                                        execution_state_ = exec_state,
                                                        price_area_ = price_area,
                                                        percent_risk_ = 1,
                                                        group_ = 0, column_= 0, bar_ = i,
                                                        direction = &apos;Buy&apos;,
                                                        order_records_= order_records,
                                                        order_counts_ = order_counts)

        elif not IsBullArray[i] and exec_state.position == 0:
            
            short_stop_loss = price_area.high #Stop Loss Placed Above The High Of The Candle
            short_take_profit = price_area.close - ( 2 * (price_area.high - short_stop_loss) ) #Stop Loss At 2RRR
            
            order_result , exec_state = enter_position(
                                                        execution_state_ = exec_state,
                                                        price_area_ = price_area,
                                                        percent_risk_ = 1,
                                                        group_ = 0, column_= 0, bar_ = i,
                                                        direction = &apos;Sell&apos;,
                                                        order_records_= order_records,
                                                        order_counts_ = order_counts)

        elif exec_state.position &gt; 0 and not IsBullArray[i]:
            #Closing Long Position
            order_result , exec_state = close_full_position(
                                                            execution_state_ = exec_state,
                                                            price_area_ = price_area,
                                                            group_ = 0, column_= 0, bar_ = i,
                                                            order_records_ = order_records,
                                                            order_counts_  = order_counts)  
            
            
            
        
        elif exec_state.position &lt; 0 and IsBullArray[i]:
            #Closing Short Position
            order_result , exec_state = close_full_position(
                                                            execution_state_ = exec_state,
                                                            price_area_ = price_area,
                                                            group_ = 0, column_= 0, bar_ = i,
                                                            order_records_= order_records,
                                                            order_counts_ = order_counts)
        
        else:
            
            if exec_state.position &gt; 0: #In Long
                if (price_area.low &lt;= long_stop_loss): 
                    #long stop loss has been hit
                    #Code To Close The Long Position
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                    
                    
                    long_stop_loss = None
                    long_take_profit = None
                
                elif (price_area.high &gt;= long_take_profit): 
                    #Long Take Profit Has Been Hit
                    #Code To Close Long Position Goes Here
                    
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                    
                    
                    long_stop_loss = None
                    long_take_profit = None
                
                else:
                    continue
            
            elif exec_state.position &lt; 0: #In Short
                if (price_area.high &gt;= short_stop_loss): 
                    #Short Stop Loss Has Been Hit
                    #Code That Closes Out The Short Position Goes Here
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
          
                    short_stop_loss = None
                    short_take_profit = None
                
                elif (price_area.low &lt;= short_take_profit): 
                    #Short Take Profit Has Been Hit
                    #Code That Closes Out The Short Position Goes Here
                    order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
                    
                    short_stop_loss = None
                    short_take_profit = None
                
                else:
                    continue
        
    
    return vbt.nb.repartition_nb(order_records, order_counts)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="key-points-summary-%F0%9F%92%A1">Key Points / Summary &#x1F4A1;</h2>
<ul>
<li>
<p>When the <code>stop loss</code> / <code>take profit</code> is hit , both variables have to be set to <code>None</code>.</p>
</li>
<li>
<p>When we are in a position we must check at each bar (candle) whether the stop loss / take profit has been hit and then deploy the approporatiate function to fulfill the logic of our strategy.</p>
</li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Custom Simulator 1: Basic Candlestick Strategy]]></title><description><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing the Dependencies</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_</code></pre>]]></description><link>http://localhost:2368/customsim_1/</link><guid isPermaLink="false">643e8de328c00f113e76395b</guid><category><![CDATA[algorithmic trading]]></category><category><![CDATA[backtesting]]></category><category><![CDATA[customsimulator]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Bhavin Siddhapura]]></dc:creator><pubDate>Tue, 18 Apr 2023 12:51:14 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1530893609608-32a9af3aa95c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEzfHxsYXB0b3B8ZW58MHx8fHwxNjgxODIxMTg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing the Dependencies</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_nb, enums as pf_enums
import plotly.io as pio
from numba import njit
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="strategy-rules-%F0%9F%93%8F">Strategy Rules &#x1F4CF;</h2>
<img src="https://images.unsplash.com/photo-1530893609608-32a9af3aa95c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEzfHxsYXB0b3B8ZW58MHx8fHwxNjgxODIxMTg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Custom Simulator 1: Basic Candlestick Strategy"><p>In this strategy we will go <code>long</code> &#x1F7E9; on a Bullish Candle and go <code>short</code> &#x1F7E5; on a Bearish Candle.</p>
<p>If already in a long position and a bearish candle is present the long position should be closed and vice versa.</p>
<p>Otherwise the position should be held.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="obtaining-the-data">Obtaining The Data</h2>
<pre><code class="language-python">data = vbt.YFData.fetch(&quot;BTC-USD&quot;, end=&quot;2022-01-01&quot;)
Open = data.get(&quot;Open&quot;).to_numpy()
High = data.get(&quot;High&quot;).to_numpy()
Low = data.get(&quot;Low&quot;).to_numpy()
Close = data.get(&quot;Close&quot;).to_numpy()
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="coding-the-rules">Coding The Rules</h2>
<blockquote>
<p>A Bullish Candle &#x1F7E9; is where the <code>close</code> is greater the the <code>open</code> (The price increased)</p>
</blockquote>
<blockquote>
<p><code>df[&apos;IsBull&apos;] = df[&apos;Close&apos;] &gt; df[&apos;Open&apos;]</code></p>
</blockquote>
<blockquote>
<p>Converting the above piece of code to a <code>NumPY Array</code></p>
</blockquote>
<blockquote>
<p><code>IsBull = df[&apos;IsBull&apos;].to_numpy()</code></p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="understanding-the-custom-simulator">Understanding the Custom Simulator</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<p>Bullish Candle &#x1F7E9; &amp; Not In A Position &#x26AA;</p>
<p><code>IsBullArray[i] and exec_state.position == 0</code></p>
<hr>
<p>Bearish Candle &#x1F7E5; &amp; Not In A Position &#x26AA;</p>
<p><code>not IsBullArray[i] and exec_state.position == 0</code></p>
<hr>
<p>Bullish Candle &#x1F7E9; &amp; In A Short Position &#x1F534;</p>
<p><code>IsBullArray[i] and exec_state.position &lt; 0</code></p>
<hr>
<p>Bearish Candle &#x1F7E5; &amp; In A Long Position &#x1F7E2;</p>
<p><code>not IsBullArray[i] and exec_state.position &gt; 0</code></p>
<hr>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="custom-simulator-code">Custom Simulator Code</h2>
<pre><code class="language-python">def custom_simulator(open_, high_ , low_ , close_ , IsBullArray,init_cash = 10000):
     
    order_records = np.empty((2663,1), dtype = vbt.pf_enums.order_dt)
    order_counts = np.full(1, 0, dtype=np.int_)

    exec_state = vbt.pf_enums.ExecState(
                        cash = float(init_cash),
                        position = 0.0,
                        debt = 0.0,
                        locked_cash = 0.0,
                        free_cash = float(init_cash),
                        val_price = np.nan,
                        value = np.nan)
    
    
    for i in range(len(close_)):
        
        price_area = vbt.pf_enums.PriceArea(open  = open_[i],
                                            high = high_[i], 
                                            low = low_[i], 
                                            close = close_[i])
        
        value_price = price_area.close
        value = exec_state.cash + (exec_state.position * value_price)
        
        exec_state = vbt.pf_enums.ExecState(
                                cash = exec_state.cash,
                                position = exec_state.position,
                                debt = exec_state.debt,
                                locked_cash = exec_state.locked_cash,
                                free_cash = exec_state.free_cash,
                                val_price = value_price,
                                value = value)
        
        if IsBullArray[i] and exec_state.position == 0:
            #CODE THAT WILL ENTER LONG POSITION

            order_result , exec_state = enter_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                percent_risk_ = 1,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                direction = &apos;Buy&apos;,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)

        elif not IsBullArray[i] and exec_state.position == 0:
            #CODE THAT WILL ENTER SHORT POSITION
            order_result , exec_state = enter_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                percent_risk_ = 1,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                direction = &apos;Sell&apos;,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)
               

        elif IsBullArray[i] and exec_state.position &lt; 0:
            #CODE THAT WILL CLOSE THE SHORT POSITION HERE
            order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_ = order_records,
                                                                order_counts_  = order_counts)    
            

        elif not IsBullArray[i] and exec_state.position &gt;0:
            order_result , exec_state = close_full_position(
                                                                execution_state_ = exec_state,
                                                                price_area_ = price_area,
                                                                group_ = 0, column_= 0, bar_ = i,
                                                                order_records_= order_records,
                                                                order_counts_ = order_counts)    
        else:
            continue
        
                
    return vbt.nb.repartition_nb(order_records, order_counts)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="running-the-custom-simulator">Running The Custom Simulator</h2>
<pre><code class="language-python">custom_simulator(open_ = Open, 
                 high_ = High, 
                 low_  = Low, 
                 close_  = Close, 
                 IsBullArray = IsBull,
                 init_cash = 100000)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="output-of-custom-simulation-backtest">Output of Custom Simulation / Backtest</h3>
<pre><code class="language-python">array([(   0, 0,    0, 2.18658566,   457.33401489, 0., 1),
       (   1, 0,    3, 2.18658566,   408.9039917 , 0., 0),
       (   2, 0,    4, 2.51004568,   398.8210144 , 0., 1), ...,
       (1818, 0, 2659, 0.0218352 , 47588.85546875, 0., 1),
       (1819, 0, 2661, 0.0218352 , 47178.125     , 0., 0),
       (1820, 0, 2662, 0.02244184, 46306.4453125 , 0., 1)],
      dtype={&apos;names&apos;:[&apos;id&apos;,&apos;col&apos;,&apos;idx&apos;,&apos;size&apos;,&apos;price&apos;,&apos;fees&apos;,&apos;side&apos;], &apos;formats&apos;:[&apos;&lt;i4&apos;,&apos;&lt;i4&apos;,&apos;&lt;i4&apos;,&apos;&lt;f8&apos;,&apos;&lt;f8&apos;,&apos;&lt;f8&apos;,&apos;&lt;i4&apos;], &apos;offsets&apos;:[0,4,8,16,24,32,40], &apos;itemsize&apos;:48, &apos;aligned&apos;:True})

</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="summary-key-points-%F0%9F%92%A1">Summary / Key Points &#x1F4A1;</h3>
<blockquote>
<hr>
<p>The custom simulator is relatively simple to understand , all we do is iterate through the <code>length</code> of the <code>closing_prices</code>.</p>
<hr>
<p>Upon each iteration we update the <code>execution_state</code></p>
<hr>
<p>We then <code>index</code> into the <code>IsBullArray</code> along with checking the value of the <code>exec_state.position</code> as shown above to match the logic of our strategy.</p>
<hr>
<p>After we use our prebuilt functions <code>enter_position</code> , <code>close_position</code> to enter and close positions as per the strategy has defined.</p>
</blockquote>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Custom Simulator 0 : Main Functions]]></title><description><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing The Dependencies</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_</code></pre>]]></description><link>http://localhost:2368/customsim_0/</link><guid isPermaLink="false">643d6375de286011d16d62ed</guid><category><![CDATA[algorithmic trading]]></category><category><![CDATA[vectorBT]]></category><category><![CDATA[backtesting]]></category><category><![CDATA[simulator]]></category><dc:creator><![CDATA[Bhavin Siddhapura]]></dc:creator><pubDate>Mon, 17 Apr 2023 15:41:52 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1661956602868-6ae368943878?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wxfDF8YWxsfDZ8fHx8fHwyfHwxNjgxNzQzNzcz&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="importing-the-dependencies">Importing The Dependencies</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">import vectorbtpro as vbt
import numpy as np
import pandas as pd
from numba import njit
import talib
import datetime as dt
import time
from collections import namedtuple
import itertools
import math
from vectorbtpro.records.nb import col_map_nb
from vectorbtpro.portfolio import nb as pf_nb, enums as pf_enums
import plotly.io as pio
from numba import njit
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="order-records-order-counts">Order Records , Order Counts</h2>
<blockquote>
<img src="https://images.unsplash.com/photo-1661956602868-6ae368943878?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wxfDF8YWxsfDZ8fHx8fHwyfHwxNjgxNzQzNzcz&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Custom Simulator 0 : Main Functions"><p>The <code>order records</code> keep track of the details of each trade executed by a trading strategy.</p>
<p>The purpose of order records is to provide traders with a complete record of  all trades executed by the strategy, including the entry and exit prices ,order type , order size and other relevant details.</p>
<p>The <code>order counts</code> are the number of trades executed by a trading strategy over a certain period of time. They can be analysed to gain insights into trading activity and use this information to adjust their approach.</p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="process-order">Process Order</h2>
<blockquote>
<p>The main purpose of using <code>vbt.pf_nb.process_order_nb</code> in the functions that will be introduced below is that it takes in the <code>order_records</code> and <code>order_counts</code> without having to manually construct them after an <code>Order</code> has been submitted.</p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="enter-position"><code>Enter Position</code></h2>
<p>The <code>enter_position</code> will enter either a <code>Buy</code> or <code>Sell</code> position depending on the logic and overall structure of your strategy.</p>
<p>Its primary purpose is to create the <code>Order</code> corresponding to the <code>percentage_risk</code> and the <code>direction</code> that has been specified.</p>
<p>It takes in a multitude of different arguments the main ones being ;</p>
<p><code>execution_state_</code></p>
<blockquote>
<p>The <code>execution_state</code> feature keeps track of the<br>
current position of a trading strategy (<code>long</code>, <code>short</code>, or <code>neutral</code>) at each time  step in a trading simulation.</p>
</blockquote>
<p><code>price_area_</code></p>
<blockquote>
<p>The <code>price_area_</code> feature can be used when constructing an order to help determine the entry and exit points for a trade since its compromised of the <code>open</code> , <code>high</code> , <code>low</code> and <code>closing</code> prices at the point in time the trade was taken.</p>
</blockquote>
<p><code>percent_risk_</code></p>
<blockquote>
<p>The <code>percent_risk_</code> % will allow us to specify how much to risk on each trade.</p>
</blockquote>
<p><code>direction</code></p>
<blockquote>
<p>This is simply the direction of the trade that one wants to take whether that be <code>Buy</code> &#x1F7E9;  or <code>Sell</code> &#x1F7E5;.</p>
</blockquote>
<p><code>group_ , col_ , bar_</code></p>
<blockquote>
<p>These refer to the group , column and the current bar number of the iteration of the close prices that we are on.</p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">@njit(nogil = True)
def enter_position(execution_state_,
                    price_area_,
                    percent_risk_ = 1, 
                    group_ = 0 , column = 0, bar_ = None,
                    direction = &quot;Buy&quot;,
                    update_value_ = False, order_records_ = None, 
                    order_counts_ = None, log_records_ = None,
                    log_counts_ = None):
    
    
    if direction == &quot;Buy&quot;:
        direction_to_take = vbt.pf_enums.Direction.LongOnly
    else:
        direction_to_take = vbt.pf_enums.Direction.ShortOnly
        
    Order = pf_nb.order_nb(size = percent_risk_, 
                           size_type = vbt.pf_enums.SizeType.ValuePercent100,
                           direction = direction_to_take,
                           price = execution_state_.val_price
                           )

    
    order_result , new_execution_state = vbt.pf_nb.process_order_nb(
                                                        group = group_ ,col = column , i = bar_,
                                                        exec_state = execution_state_,
                                                        order = Order,
                                                        price_area = price_area_,
                                                        update_value = update_value_,
                                                        order_records = order_records_,
                                                        order_counts = order_counts_,
                                                        log_records = log_records_,
                                                        log_counts = log_counts_)
    
    

    
                                                                
    return order_result, new_execution_state
    
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="closefullposition"><code>close_full_position</code></h2>
<p>There are minor differences between each function in the <code>close_full_position</code> the size is specified to be <code>-np.inf</code> (Infinite size) and the direction is determined via the passed execution_state.</p>
<p>If the <code>execution_state.position</code> is <code>&gt;0</code> (greater than zero) it indicates that we are invested in a a Buy (Long position) and if it is <code>&lt;0</code> (Less than zero) then we are invested in a Sell (Short Position).</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="closepartialpos"><code>close_partial_pos</code></h2>
<blockquote>
<p>The <code>close_partial_pos</code> intends to close the position only partially.</p>
<p>This is useful when taking partial profits which is the basis of many algorithmic trading strategies.</p>
<p>The <code>Size</code> when constructing the <code>Order</code> is set to be <code>-closing_percent</code> such that if <code>50</code> is specified only 50% of that particular position will be closed.</p>
</blockquote>
<pre><code class="language-python">@njit(nogil = True)
def close_partial_pos(execution_state_,
                      price_area_,
                      closing_percent = 50, 
                      group_ = 0 , column = 0, bar_ = None,
                      update_value_ = False, order_records_ = None, 
                      order_counts_ = None, log_records_ = None,
                      log_counts_ = None):
    
    
    if execution_state.position &gt; 0 :
        direction_to_take = vbt.pf_enums.Direction.LongOnly
    else:
        direction_to_take = vbt.pf_enums.Direction.ShortOnly
        
    Order = pf_nb.order_nb(size = -closing_percent, 
                           size_type = vbt.pf_enums.SizeType.ValuePercent100,
                           direction = direction_to_take,
                           price = execution_state_.val_price
                           )

    
    order_result , new_execution_state = vbt.pf_nb.process_order_nb(
                                                group = group_ ,col = column , i = bar_,
                                                exec_state = execution_state_,
                                                order = Order,
                                                price_area = price_area_,
                                                update_value = update_value_,
                                                order_records = order_records_,
                                                order_counts = order_counts_,
                                                log_records = log_records_,
                                                log_counts = log_counts_)
    
                                                         
    return order_result, new_execution_state



</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="key-points-summary-%F0%9F%92%A1">Key Points / Summary &#x1F4A1;</h2>
<blockquote>
<ul>
<li>
<p>The functions streamline the process of creating the <code>Order</code> and allow all the trades to be tracked via the <code>order_records</code> and <code>order_counts</code></p>
</li>
<li>
<p>The <code>Size</code> component of the <code>Order</code> is directly linked to the precentage risk that is being taken on the account and the <code>size_type</code> ensures that the amount on the account that is risked is exactly as what has been specified in the function argument.</p>
</li>
</ul>
</blockquote>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Discretionary Signal Bactesting]]></title><description><![CDATA[<p>In this tutorial we see how to backtest discretionary signals (eg: from a Telegram Channel) using VectorBT Pro. Primarily, we learn how to create our own order execution engine <code>order_func_nb</code> which deals with orders and position management in our signals data and finally our own custom simulator <code>signal_</code></p>]]></description><link>http://localhost:2368/discretionary-signals-bactesting/</link><guid isPermaLink="false">643c151fe770773c74f2e605</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[discretionary signals]]></category><category><![CDATA[backtesting]]></category><category><![CDATA[telegram]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Sat, 15 Apr 2023 09:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1636743094110-5e153f93ad7e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDJ8fFRlbGVncmFtfGVufDB8fHx8MTY4MTU1MzExOA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1636743094110-5e153f93ad7e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDJ8fFRlbGVncmFtfGVufDB8fHx8MTY4MTU1MzExOA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Discretionary Signal Bactesting"><p>In this tutorial we see how to backtest discretionary signals (eg: from a Telegram Channel) using VectorBT Pro. Primarily, we learn how to create our own order execution engine <code>order_func_nb</code> which deals with orders and position management in our signals data and finally our own custom simulator <code>signal_simulator_nb</code> which uses the <code>order_func_nb</code> function along with a host of other smaller helper functions to complete the simulation.</p><p>You can follow this tutorial in this YouTube video</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe width="200" height="113" src="https://www.youtube.com/embed/EQjdWAE613A?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen title="Discretionary Signals Backtesting using VectorBT Pro"></iframe><figcaption>YouTube - Discretionary Signals using VectorBT Pro</figcaption></figure><p>Many Thanks to <code>Oleg Polakow</code> for his gracious effort in building all the code in this project. Be sure to check out the jupyter notebook in the link below</p><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/QubitQuants/vectorbt_pro_tutorials/blob/main/Discretionary_Signal_Backtesting.ipynb" class="kg-btn kg-btn-accent">See Project Code</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Parameter Optimisation of a Strategy]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>In this tutorial, we will see how to do <code>Parameter Optimization</code> on the <code>Double Bollinger Band strategy</code> we had seen in our earlier tutorials. The goal of parameter optimization is to find the optimal values for the parameters of an algorithmic trading strategy to maximize a performance metric like <code>total_</code></p>]]></description><link>http://localhost:2368/parameter-optimization/</link><guid isPermaLink="false">643c151fe770773c74f2e604</guid><category><![CDATA[algorithmic trading]]></category><category><![CDATA[parameter optimization]]></category><category><![CDATA[cross-validation]]></category><category><![CDATA[vectorBT]]></category><category><![CDATA[signal generation]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Tue, 28 Feb 2023 09:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1564730465543-e732e7fc9c10?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fGVuZ2luZSUyMHR1bmluZ3xlbnwwfHx8fDE2Nzc1MTIwNjU&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1564730465543-e732e7fc9c10?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fGVuZ2luZSUyMHR1bmluZ3xlbnwwfHx8fDE2Nzc1MTIwNjU&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Parameter Optimisation of a Strategy"><p>In this tutorial, we will see how to do <code>Parameter Optimization</code> on the <code>Double Bollinger Band strategy</code> we had seen in our earlier tutorials. The goal of parameter optimization is to find the optimal values for the parameters of an algorithmic trading strategy to maximize a performance metric like <code>total_returns</code>, <code>Sharpe Ratio</code>, <code>Sortino Ratio</code>, <code>Win Rate</code> etc. or also to minimize certain metrics like <code>Total Drawdown</code>. Quintessentially, we will see how to:</p>
<ul>
<li>Use the <code>vbt.Parameterized()</code> decorator to easily convert any strategy function into a parameter optimization simulation.</li>
<li>Use the <code>vbt.Splitter</code> object to create <code>train</code> and <code>test</code> splits for cross validation of the parameter optimization process.</li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="loading-and-resampling-market-data">Loading and resampling market data</h2>
<p>As always, we begin by loading the market data, in this case <code>BTCUSDT</code> (one minute) data from Binance. We will then resample the <code>M1</code> data to higher timeframes and store this resampled data in a dictionary for quick in memory access during the parameter optimization process.</p>
<pre><code class="language-python">import numpy as np
import pandas as pd
import vectorbtpro as vbt

## Acquire BTCUSDT 1m crypto data from Binance

data = vbt.BinanceData.fetch(
    [&quot;BTCUSDT&quot;], 
    start=&quot;2019-01-01 UTC&quot;, 
    end=&quot;2023-02-02 UTC&quot;,
    timeframe=&quot;1m&quot;
    )

## Save acquired data locally for persistance
data.to_hdf(&quot;/Users/john.doe/vbt_pro_tutorials/data/Binance_BTCUSDT_OHLCV_3Y_m1.h5&quot;)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>To read <code>hdf</code> files of market data downloaded from Binance, VectorBT Pro has this <code>vbt.BinanceData.from_hdf()</code> method which automatically deals with resampling issues for all the columns.</p>
<pre><code class="language-python">## Load m1 data - GBPUSD
m1_data = vbt.BinanceData.from_hdf(&apos;../data/Binance_BTCUSDT_OHLCV_3Y_m1.h5&apos;)

## Resample m1 data to higher timeframes
m5_data  = m1_data.resample(&apos;5T&apos;)   # Convert 1 minute to 5 mins
m15_data = m1_data.resample(&apos;15T&apos;)  # Convert 1 minute to 15 mins
m30_data = m1_data.resample(&apos;30T&apos;)  # Convert 1 minute to 30 mins
h1_data  = m1_data.resample(&quot;1H&quot;)   # Convert 1 minute to 1 hour
h2_data  = m1_data.resample(&quot;2H&quot;)   # Convert 1 minute to 2 hour
h4_data  = m1_data.resample(&apos;4H&apos;)   # Convert 1 minute to 4 hour
h12_data = m1_data.resample(&apos;12H&apos;)  # Convert 1 minute to 12 hour
d1_data  = m1_data.resample(&apos;1D&apos;)   # Convert 1 minute to Daily data

mtf_data = { &quot;1T&quot; : m1_data, &quot;5T&quot; : m5_data, &quot;15T&quot; : m15_data, &quot;30T&quot; : m30_data,
             &quot;1H&quot; : h1_data, &quot;2H&quot; : h2_data, &quot;4H&quot; : h4_data, &quot;12H&quot; : h12_data, &quot;1D&quot; : d1_data }
</code></pre>
<p>We will also create helper functions like:</p>
<ul>
<li><code>remapped_tf</code> - to retrive mapped key values from this <code>freq_dict</code> mapper dict</li>
<li><code>flatten_list</code> - to flatten a 2D list into a 1D list</li>
<li><code>create_list_numbers</code> - to generate a range list of numbers</li>
</ul>
<pre><code class="language-python">freq_dict = { &quot;1T&quot; : 1, &quot;5T&quot; : 5, &quot;15T&quot; : 15, &quot;30T&quot; : 30,
              &quot;1H&quot; : 60, &quot;2H&quot; : 120, &quot;4H&quot; : 240, &quot;8H&quot; : 480,
              &quot;12H&quot; : 720, &quot;1D&quot;: 1440 }  

def remapped_tf(input_value : int) -&gt; str:
    &quot;&quot;&quot;Map an integer to a string timeframe format&quot;&quot;&quot;
    tf_freq = {1 : &quot;1T&quot;, 5 : &quot;5T&quot;, 15 : &quot;15T&quot;, 30 : &quot;30T&quot;, 60 :&quot;1H&quot;, 
                  120 : &quot;2H&quot;, 240 : &quot;4H&quot;, 720 : &quot;12H&quot;, 1440 : &quot;1D&quot;}
    new_value = tf_freq.get(input_value)
    return new_value      

def flatten_list(list_2D : list):
    &quot;&quot;&quot;Flatten a list of list of strings&quot;&quot;&quot;
    flat_list = list_2D if len(list_2D) == 0 else [item for sublist in list_2D for item in sublist]
    return flat_list

def create_list_numbers(r1, r2, step):
    &quot;&quot;&quot;Create a list of numbers between two bounds (r1, r2 which can be float or int) and incrementing
       each number using the specified `step` value &quot;&quot;&quot;
    if type(r1) == float and type(r2) == float:
        return list(np.round(np.arange(r1, r2+step, step), 2))
    return list(np.arange(r1, r2+step, step))                            
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>You might remember this <code>create_resamplers</code> function from our first tutorial which we used for <code>upsampling</code>.</p>
<pre><code class="language-python">def create_resamplers(result_dict_keys_list : list, source_indices : list,  
                      source_frequencies :list, target_index : pd.Series, target_freq : str):
    &quot;&quot;&quot;
    Creates a dictionary of vbtpro resampler objects.

    Parameters
    ==========
    result_dict_keys_list : list, list of strings, which are keys of the output dictionary
    source_indices        : list, list of pd.time series objects of the higher timeframes
    source_frequencies    : list(str), which are short form representation of time series order. Eg:[&quot;1D&quot;, &quot;4h&quot;]
    target_index          : pd.Series, target time series for the resampler objects
    target_freq           : str, target time frequency for the resampler objects

    Returns
    ===========
    resamplers_dict       : dict, vbt pro resampler objects
    &quot;&quot;&quot;
    
    
    resamplers = []
    for si, sf in zip(source_indices, source_frequencies):
        resamplers.append(vbt.Resampler(source_index = si,  target_index = target_index,
                                        source_freq = sf, target_freq = target_freq))
    return dict(zip(result_dict_keys_list, resamplers))
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="vbtparameterized-decorator"><code>@vbt.parameterized</code> decorator</h2>
<p>The decorator <code>@vbt.parameterized</code> is engine-agnostic and parameterizes a strategy function and returns a new function with the same signature as the passed one. This decorator enhances our <code>optimal_2BB</code> strategy function (below) to take arguments wrapped with <code>vbt.Param</code>, and build the grid of parameter combinations, run the <code>optimal_2BB</code> function on each parameter combination, and merge the results using concatenation. <br><br>
The following arguments are used in the <code>@vbt.parameterized()</code> decorator:</p>
<ul>
<li><code>random_subset = 1000</code>, randomly selects 1000 combinations out of millions of combinations, like we do in <code>random selection</code></li>
<li><code>merge_func = &quot;concat&quot;</code>, concats the output of each output row-wise, to the same <code>pd.Series</code>, other values for <code>merg_func</code> are <code>&quot;column_stack&quot;</code></li>
<li><code>show_progress = True</code>, shows the <code>tqdm</code> progress bar of the simulation</li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">@vbt.parameterized(merge_func = &quot;concat&quot;, random_subset = 1000, show_progress=True)  
def optimal_2BB(lower_tf : int = 1, higher_tf: int = 5,
                ltf_rsi_timeperiod : int = 21, 
                bb_price_timeperiod : int = 14, bb_rsi_timeperiod : int = 14,
                bb_price_nbdevup : int = 2, bb_price_nbdevdn: int = 2,
                bb_rsi_nbdevup : int = 2, bb_rsi_nbdevdn : int = 2,
                output_metric : str | list = &quot;total_return&quot;,
                index = None
                ):
    
    lower_tf  = remapped_tf(lower_tf)
    higher_tf = remapped_tf(higher_tf)
    # print(&quot;New Lower TF:&quot;, lower_tf, &quot;New Higher TF:&quot;, higher_tf)
    
    if index is None:
        ltf_data = mtf_data[lower_tf]
        htf_data = mtf_data[higher_tf]
    else:
        # print(f&quot;Start Index:{index[0]} || End Index: {index[-1]}&quot;)
        ltf_data = mtf_data[lower_tf].loc[index[0]:index[-1]]
        htf_data = mtf_data[higher_tf].loc[index[0]:index[-1]]

    ### Get OHLC prices for lower and higher timeframes
    ltf_open, ltf_high, ltf_low, ltf_close = ltf_data.get(&apos;Open&apos;), ltf_data.get(&apos;High&apos;), ltf_data.get(&apos;Low&apos;), ltf_data.get(&apos;Close&apos;)
    htf_open, htf_high, htf_low, htf_close = htf_data.get(&apos;Open&apos;), htf_data.get(&apos;High&apos;), htf_data.get(&apos;Low&apos;), htf_data.get(&apos;Close&apos;)

    ltf_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = ltf_rsi_timeperiod).run(ltf_close, skipna=True).real.ffill()
    ltf_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(ltf_rsi, timeperiod = bb_rsi_timeperiod, nbdevup = bb_rsi_nbdevup, nbdevdn = bb_rsi_nbdevdn, skipna=True)    
    htf_bbands_price = vbt.talib(&quot;BBANDS&quot;).run(htf_close, timeperiod = bb_price_timeperiod, nbdevup = bb_price_nbdevup, nbdevdn = bb_price_nbdevdn, skipna=True)

    ## Initialize  dictionary
    data = {}

    col_values = [ ltf_close, ltf_rsi,ltf_bbands_rsi.upperband, ltf_bbands_rsi.middleband, ltf_bbands_rsi.lowerband ]

    col_keys = [ &quot;ltf_close&quot;, &quot;ltf_rsi&quot;, &quot;ltf_bbands_rsi_upper&quot;,  &quot;ltf_bbands_rsi_middle&quot;, &quot;ltf_bbands_rsi_lower&quot; ]

    # Assign key, value pairs for method of time series data to store in data dict
    for key, time_series in zip(col_keys, col_values):
        data[key] = time_series.ffill()

    resampler_dict_keys = [higher_tf + &quot;_&quot; + lower_tf]

    list_resamplers = create_resamplers(result_dict_keys_list = resampler_dict_keys,
                                        source_indices = [htf_close.index], 
                                        source_frequencies = [higher_tf], 
                                        target_index = ltf_close.index,
                                        target_freq = lower_tf)

    # print(list_resamplers)
    
    ## Use along with  Manual indicator creation method for MTF
    series_to_resample = [
        [htf_open, htf_high, htf_low, htf_close, 
        htf_bbands_price.upperband, htf_bbands_price.middleband, htf_bbands_price.lowerband]
        ]


    resample_data_keys = [
        [&quot;htf_open&quot;, &quot;htf_high&quot;, &quot;htf_low&quot;, &quot;htf_close&quot;, 
        &quot;htf_bbands_price_upper&quot;,  &quot;htf_bbands_price_middle&quot;,  &quot;htf_bbands_price_lower&quot;]
            ]    

    df_cols_order = col_keys + flatten_list(resample_data_keys)
    ## Create resampled time series data aligned to base line frequency (15min)
    # print(&quot;COLUMNS ORDER:&quot;, df_cols_order)
    
    for lst_series, lst_keys, resampler in zip(series_to_resample, resample_data_keys, resampler_dict_keys):
        for key, time_series in zip(lst_keys, lst_series):
            if key.lower().endswith(&apos;open&apos;):
                # print(f&apos;Resampling {key} differently using vbt.resample_opening using &quot;{resampler}&quot; resampler&apos;)
                resampled_time_series = time_series.vbt.resample_opening(list_resamplers[resampler])
            else:
                resampled_time_series = time_series.vbt.resample_closing(list_resamplers[resampler])
            data[key] = resampled_time_series
    

    ## construct a multi-timeframe dataframe
    mtf_df = pd.DataFrame(data)[df_cols_order]

    # print(&quot;DataFrame Output:\n&quot;, mtf_df.head())

    ## Long Entry Conditions
    c1_long_entry = (mtf_df[&apos;htf_low&apos;] &lt;= mtf_df[&apos;htf_bbands_price_lower&apos;])
    c2_long_entry = (mtf_df[&apos;ltf_rsi&apos;] &lt;= mtf_df[&apos;ltf_bbands_rsi_lower&apos;] )

    ## Long Exit Conditions
    c1_long_exit =  (mtf_df[&apos;htf_high&apos;] &gt;= mtf_df[&apos;htf_bbands_price_upper&apos;])
    c2_long_exit =  (mtf_df[&apos;ltf_rsi&apos;]  &gt;= mtf_df[&apos;ltf_bbands_rsi_upper&apos;])             

    ## Create entries and exit columns using the above conditions
    mtf_df[&apos;entry&apos;] = c1_long_entry &amp; c2_long_entry
    mtf_df[&apos;exit&apos;]  = c1_long_exit &amp; c2_long_exit

    mtf_df[&apos;signal&apos;] = 0   
    mtf_df[&apos;signal&apos;] = np.where( mtf_df[&apos;entry&apos;], 1, 0)
    mtf_df[&apos;signal&apos;] = np.where( mtf_df[&apos;exit&apos;] , -1, mtf_df[&apos;signal&apos;])

    entries = mtf_df.signal == 1.0
    exits = mtf_df.signal == -1.0

    pf = vbt.Portfolio.from_signals(
        close = ltf_close, 
        entries = entries, 
        exits = exits, 
        direction = &quot;both&quot;, ## This setting trades both long and short signals
        freq = pd.Timedelta(minutes = freq_dict[lower_tf]), 
        init_cash = 100000
    )

    if type(output_metric) == str:
        return pf.deep_getattr(output_metric) ## When tuning a single metric
    elif type(output_metric) == list:
        return pd.Series({k: getattr(pf, k) for k in output_metric}) ## When you want to tune a list of metrics
</code></pre>
<h4 id="double-bollinger-bandstrategy">Double Bollinger Band - Strategy</h4>
<p>As a quick recap, the rules of the strategy coded in <code>optimal_2BB</code> are as follows:</p>
<ol>
<li>
<p>A long (buy) signal is generated whenever the higher timeframe (Low) price goes below its lower Bollinger band, and the lower timeframe RSI goes below its lower Bollinger band (RSI).</p>
</li>
<li>
<p>A short (sell) signal is generated whenever the higher timeframe (High) price breaks its upper Bollinger band, and the lower timeframe RSI breaks above its upper Bollinger band (RSI).</p>
</li>
</ol>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We can invoke the parameter optimization process by passing the list of parameters we want for each argument wrapped in the <code>vbt.Param</code> class.<br>
The <code>vbt.Param</code> class also accepts conditions, like in our case we don&apos;t want the <code>lower_tf</code> to have a value greater than the <code>higher_tf</code> so we specify that using the <code>condition</code> argument inside the <code>vbt.Param</code> class. In this particular case we are just specifying one metric (<code>total_return</code>) to tune our parameter optimization.</p>
<pre><code class="language-python">pf_results = optimal_2BB(
    lower_tf = vbt.Param([1, 5, 15, 30, 60, 120, 240, 720], condition = &quot;x &lt;= higher_tf&quot;),
    higher_tf = vbt.Param([1, 5, 15, 30, 60, 120, 240, 720, 1440]),
    ltf_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_price_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    output_metric = &quot;total_return&quot;
 )

print(f&quot;Best Total Returns: {round(pf_results.max(), 2)} %&quot;)
print(f&quot;Parameter Combinations with Best Total Returns:{pf_results.idxmax()}&quot;)

print(f&quot;Worst Total Returns: {round(pf_results.min(), 2)} %&quot;)
print(f&quot;Parameter Combinations with Worst Total Returns:{pf_results.idxmin()}&quot;)
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-bash">Best Total Returns: 8917.26 %
Parameter Combinations with Best Total Returns:(1, 1, 19, 20, 22, 1.75, 2.25, 1.5, 2.0)
Worst Total Returns: -4.41 %
Parameter Combinations with Worst Total Returns:(120, 1440, 18, 19, 22, 2.5, 2.0, 2.25, 2.5)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Since for this simulation, we selected only a single output metric ( <code>total_returns</code> ), we get a multi-index pandas series which we can sort to quickly see the most promising results</p>
<pre><code class="language-python">pf_results.sort_values(ascending=False)
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/02/pf_sim_multi_index_series.png" class="kg-image" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy" width="2000" height="425" srcset="http://localhost:2368/content/images/size/w600/2023/02/pf_sim_multi_index_series.png 600w, http://localhost:2368/content/images/size/w1000/2023/02/pf_sim_multi_index_series.png 1000w, http://localhost:2368/content/images/size/w1600/2023/02/pf_sim_multi_index_series.png 1600w, http://localhost:2368/content/images/size/w2400/2023/02/pf_sim_multi_index_series.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Portfolio Simulation Results (Multi-index Pandas Series)</figcaption></figure><!--kg-card-begin: markdown--><p>We can also pass multiple metrics as a list to the <code>output_metric</code> argument, and the output the entire portfolio simulation a multi-index pandas series. Of course, in this case, it is not like <em>we are tuning multiple knobs and dials to get an optimal value for all the metrics passed</em>, but we are just returning multiple metrics as part of the output of each simulation.</p>
<pre><code class="language-python">pf_results = optimal_2BB(
    lower_tf = vbt.Param([5, 30], condition = &quot;x &lt;= higher_tf&quot;),
    higher_tf = vbt.Param([1, 5, 15]),
    ltf_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_price_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    output_metric = [&quot;total_profit&quot;, &quot;total_return&quot;, &quot;max_drawdown&quot;, &quot;sharpe_ratio&quot;]
 )</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>To flatten the multi-index series and convert it into a pandas DataFrame, we can use this following code:</p>
<pre><code class="language-python">pf_results_df = pf_results.unstack(level = -1)
pf_results_df = pf_results_df[[&apos;total_return&apos;,&apos;max_drawdown&apos;,&apos;sharpe_ratio&apos;]].sort_values(
                by=[&apos;total_return&apos;, &apos;max_drawdown&apos;], 
                ascending=False)
pf_results_df.reset_index(inplace=True)
pf_results_df
</code></pre>
<p><img src="http://localhost:2368/content/images/2023/02/pf_results_flattened_dataframe.png" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## To check if our condition for `lower_tf` works
print(&quot;Length of DF:&quot;,len(pf_results_df[pf_results_df[&apos;lower_tf&apos;] &gt; pf_results_df[&apos;higher_tf&apos;]]))
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-bash">Length of DF: 0
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">print(f&quot;Best Total Returns: {round(pf_results_df[&apos;total_return&apos;].max(), 2)} %&quot;)
print(f&quot;Parameter Combinations with Best Total Returns:&quot;)
pd.DataFrame(pf_results_df.iloc[pf_results_df[&apos;total_return&apos;].idxmax()]).T
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-bash">Best Total Returns: 504.49 %
Parameter Combinations with Best Total Returns:
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>lower_tf</th>
<th>higher_tf</th>
<th>ltf_rsi_timeperiod</th>
<th>bb_price_timeperiod</th>
<th>bb_rsi_timeperiod</th>
<th>bb_price_nbdevup</th>
<th>bb_price_nbdevdn</th>
<th>bb_rsi_nbdevup</th>
<th>bb_rsi_nbdevdn</th>
<th>total_return</th>
<th>max_drawdown</th>
<th>sharpe_ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>5</td>
<td>5</td>
<td>18.0</td>
<td>18.0</td>
<td>19.0</td>
<td>2.25</td>
<td>1.5</td>
<td>1.75</td>
<td>2.0</td>
<td>504.490043</td>
<td>-0.389288</td>
<td>2.328832</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">print(f&quot;Worst Total Returns: {round(pf_results_df[&apos;total_return&apos;].min(), 2)} %&quot;)
print(f&quot;Parameter Combinations with Worst Total Returns:&quot;)
pd.DataFrame(pf_results_df.iloc[pf_results_df[&apos;total_return&apos;].idxmin()]).T
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-bash">Worst Total Returns: -0.98 %
Parameter Combinations with Worst Total Returns:
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>lower_tf</th>
<th>higher_tf</th>
<th>ltf_rsi_timeperiod</th>
<th>bb_price_timeperiod</th>
<th>bb_rsi_timeperiod</th>
<th>bb_price_nbdevup</th>
<th>bb_price_nbdevdn</th>
<th>bb_rsi_nbdevup</th>
<th>bb_rsi_nbdevdn</th>
<th>total_return</th>
<th>max_drawdown</th>
<th>sharpe_ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>999</td>
<td>5</td>
<td>15</td>
<td>20.0</td>
<td>22.0</td>
<td>20.0</td>
<td>2.25</td>
<td>2.5</td>
<td>2.25</td>
<td>2.5</td>
<td>-0.977365</td>
<td>-0.991565</td>
<td>-0.704983</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="cross-validation">Cross Validation</h2>
<p>Cross-Validation (CV) is a technique used to curb <a href="https://en.wikipedia.org/wiki/Curve_fitting">overfitting</a>, which involves partitioning a sample of data into complementary subsets, performing the analysis on one subset of data called the <code>training</code> or <code>in-sample</code> (IS) set, and validating the analysis on the other subset of data called the <code>testing</code>, <code>validation</code> or <code>out-of-sample</code> (OOS) set. This procedure is repeated until we have multiple OOS periods and can draw statistics from these results combined. CV is mainly done for the following reasons:</p>
<ul>
<li>Improve robustness testing of the strategy</li>
<li>Mitigate the risk of running wrong predictions. <br>
<ul>
<li>This is because, the input data, usually retrieved from a limited time frame slice of history, is highly biased and can not produce reliable forecasts. One way to mitigate the risk of running wrong predictions is to do CV, where we re-run backtests many times but each with slightly different data input</li>
</ul>
</li>
</ul>
<h3 id="splitter-class"><code>Splitter</code> Class</h3>
<p>At the heart of implementing CV functionality in vectorBT Pro is the class <code>Splitter</code>, whose main responsibility is to produce arbitrary splits and perform operations on those splits. The workings of this class are quite simple- the user calls one of the class methods with the prefix <code>from_</code>to generate splits; in return, a splitter instance is returned with splits and their labels being saved in a memory-efficient array format. This instance can be used to analyze the split distribution, to chunk array-like objects, and to run User Defined Functions (UDFs).<br>
The splitter class has many methods like:</p>
<ul>
<li><code>from_rolling</code> and<code>from_n_rolling</code></li>
<li><code>from_expanding</code>and <code>from_n_expanding</code></li>
<li><code>from_splits</code></li>
<li><code>from_ranges</code></li>
<li><code>from_grouper</code></li>
<li><code>from_random</code></li>
<li><code>from_sklearn</code></li>
<li><code>from_split_func</code></li>
</ul>
<p>In this tutorial we will just go over the <code>from_rolling</code> splitter method as it is the typical requirement of creating data splits. It is beyond the scope of this tutorial, to go over all the splitter methods above, so it is recommended to read the <code>vectorbtpro</code> documentation to decide which method would best fit your use case.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Let&apos;s create a splitter schema using <code>splitter.from_rolling()</code> method for cross-validation of our <code>optimal_2BB</code> strategy.</p>
<pre><code class="language-python">## Global Plot Settings
vbt.settings.set_theme(&quot;dark&quot;)
vbt.settings[&apos;plotting&apos;][&apos;layout&apos;][&apos;width&apos;] = 1600

splitter = vbt.Splitter.from_rolling(
    index  = d1_data.index, 
    length = 360, 
    split = 0.5,
    set_labels = [&quot;train&quot;, &quot;test&quot;]
    )
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>The arguments we have used in the <code>from_rolling</code> method for the above schema are as follows:</p>
<ul>
<li><code>index</code> - datatime index series required to create the splits from. In this case, we used the the index series from the daily (<code>d1_data</code>) data.</li>
<li><code>length</code> - can be <code>int</code>, <code>float</code>, or <code>timedelta_like</code> . Floating values between 0 and 1 are considered relative. Length can also be negative. We have used 360 days as the length of a single split.</li>
<li><code>split</code> - Ranges to split the range into. If None, will produce the entire range as a single range. Here <code>split = 0.5</code> means, we will be splitting the length of 360 days into equal splits for <code>train</code> and <code>test</code> sets.</li>
<li><code>set_labels</code> - Labels corresponding to the selected row/column groups. In our case we are creating two sets called <code>train</code> and <code>test</code></li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">splitter.plot().show()
</code></pre>
<p><strong>Output</strong>:<br>
<img src="http://localhost:2368/content/images/2023/02/Splitter_Test_Train.png" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>The smallest unit of a splitter is a range, which is a period of time that can be mapped onto data. On the plot above, we can count a total of 14 ranges - 7 blue ones for train sets and 7 orange ones for test sets. Multiple ranges next to each other and representing a single test are called a split; there are 6 splits present in the chart, such that we expect one pipeline to be tested on 6 different data ranges. Different range types within each split are called sets. We have used the two sets - &quot;training&quot; and &quot;test&quot; (commonly used in backtesting). The number of sets is fixed throughout all splits.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">splitter.splits
</code></pre>
<p><strong>Output</strong>:<br></p>
<table>
<thead>
<tr>
<th>set</th>
<th>train</th>
<th>test</th>
</tr>
</thead>
<tbody>
<tr>
<td>split</td>
<td></td>
<td></td>
</tr>
<tr>
<td>0</td>
<td>slice(0,180,None)</td>
<td>slice(180,360,None)</td>
</tr>
<tr>
<td>1</td>
<td>slice(180,360,None)</td>
<td>slice(360,540,None)</td>
</tr>
<tr>
<td>2</td>
<td>slice(360,540,None)</td>
<td>slice(540,720,None)</td>
</tr>
<tr>
<td>3</td>
<td>slice(540,720,None)</td>
<td>slice(720,900,None)</td>
</tr>
<tr>
<td>4</td>
<td>slice(720,900,None)</td>
<td>slice(900,1080,None)</td>
</tr>
<tr>
<td>5</td>
<td>slice(900,1080,None)</td>
<td>slice(1080,1260,None)</td>
</tr>
<tr>
<td>6</td>
<td>slice(1080,1260,None)</td>
<td>slice(1260,1440,None)</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Time is being tracked separately in <code>Splitter.index</code> while assets aren&apos;t being tracked at all since they have no implications on splitting.</p>
<pre><code class="language-python">splitter.index
</code></pre>
<p><strong>Output</strong>:<br></p>
<pre><code class="language-bash">DatetimeIndex([&apos;2019-01-01 00:00:00+00:00&apos;, &apos;2019-01-02 00:00:00+00:00&apos;,
               &apos;2019-01-03 00:00:00+00:00&apos;, &apos;2019-01-04 00:00:00+00:00&apos;,
               &apos;2019-01-05 00:00:00+00:00&apos;, &apos;2019-01-06 00:00:00+00:00&apos;,
               &apos;2019-01-07 00:00:00+00:00&apos;, &apos;2019-01-08 00:00:00+00:00&apos;,
               &apos;2019-01-09 00:00:00+00:00&apos;, &apos;2019-01-10 00:00:00+00:00&apos;,
               ...
               &apos;2023-01-23 00:00:00+00:00&apos;, &apos;2023-01-24 00:00:00+00:00&apos;,
               &apos;2023-01-25 00:00:00+00:00&apos;, &apos;2023-01-26 00:00:00+00:00&apos;,
               &apos;2023-01-27 00:00:00+00:00&apos;, &apos;2023-01-28 00:00:00+00:00&apos;,
               &apos;2023-01-29 00:00:00+00:00&apos;, &apos;2023-01-30 00:00:00+00:00&apos;,
               &apos;2023-01-31 00:00:00+00:00&apos;, &apos;2023-02-01 00:00:00+00:00&apos;],
              dtype=&apos;datetime64[ns, UTC]&apos;, name=&apos;Open time&apos;, length=1493, freq=&apos;D&apos;)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">print(&quot;Total Nr. of Splits:&quot;,len(close_slices.index))
df_splits = pd.DataFrame(close_slices.index.tolist(), columns=[&quot;split&quot;, &quot;period&quot;])
unique_splits = df_splits[&quot;split&quot;].unique().tolist()
print(&quot;Unique Splits:&quot;, unique_splits)
df_splits
</code></pre>
<p><strong>Output:</strong><br></p>
<pre><code class="language-bash">Total Nr. of Splits: 14
Unique Splits: [0, 1, 2, 3, 4, 5, 6]
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>split</th>
<th>period</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>train</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>test</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>train</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>test</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>train</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>test</td>
</tr>
<tr>
<td>6</td>
<td>3</td>
<td>train</td>
</tr>
<tr>
<td>7</td>
<td>3</td>
<td>test</td>
</tr>
<tr>
<td>8</td>
<td>4</td>
<td>train</td>
</tr>
<tr>
<td>9</td>
<td>4</td>
<td>test</td>
</tr>
<tr>
<td>10</td>
<td>5</td>
<td>train</td>
</tr>
<tr>
<td>11</td>
<td>5</td>
<td>test</td>
</tr>
<tr>
<td>12</td>
<td>6</td>
<td>train</td>
</tr>
<tr>
<td>13</td>
<td>6</td>
<td>test</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="compute-baseline-returns-across-splits">Compute Baseline Returns across <code>splits</code></h3>
<p>The baseline returns is just the buy and hold returns for buying and holding the asset for the period of the split.</p>
<pre><code class="language-python">def get_total_return(close_prices):
    return close_prices.vbt.to_returns().vbt.returns.total()

base_line_returns = close_slices.apply(get_total_return)
base_line_returns
</code></pre>
<p><strong>Output:</strong><br></p>
<pre><code class="language-bash">split  set  
0      train    2.134762
       test    -0.336472
1      train   -0.336472
       test     0.326704
2      train    0.326704
       test     1.523051
3      train    1.523051
       test     0.576598
4      train    0.576598
       test     0.377110
5      train    0.377110
       test    -0.527897
6      train   -0.527897
       test    -0.226275
dtype: float64
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><strong>Print upper and lower bound in each split</strong></p>
<pre><code class="language-python">train_slices = [slice(close_slices[i, &quot;train&quot;].index[0], close_slices[i, &quot;train&quot;].index[-1]) for i in unique_splits]
train_slices
</code></pre>
<p><strong>Output:</strong><br></p>
<pre><code class="language-bash">[slice(Timestamp(&apos;2019-01-01 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2019-06-29 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2019-06-30 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2019-12-26 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2019-12-27 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2020-06-23 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2020-06-24 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2020-12-20 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2020-12-21 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2021-06-18 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2021-06-19 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2021-12-15 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2021-12-16 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2022-06-13 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None)]
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">test_slices = [slice(close_slices[i, &quot;test&quot;].index[0], close_slices[i, &quot;test&quot;].index[-1]) for i in unique_splits]
test_slices
</code></pre>
<p><strong>Output:</strong></p>
<pre><code class="language-bash">[slice(Timestamp(&apos;2019-06-30 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2019-12-26 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2019-12-27 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2020-06-23 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2020-06-24 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2020-12-20 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2020-12-21 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2021-06-18 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2021-06-19 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2021-12-15 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2021-12-16 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2022-06-13 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None),
 slice(Timestamp(&apos;2022-06-14 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), Timestamp(&apos;2022-12-10 00:00:00+0000&apos;, tz=&apos;UTC&apos;, freq=&apos;D&apos;), None)]
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="splitterapplyapplying-our-optimal2bb-function-to-the-splitter-sets"><code>Splitter.apply</code> - Applying our <code>optimal_2BB</code> function to the splitter sets</h2>
<p>We can use the <code>splitter.apply()</code> to apply the different splits on our strategy <code>optimal_2BB</code> function, by selecting the splits by their set label (eg: <code>train</code> or <code>test</code>). We would pass our strategy function (<code>optimal_2BB</code>) to the <code>apply_func</code> argument of the <code>splitter_apply</code> method and the arguments of the <code>optimal_2BB</code> function typically follow after the <code>apply_func</code> argument.<br><br>
The <code>splitter.apply()</code> method also has lots of arguments on its own and below we will see the  significant ones used here:</p>
<ul>
<li><code>index</code> argument allows us to pass the <code>splitter.index</code> variable containing our timeseries index, wrapped with the class <code>vbt.Takeable</code> which represents an object from which a range can be taken. The <code>vbt.Takeable</code> method will select a slice from it and substitute the instruction with that slice.</li>
<li><code>set_</code> argument allows us to select the <code>set_label</code> from the splitter object, in our case either <code>train</code> or <code>test</code></li>
<li><code>_random_subset</code> argument over-rides the argument <code>random_subset</code> in <code>vbt.parameterized</code> and determines the nr. of simulations to run per split</li>
<li><code>merge_func</code> argument with the value <code>concat</code> allows to append the result of each simulation in the train set row-wise (<code>axis = 0</code>)</li>
<li><code>execute_kwargs</code> control the execution of each split/set/range</li>
<li><code>_execute_kwargs</code> control the execution of your parameter combinations</li>
</ul>
<p>When we use this <code>optimal_2BB</code> function during cross-validation by calling <code>splitter.apply()</code> method, we have to pass an <code>index</code> argument to our <code>optimal_2BB</code> function. We slice the dataframe using this <code>index</code> argument (eg: <code>mtf_data[lower_tf]loc[index[0]:index[-1]]</code>) inside the <code>optimal_2BB</code> function since we are doing <code>vbt.Splitter.from_rolling()</code>in this tutorial.</p>
<p>Generally, if the splitter produces date ranges that contain no gaps, such as in <code>from_rolling</code> method and most other cross-validation schemes for time-series data, we can use the first and the last date (also called <code>&quot;bounds&quot;</code>) of each produced date range to select the subset of data.<br>
For splitter versions that produce gaps, such as for k-fold cross-validation schemes (which are rarely used anyway), we must use the entire index to select the subset of data.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="performance-on-train-splits">Performance on <code>train</code> splits</h3>
<p>Below we will see the <code>splitter.apply</code> used on our <code>train</code> splits</p>
<pre><code class="language-python">train_perf = splitter.apply(
    apply_func = optimal_2BB, ## apply your strategy function to the splitter object, followed by its arguments
    lower_tf = vbt.Param([1, 5, 15, 30, 60, 120, 240, 720], condition = &quot;x &lt;= higher_tf&quot;),
    higher_tf = vbt.Param([1, 5, 15, 30, 60, 120, 240, 720, 1440]),    
    ltf_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_price_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    output_metric = &quot;sharpe_ratio&quot;,
    #### Arguments of splitter.apply() not related to strategy
    index =  vbt.Takeable(splitter.index), ## DataTime index from the splitter object
    set_ = &quot;train&quot;,  ## Specify the set to be used for this CV simulation - train or test
    _random_subset = 500, ## Specify the nr. of simulations to run per train split
    merge_func = &quot;concat&quot;, ## concat the results
    execute_kwargs=dict(show_progress=True), ## execute_kwargs control the execution of each split/set/range - Show Progress bar of the simulation
    _execute_kwargs=dict(show_progress=False, clear_cache=50, collect_garbage=50) ## _execute_kwargs control the execution of your parameter combinations
    )
    
train_perf.sort_values(ascending=False)
</code></pre>
<p>An argument having underscore <code>_</code> as the prefix (eg: <code>_random_subset</code>) here means that the argument overrides the default argument value passed to the <code>vbt.parameterized()</code> decorator. In this case, <code>_random_subset = 500</code> means we will be doing only 500 simulations for each train split (7 train splits in total), as opposed to the default value of <code>random_subset = 1000</code> set in the <code>vbt.parameterized()</code> decorator above the <code>optimal_2BB</code> function definition.</p>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/02/train_split_performance-1.png" class="kg-image" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy" width="2000" height="453" srcset="http://localhost:2368/content/images/size/w600/2023/02/train_split_performance-1.png 600w, http://localhost:2368/content/images/size/w1000/2023/02/train_split_performance-1.png 1000w, http://localhost:2368/content/images/size/w1600/2023/02/train_split_performance-1.png 1600w, http://localhost:2368/content/images/size/w2400/2023/02/train_split_performance-1.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Parameter Optimization Results on <code>train</code> splits</figcaption></figure><!--kg-card-begin: markdown--><h3 id="statistics-on-train-split">Statistics on <code>train</code> split</h3>
<pre><code class="language-python">train_split_describe = pd.concat([train_perf[train_perf.index.get_level_values(&apos;split&apos;) == i].describe()\
                                for i in unique_splits], axis = 1, 
                                keys = [f&quot;Train_Split_{i}&quot; for i in unique_splits])
train_split_describe 
</code></pre>
<p><strong>Output:</strong><br>
<img src="http://localhost:2368/content/images/2023/02/train_split_describe-1.png" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Compute baseline, best and worst returns for the overlaid line plots
train_split_best_returns = train_split_describe.loc[&apos;max&apos;].reset_index(drop=True)
train_split_worst_returns = train_split_describe.loc[&apos;min&apos;].reset_index(drop=True)
train_splits_baseline_returns = pd.Series([base_line_returns[i, &quot;train&quot;] for i in unique_splits])

## Create Box Plot for train_performance
train_split_fig = train_perf.vbt.boxplot(
    by_level=&quot;split&quot;,
    trace_kwargs=dict(
        line=dict(color=&quot;lightskyblue&quot;),
        opacity=0.4,
        showlegend=False
        ),
        xaxis_title=&quot;Train Splits&quot;,
        yaxis_title=&quot;Sharpe Ratio&quot;
        )

train_split_best_returns.vbt.plot(trace_kwargs=dict(name=&quot;Best Returns&quot;, line=dict(color=&quot;limegreen&quot;, dash=&quot;dash&quot;)), fig=train_split_fig)
train_split_worst_returns.vbt.plot(trace_kwargs=dict(name=&quot;Worst Returns&quot;, line=dict(color=&quot;tomato&quot;, dash=&quot;dash&quot;)), fig=train_split_fig)
train_splits_baseline_returns.vbt.plot(trace_kwargs=dict(name=&quot;Baseline&quot;, line=dict(color=&quot;yellow&quot;, dash=&quot;dash&quot;)), fig=train_split_fig)
train_split_fig.show()
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/02/train_split_perf_box_plot-1.png" class="kg-image" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy" width="1600" height="350" srcset="http://localhost:2368/content/images/size/w600/2023/02/train_split_perf_box_plot-1.png 600w, http://localhost:2368/content/images/size/w1000/2023/02/train_split_perf_box_plot-1.png 1000w, http://localhost:2368/content/images/2023/02/train_split_perf_box_plot-1.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Box Plot to view simulation statistics on <code>train</code> splits</figcaption></figure><!--kg-card-begin: markdown--><h3 id="performance-statistics-on-test-splits">Performance Statistics on <code>test</code> splits</h3>
<pre><code class="language-python">test_perf = splitter.apply(
    apply_func = optimal_2BB, ## apply your strategy function to the splitter object, followed by its arguments
    lower_tf = vbt.Param([1, 5, 15, 30, 60, 120, 240, 720], condition = &quot;x &lt;= higher_tf&quot;),
    higher_tf = vbt.Param([1, 5, 15, 30, 60, 120, 240, 720, 1440]),    
    ltf_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_rsi_timeperiod = vbt.Param(create_list_numbers(18, 22, 1)),
    bb_price_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_price_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevup = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    bb_rsi_nbdevdn = vbt.Param(create_list_numbers(1.5, 2.5, step = 0.25)),
    output_metric = &quot;sharpe_ratio&quot;,
    #### Arguments of splitter.apply() not related to strategy
    index =  vbt.Takeable(splitter.index), ## DataTime index from the splitter object
    _random_subset = 500, ## Specify the nr. of simulations to run per test split
    set_ = &quot;test&quot;,  ## Specify the set to be used for this CV simulation - train or test
    merge_func =&quot;concat&quot;, ## concat the results
    execute_kwargs=dict(show_progress=True), ## execute_kwargs control the execution of each split/set/range - Show Progress bar of the simulation
    _execute_kwargs=dict(show_progress=False, clear_cache=50, collect_garbage=50) ## _execute_kwargs control the execution of your parameter combinations
    )
    
test_perf.sort_values(ascending=False)
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/02/test_split_performance-1.png" class="kg-image" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy" width="2000" height="501" srcset="http://localhost:2368/content/images/size/w600/2023/02/test_split_performance-1.png 600w, http://localhost:2368/content/images/size/w1000/2023/02/test_split_performance-1.png 1000w, http://localhost:2368/content/images/size/w1600/2023/02/test_split_performance-1.png 1600w, http://localhost:2368/content/images/size/w2400/2023/02/test_split_performance-1.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Parameter Optimization Results on <code>test</code> splits</figcaption></figure><!--kg-card-begin: markdown--><h3 id="statistics-on-test-split">Statistics on <code>test</code> split</h3>
<pre><code class="language-python">test_split_describe = pd.concat([test_perf[test_perf.index.get_level_values(&apos;split&apos;) == i].describe()\
                                for i in unique_splits], axis = 1, 
                                keys = [f&quot;Test_Split_{i}&quot; for i in unique_splits])
test_split_describe  
</code></pre>
<p><img src="http://localhost:2368/content/images/2023/02/test_split_describe-1.png" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Compute baseline, best and worst returns for the overlaid line plots
test_split_best_returns = test_split_describe.loc[&apos;max&apos;].reset_index(drop=True)
test_split_worst_returns = test_split_describe.loc[&apos;min&apos;].reset_index(drop=True)
test_splits_baseline_returns = pd.Series([base_line_returns[i, &quot;test&quot;] for i in unique_splits])

## Create Box Plot for test_performance statistics
test_split_fig = test_perf.vbt.boxplot(
    by_level=&quot;split&quot;,
    trace_kwargs=dict(
        line=dict(color=&quot;lightskyblue&quot;),
        opacity=0.4,
        showlegend=False
        ),
        xaxis_title=&quot;Test Splits&quot;,
        yaxis_title=&quot;Sharpe Ratio&quot;
        )

test_split_best_returns.vbt.plot(trace_kwargs=dict(name=&quot;Best Returns&quot;, line=dict(color=&quot;limegreen&quot;, dash=&quot;dash&quot;)), fig=test_split_fig)
test_split_worst_returns.vbt.plot(trace_kwargs=dict(name=&quot;Worst Returns&quot;, line=dict(color=&quot;tomato&quot;, dash=&quot;dash&quot;)), fig=test_split_fig)
test_splits_baseline_returns.vbt.plot(trace_kwargs=dict(name=&quot;Baseline&quot;, line=dict(color=&quot;yellow&quot;, dash=&quot;dash&quot;)), fig=test_split_fig)
test_split_fig.show()
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/02/test_split_perf_box_plot-1.png" class="kg-image" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy" width="1600" height="350" srcset="http://localhost:2368/content/images/size/w600/2023/02/test_split_perf_box_plot-1.png 600w, http://localhost:2368/content/images/size/w1000/2023/02/test_split_perf_box_plot-1.png 1000w, http://localhost:2368/content/images/2023/02/test_split_perf_box_plot-1.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Box Plot to view simulation statistics on <code>test</code> splits</figcaption></figure><!--kg-card-begin: markdown--><h2 id="bonusline-by-line-profiling-of-a-python-function">BONUS - <code>Line-by-Line</code> Profiling of a python function</h2>
<p>It is sometimes important to optimize your strategy function to reduce the time taken for each simulation. We can do, <em>line by line</em> profiling of <code>optimal_2BB</code> function using this <code>%load_ext line_profiler</code>. <br> When applying the <code>line_profiler</code> you have to remove the <code>vbt.parameterized()</code> decorator, and apply the <code>line_profiler</code> on the unwrapped raw <code>optimal_2BB</code> strategy function. Below is a snapshot of the results you will get from the <code>line_profiler</code> which you can use to optimize aspects of your strategy function which have very higher <code>Time per hit</code> cost.</p>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/02/line_profiler_output.png" class="kg-image" alt="VectorBT Pro - Parameter Optimisation of a Strategy" loading="lazy" width="2000" height="979" srcset="http://localhost:2368/content/images/size/w600/2023/02/line_profiler_output.png 600w, http://localhost:2368/content/images/size/w1000/2023/02/line_profiler_output.png 1000w, http://localhost:2368/content/images/size/w1600/2023/02/line_profiler_output.png 1600w, http://localhost:2368/content/images/size/w2400/2023/02/line_profiler_output.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Line Profiler Results on <code>optimal_2BB</code> function</figcaption></figure><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/QubitQuants/vectorbt_pro_tutorials/blob/main/Parameter%20Optimization.ipynb" class="kg-btn kg-btn-accent">See Project Code</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - MultiAsset Data Acquisition]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>In this tutorial, we will talk about the acquisition of M1 (1 minute) data for various <strong>forex currency pairs</strong> from <code>dukascopy</code> (a free data provider).The acquired data will be saved to a <code>.hdf</code> file for use in a VectorBT Pro Backtesting project. We will use a nodeJS package called</p>]]></description><link>http://localhost:2368/multi_asset_data_acquisition/</link><guid isPermaLink="false">643c151fe770773c74f2e603</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[data acquisition]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Sun, 22 Jan 2023 17:27:21 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1641932973980-3dce5f65c5b8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDg0fHxmb3JleHxlbnwwfHx8fDE2NzQ0MDc4MTQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1641932973980-3dce5f65c5b8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDg0fHxmb3JleHxlbnwwfHx8fDE2NzQ0MDc4MTQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - MultiAsset Data Acquisition"><p>In this tutorial, we will talk about the acquisition of M1 (1 minute) data for various <strong>forex currency pairs</strong> from <code>dukascopy</code> (a free data provider).The acquired data will be saved to a <code>.hdf</code> file for use in a VectorBT Pro Backtesting project. We will use a nodeJS package called <code>Dukascopy-node</code> to download M1 (1 minute) historical data for the following currency pairs.<br></p>
<p>You can find the installation instructions and other details for this node package here: <a href="https://github.com/Leo4815162342/dukascopy-node">https://github.com/Leo4815162342/dukascopy-node</a></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="multi-asset-market-data-acquistion-with-dukascopy">Multi Asset Market Data Acquistion with DukaScopy</h2>
<pre><code class="language-shell">npx dukascopy-node -i gbpaud -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i gbpaud -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i eurgbp -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i eurgbp -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i gbpjpy -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i gbpjpy -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i usdjpy -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i usdjpy -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i usdcad -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i usdcad -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i eurusd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i eurusd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i audusd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i audusd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv

npx dukascopy-node -i gbpusd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
npx dukascopy-node -i gbpusd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>The acquired <code>bid</code> and <code>ask</code> files need to be averaged to get normalized 1 min data and finally saved into a <code>hdf</code> (.h5) file. The code for these processes is as follows:</p>
<pre><code class="language-python">def read_bid_ask_data(ask_file : str, bid_file : str, set_time_index = False) -&gt; pd.DataFrame:
    &quot;&quot;&quot;Reads and combines the bid &amp; ask csv files of duksascopy historical market data, into a single OHLCV dataframe.&quot;&quot;&quot;
    df_ask = pd.read_csv(ask_file, infer_datetime_format = True)
    df_bid = pd.read_csv(bid_file, infer_datetime_format = True)
    merged_df = pd.merge(df_bid, df_ask, on=&apos;timestamp&apos;, suffixes=(&apos;_ask&apos;, &apos;_bid&apos;))
    merged_df[&apos;open&apos;] = (merged_df[&apos;open_ask&apos;] + merged_df[&apos;open_bid&apos;]) / 2.0
    merged_df[&apos;close&apos;]= (merged_df[&apos;close_ask&apos;] + merged_df[&apos;close_bid&apos;]) / 2.0
    merged_df[&apos;high&apos;] = merged_df[[&apos;high_ask&apos;,&apos;high_bid&apos;]].max(axis=1)
    merged_df[&apos;low&apos;] = merged_df[[&apos;low_ask&apos;,&apos;low_bid&apos;]].max(axis=1)
    merged_df[&apos;volume&apos;] = merged_df[&apos;volume_bid&apos;] + merged_df[&apos;volume_ask&apos;]    

    merged_df = merged_df[merged_df[&quot;volume&quot;] &gt; 0.0].reset_index()
    ## Case when we downloaded Dukascopy historical market data from node package: dukascopy-node
    merged_df[&apos;time&apos;] = pd.to_datetime(merged_df[&apos;timestamp&apos;], unit = &apos;ms&apos;)
    merged_df.drop(columns = [&quot;timestamp&quot;], inplace = True)

    final_cols = [&apos;time&apos;,&apos;open&apos;,&apos;high&apos;,&apos;low&apos;,&apos;close&apos;,&apos;volume&apos;,&apos;volume_bid&apos;,&apos;volume_ask&apos;]

    if set_time_index:
        merged_df[&quot;time&quot;] = pd.to_datetime(merged_df[&quot;time&quot;],format=&apos;%d.%m.%Y %H:%M:%S&apos;)
        merged_df = merged_df.set_index(&quot;time&quot;)
        return merged_df[final_cols[1:]]      
    return merged_df[final_cols].reset_index(drop=True)

## Specify FileNames of Bid / Ask data downloaded from DukaScopy
bid_ask_files = {
    &quot;GBPUSD&quot; : {&quot;Bid&quot;: &quot;gbpusd-m1-bid-2019-01-01-2023-01-13.csv&quot;,
                &quot;Ask&quot;: &quot;gbpusd-m1-ask-2019-01-01-2023-01-13.csv&quot;},
    &quot;EURUSD&quot; : {&quot;Bid&quot;: &quot;eurusd-m1-bid-2019-01-01-2023-01-13.csv&quot;,
                &quot;Ask&quot;: &quot;eurusd-m1-ask-2019-01-01-2023-01-13.csv&quot;},
    &quot;AUDUSD&quot; : {&quot;Bid&quot;: &quot;audusd-m1-bid-2019-01-01-2023-01-13.csv&quot;,
                &quot;Ask&quot;: &quot;audusd-m1-ask-2019-01-01-2023-01-13.csv&quot;},
    &quot;USDCAD&quot; : {&quot;Bid&quot;: &quot;usdcad-m1-bid-2019-01-01-2023-01-13.csv&quot;,
                &quot;Ask&quot;: &quot;usdcad-m1-ask-2019-01-01-2023-01-13.csv&quot;},
    &quot;USDJPY&quot; : {&quot;Bid&quot;: &quot;usdjpy-m1-bid-2019-01-01-2023-01-13.csv&quot;,
                &quot;Ask&quot;: &quot;usdjpy-m1-ask-2019-01-01-2023-01-13.csv&quot;},
    &quot;GBPJPY&quot; : {&quot;Bid&quot;: &quot;gbpjpy-m1-bid-2019-01-01-2023-01-13.csv&quot;,
                &quot;Ask&quot;: &quot;gbpjpy-m1-ask-2019-01-01-2023-01-13.csv&quot;},
    &quot;EURGBP&quot; : {&quot;Bid&quot;: &quot;eurgbp-m1-bid-2019-01-01-2023-01-16.csv&quot;,
                &quot;Ask&quot;: &quot;eurgbp-m1-ask-2019-01-01-2023-01-16.csv&quot;},
    &quot;GBPAUD&quot; : {&quot;Bid&quot;: &quot;gbpaud-m1-bid-2019-01-01-2023-01-16.csv&quot;,
                &quot;Ask&quot;: &quot;gbpaud-m1-ask-2019-01-01-2023-01-16.csv&quot;}                                                                           
}

## Write everything into one single HDF5 file indexed by keys for the various symbols
source_folder_path = &quot;/Users/John.Doe/Documents/Dukascopy_Historical_Data/&quot;
output_file_path = &quot;/Users/John.Doe/Documents/qqblog_vbt_pro_tutorials/data/MultiAsset_OHLCV_3Y_m1.h5&quot;

for symbol in bid_ask_files.keys():
    print(f&apos;\n{symbol}&apos;)
    ask_csv_file = source_folder_path + bid_ask_files[symbol][&quot;Ask&quot;]
    bid_csv_file = source_folder_path + bid_ask_files[symbol][&quot;Bid&quot;]
    print(&quot;ASK File PATH:&quot;,ask_csv_file,&apos;\nBID File PATH:&apos;,bid_csv_file)
    df = read_bid_ask_data(ask_csv_file, bid_csv_file, set_time_index = True)
    df.to_hdf(output_file_path, key=symbol)

</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><strong>Output</strong></p>
<pre><code class="language-python">GBPUSD
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/gbpusd-m1-ask-2019-01-01-2023-01-13.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/gbpusd-m1-bid-2019-01-01-2023-01-13.csv

EURUSD
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/eurusd-m1-ask-2019-01-01-2023-01-13.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/eurusd-m1-bid-2019-01-01-2023-01-13.csv

AUDUSD
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/audusd-m1-ask-2019-01-01-2023-01-13.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/audusd-m1-bid-2019-01-01-2023-01-13.csv

USDCAD
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/usdcad-m1-ask-2019-01-01-2023-01-13.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/usdcad-m1-bid-2019-01-01-2023-01-13.csv

USDJPY
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/usdjpy-m1-ask-2019-01-01-2023-01-13.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/usdjpy-m1-bid-2019-01-01-2023-01-13.csv

GBPJPY
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/gbpjpy-m1-ask-2019-01-01-2023-01-13.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/gbpjpy-m1-bid-2019-01-01-2023-01-13.csv

EURGBP
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/eurgbp-m1-ask-2019-01-01-2023-01-16.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/eurgbp-m1-bid-2019-01-01-2023-01-16.csv

GBPAUD
ASK File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/gbpaud-m1-ask-2019-01-01-2023-01-16.csv 
BID File PATH: /Users/john.doe/Documents/Dukascopy_Historical_Data/gbpaud-m1-bid-2019-01-01-2023-01-16.csv
</code></pre>
<!--kg-card-end: markdown--><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><strong>Note</strong>: The free M1 data, provided by Dukascopy has some missing data and one needs to validate the data quality by comparing it with other preferable paid data sources.</div></div><!--kg-card-begin: markdown--><h2 id="binance-crypto-data">Binance Crypto Data</h2>
<p>For the crypto fans VectorBT directly provides a wrapper to fetch data from <code>Binance</code><br></p>
<pre><code class="language-python">## Acquire multi-asset 1m crypto data from Binance

data = vbt.BinanceData.fetch(
    [&quot;BTCUSDT&quot;, &quot;ETHUSDT&quot;, &quot;BNBUSDT&quot;, &quot;XRPUSDT&quot;, &quot;ADAUSDT&quot;], 
    start=&quot;2019-01-01 UTC&quot;, 
    end=&quot;2022-12-01 UTC&quot;,
    timeframe=&quot;1m&quot;
    )

## Save acquired data locally for persistance
data.to_hdf(&quot;/Users/john.doe/Documents/vbtpro_tuts_private/data/Binance_MultiAsset_OHLCV_3Y_m1.h5&quot;)
</code></pre>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - MultiAsset Portfolio Simulation]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>In this tutorial, we will talk about verious topics pertaining to Multi Asset Portfolio Simulation, beginning with</p>
<ul>
<li>Converting various forex (FX) pairs to the account currency, if the quote currency of the currency pair is not the same as the account currency.</li>
<li>Running different types of backtesting simulations like <code>grouped</code></li></ul>]]></description><link>http://localhost:2368/multi_asset_portfolio_simulation/</link><guid isPermaLink="false">643c151fe770773c74f2e602</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[multi-asset]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Sun, 22 Jan 2023 16:50:48 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1651341050677-24dba59ce0fd?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxUcmFkaW5nJTIwUG9ydGZvbGlvfGVufDB8fHx8MTY3NDQ4MjYxNg&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1651341050677-24dba59ce0fd?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxUcmFkaW5nJTIwUG9ydGZvbGlvfGVufDB8fHx8MTY3NDQ4MjYxNg&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - MultiAsset Portfolio Simulation"><p>In this tutorial, we will talk about verious topics pertaining to Multi Asset Portfolio Simulation, beginning with</p>
<ul>
<li>Converting various forex (FX) pairs to the account currency, if the quote currency of the currency pair is not the same as the account currency.</li>
<li>Running different types of backtesting simulations like <code>grouped</code>, <code>unified</code> and <code>discrete</code> using <code>vbt.Portfolio.from_signals()</code> , and</li>
<li>Finally, exporting data to <code>.pickle</code> files for plotting and visualizing in an interactive plotly dashboard.</li>
</ul>
<blockquote>
<p>Before proceeding further, you would want to read this <a href="https://qubitquants.github.io/multi_asset_data_acquisition/index.html">short helper tutorial</a> about multi-asset data acquisition which explains how we created the below <code>MultiAsset_OHLCV_3Y_m1.h5</code> file, which we load into <code>hdf_data</code></p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Here, we will run the <code>Double Bollinger Band Strategy</code> from our earlier tutorial on multiple assets. But before we do that, we have to bring the quote value of all our forex currency pairs to the account currency (<code>USD</code>).</p>
<pre><code class="language-python">## Import Libraries
import numpy as np
import pandas as pd
import vectorbtpro as vbt

## Forex Data
hdf_data = vbt.HDFData.fetch(&apos;/Users/dilip.rajkumar/Documents/vbtpro_tuts_private/data/MultiAsset_OHLCV_3Y_m1.h5&apos;) 
symbols = hdf_data.symbols
print(&apos;Multi-Asset DataFrame Symbols:&apos;,symbols)
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-python">Multi-Asset DataFrame Symbols: [&apos;AUDUSD&apos;, &apos;EURGBP&apos;, &apos;EURUSD&apos;, &apos;GBPAUD&apos;, &apos;GBPJPY&apos;, &apos;GBPUSD&apos;, &apos;USDCAD&apos;, &apos;USDJPY&apos;]
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="convert-fx-pairs-where-quotecurrency-account-currency-us">Convert FX pairs where <code>quote_currency != account currency</code> ( US$ )</h3>
<p>We will be converting <code>OHLC</code> price columns for the following currency pairs to the account currency (USD), as in these pairs either the <code>quote currency</code>  or both the <code>base currency</code> &amp; <code>quote currency</code> are not the same as the <code>account currency</code> which in our requirement is USD.</p>
<pre><code class="language-python">price_cols = [&quot;Open&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Close&quot;]
symbols_to_convert = [&quot;USDJPY&quot;, &quot;USDCAD&quot;, &quot;GBPJPY&quot;, &quot;EURGBP&quot;, &quot;GBPAUD&quot;]
</code></pre>
<p>For this currency conversion of price data, we will use this <code>convert_to_account_currency</code> function, which handles the following scenarios, where the <code>quote currency</code> is not the same as <code>account currency</code>:<br><br>
<strong>1.) Base currency == Account currency</strong> : <br><br>
In this case, we simply inverse the price of the instrument. For eg: in the case of USDJPY the quote currency is JPY, but the base currency is the same as the account currency (USD). So in order to get the price of USDJPY in USD all we have to do is compute <code>1 / USDJPY</code>.</p>
<p><strong>2.) Both (Base Currency &amp; Quote Currency ) != Account Currency</strong> : <br><br>
This scenario occurs when we basically don&apos;t see the account currency characters in the source forex currency pair symbol (Eg: GBPJPY) and in order to convert this kind of currency pair to the account currency we require a <code>bridge currency pair</code>. Now depending on how the bridge pair symbol is presented in the market data provided by the exchange, we would be either dividing or multiplying the source currency pair by the bridge pair. For eg:<br><br>
a.) In the case of converting <code>GBPJPY</code> to USD, we would be dividing <code>GBPJPY / USDJPY</code> <br><br>
b.) In the case of converting <code>GBPAUD</code> to USD, the exchange typically provides the bridge currency pair data required as <code>AUDUSD</code> and not <code>USDAUD</code> and so in this case, we would be multiplying <code>GBPAUD * AUDUSD</code>.</p>
<pre><code class="language-python">def convert_to_account_currency(price_data : pd.Series, account_currency : str = &quot;USD&quot;,
                                bridge_pair_price_data: pd.Series = None) -&gt; pd.Series:
    &quot;&quot;&quot;
    Convert prices of different FX pairs to account currency.

    Parameters
    ==========
    price_data      :   pd.Series, Price data from (OHLC) columns of the pair to be converted
    account_currency:   str, default = &apos;USD&apos;
    bridge_pair_price_data: pd.Series, price data to be used when neither,
                            the base or quote currency is = account currency
    
    Returns
    =======
    new_instrument_price : pd.Series, converted price data

    &quot;&quot;&quot;
    symbol = price_data.name
    base_currency  = symbol[0:3].upper()
    quote_currency = symbol[3:6].upper() ## a.k.a Counter_currency

    if base_currency == account_currency: ## case 1  - Eg: USDJPY
        print(f&quot;BaseCurrency: {base_currency} is same as AccountCurrency: {account_currency} for Symbol:- {symbol}.&quot;+ \
              &quot;Performing price inversion&quot;)
        new_instrument_price = (1/price_data)

    elif (quote_currency != account_currency) and (base_currency != account_currency): ## Case 2 - Eg: GBPJPY  
        bridge_pair_symbol =  account_currency + quote_currency  ## Bridge Pair symbol is : USDJPY
        print(f&quot;Applying currency conversion for {symbol} with {bridge_pair_symbol} price data&quot;)
        if (bridge_pair_price_data is None):
            raise Exception(f&quot;Price data for {bridge_pair_symbol} is missing. Please provide the same&quot;)
        elif (bridge_pair_symbol != bridge_pair_price_data.name.upper()):
            message = f&quot;Mismatched data. Price data for {bridge_pair_symbol} is expected, but&quot; + \
                      f&quot;{bridge_pair_price_data.name.upper()} price data is provided&quot;
            print(message) ## Eg: When AUDUSD is required, but instead USDAUD is provided
            new_instrument_price = price_data * bridge_pair_price_data
            # raise Exception(message)
        else:
            new_instrument_price = price_data/ bridge_pair_price_data ## Divide GBPJPY / USDJPY
    
    else:
        print(f&quot;No currency conversion needed for {symbol} as QuoteCurreny: {quote_currency} == Account Currency&quot;)
        new_instrument_price = price_data
    return new_instrument_price
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We copy the data from the original <code>hdf_data</code> file and store them in a dictionary of dataframes. For symbols whose price columns are to be converted we create an empty <code>pd.DataFrame</code> which we will be filling with the converted price values</p>
<pre><code class="language-python">new_data = {}
for symbol, df in hdf_data.data.items():
    if symbol in symbols_to_convert: ## symbols whose price columns needs to be converted to account currency
        new_data[symbol] = pd.DataFrame(columns=[&apos;Open&apos;,&apos;High&apos;,&apos;Low&apos;,&apos;Close&apos;,&apos;Volume&apos;])
    else: ## for other symbols store the data as it is
        new_data[symbol] = df
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Here we call our <code>convert_to_account_currency()</code> function to convert the price data to account cuurency. For pairs like <code>USDJPY</code> and <code>USDCAD</code> a simple price inversion (Eg: <code>1 / USDJPY</code> ) alone is sufficient, so for these cases we will be setting <code>bridge_pair == None</code>.</p>
<pre><code class="language-python">bridge_pairs = [None, None, &quot;USDJPY&quot;, &quot;GBPUSD&quot;, &quot;AUDUSD&quot;]

for ticker_source, ticker_bridge  in zip(symbols_to_convert, bridge_pairs):
    new_data[ticker_source][&quot;Volume&quot;] = hdf_data.get(&quot;Volume&quot;)[ticker_source]
    for col in price_cols:
        print(&quot;Source Symbol:&quot;, ticker_source, &quot;|| Bridge Pair:&quot;, ticker_bridge, &quot;|| Column:&quot;, col)
        new_data[ticker_source][col] = convert_to_account_currency( 
                            price_data =  hdf_data.get(col)[ticker_source],
                            bridge_pair_price_data = None  if ticker_bridge is None else hdf_data.get(col)[ticker_bridge]
                            )
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="ensuring-correct-data-for-high-and-low-columns">Ensuring Correct data for <code>High</code> and <code>Low</code> columns</h3>
<p>Once we have the converted OHLC price columns for a particular symbol (<code>ticker_source</code>), we recalculate the <code>High</code> and <code>Low</code> by getting the <code>max</code> and <code>min</code> of each row in the OHLC columns respectively using <code>df.max(axis=1)</code> and <code>df.min(axis=1)</code></p>
<pre><code class="language-python">## Converts this `new_data` (dict of dataframes) into a vbt.Data object
m1_data = vbt.Data.from_data(new_data)    

for ticker_source in symbols:
    m1_data.data[ticker_source][&apos;High&apos;] = m1_data.data[ticker_source][price_cols].max(axis=1)
    m1_data.data[ticker_source][&apos;Low&apos;] = m1_data.data[ticker_source][price_cols].min(axis=1)
</code></pre>
<p><strong>What need is there for above step?</strong> <br><br>
Lets assume for a symbol <code>X</code> if low is 10 and high is 20, then when we do a simple price inversion ( <code>1/X</code> ) new high would become <code>1/10 = 0.1</code> and new low would become <code>1/20 = 0.05</code> which will result in complications and thus arises the need for the above step</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Sanity check to see if empty pd.DataFrame got filled now
m1_data.data[&apos;EURGBP&apos;].dropna()
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/EURGBP_Sanity_Check.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="1048" height="638" srcset="http://localhost:2368/content/images/size/w600/2023/01/EURGBP_Sanity_Check.png 600w, http://localhost:2368/content/images/size/w1000/2023/01/EURGBP_Sanity_Check.png 1000w, http://localhost:2368/content/images/2023/01/EURGBP_Sanity_Check.png 1048w" sizes="(min-width: 720px) 720px"><figcaption>M1 data of EURGBP after dropping NaN rows</figcaption></figure><!--kg-card-begin: markdown--><h2 id="double-bollinger-band-strategy-over-multi-asset-portfolio">Double Bollinger Band Strategy over Multi-Asset portfolio</h2>
<p>The following steps are very similar we already saw in the <a href="https://qubitquants.pro/aligning-mtf-data/index.html">Alignment and Resampling</a> and <a href="https://qubitquants.pro/strategydev/index.html">Strategy Development</a> tutorials, except now they are applied over multiple symbols (assets) in a portfolio. So I will just put the code here and won&apos;t be explaining anything here in detail, when in doubt refer back to the above two tutorials.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">m15_data = m1_data.resample(&apos;15T&apos;)  # Convert 1 minute to 15 mins
h1_data = m1_data.resample(&quot;1h&quot;)    # Convert 1 minute to 1 hour
h4_data = m1_data.resample(&apos;4h&apos;)    # Convert 1 minute to 4 hour

# Obtain all the required prices using the .get() method
m15_close = m15_data.get(&apos;Close&apos;)

## h1 data
h1_open  = h1_data.get(&apos;Open&apos;)
h1_close = h1_data.get(&apos;Close&apos;)
h1_high  = h1_data.get(&apos;High&apos;)
h1_low   = h1_data.get(&apos;Low&apos;)

## h4 data
h4_open  = h4_data.get(&apos;Open&apos;)
h4_close = h4_data.get(&apos;Close&apos;)
h4_high  = h4_data.get(&apos;High&apos;)
h4_low   = h4_data.get(&apos;Low&apos;)

### Create (manually) the indicators for Multi-Time Frames
rsi_period = 21

## 15m indicators
m15_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = rsi_period).run(m15_close, skipna=True).real.ffill()
m15_bbands = vbt.talib(&quot;BBANDS&quot;).run(m15_close, skipna=True)
m15_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(m15_rsi, skipna=True)

## h1 indicators
h1_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = rsi_period).run(h1_close, skipna=True).real.ffill()
h1_bbands = vbt.talib(&quot;BBANDS&quot;).run(h1_close, skipna=True)
h1_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(h1_rsi, skipna=True)

## h4 indicators
h4_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = rsi_period).run(h4_close, skipna=True).real.ffill()
h4_bbands = vbt.talib(&quot;BBANDS&quot;).run(h4_close, skipna=True)
h4_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(h4_rsi, skipna=True)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">def create_resamplers(result_dict_keys_list : list, source_indices : list,  
                      source_frequencies :list, target_index : pd.Series, target_freq : str):
    &quot;&quot;&quot;
    Creates a dictionary of vbtpro resampler objects.

    Parameters
    ==========
    result_dict_keys_list : list, list of strings, which are keys of the output dictionary
    source_indices        : list, list of pd.time series objects of the higher timeframes
    source_frequencies    : list(str), which are short form representation of time series order. Eg:[&quot;1D&quot;, &quot;4h&quot;]
    target_index          : pd.Series, target time series for the resampler objects
    target_freq           : str, target time frequency for the resampler objects

    Returns
    ===========
    resamplers_dict       : dict, vbt pro resampler objects
    &quot;&quot;&quot;
    
    
    resamplers = []
    for si, sf in zip(source_indices, source_frequencies):
        resamplers.append(vbt.Resampler(source_index = si,  target_index = target_index,
                                        source_freq = sf, target_freq = target_freq))
    return dict(zip(result_dict_keys_list, resamplers))
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Initialize  dictionary
mtf_data = {}

col_values = [
    m15_close, m15_rsi, m15_bbands.upperband, m15_bbands.middleband, m15_bbands.lowerband, 
    m15_bbands_rsi.upperband, m15_bbands_rsi.middleband, m15_bbands_rsi.lowerband
    ]

col_keys = [
    &quot;m15_close&quot;, &quot;m15_rsi&quot;, &quot;m15_bband_price_upper&quot;,  &quot;m15_bband_price_middle&quot;, &quot;m15_bband_price_lower&quot;, 
    &quot;m15_bband_rsi_upper&quot;,  &quot;m15_bband_rsi_middle&quot;, &quot;m15_bband_rsi_lower&quot;
         ]

# Assign key, value pairs for method of time series data to store in data dict
for key, time_series in zip(col_keys, col_values):
    mtf_data[key] = time_series.ffill()

## Create Resampler Objects for upsampling
src_indices = [h1_close.index, h4_close.index]
src_frequencies = [&quot;1H&quot;,&quot;4H&quot;] 
resampler_dict_keys = [&quot;h1_m15&quot;,&quot;h4_m15&quot;]

list_resamplers = create_resamplers(resampler_dict_keys, src_indices, src_frequencies, m15_close.index, &quot;15T&quot;)

## Use along with  Manual indicator creation method for MTF
series_to_resample = [
    [h1_open, h1_high, h1_low, h1_close, h1_rsi, h1_bbands.upperband, h1_bbands.middleband, h1_bbands.lowerband,
     h1_bbands_rsi.upperband, h1_bbands_rsi.middleband, h1_bbands_rsi.lowerband], 
    [h4_high, h4_low, h4_close, h4_rsi, h4_bbands.upperband, h4_bbands.middleband, h4_bbands.lowerband, 
    h4_bbands_rsi.upperband, h4_bbands_rsi.middleband, h4_bbands_rsi.lowerband]
    ]


data_keys = [
    [&quot;h1_open&quot;,&quot;h1_high&quot;, &quot;h1_low&quot;, &quot;h1_close&quot;, &quot;h1_rsi&quot;, &quot;h1_bband_price_upper&quot;,  &quot;h1_bband_price_middle&quot;,  &quot;h1_bband_price_lower&quot;, 
     &quot;h1_bband_rsi_upper&quot;,  &quot;h1_bband_rsi_middle&quot;, &quot;h1_bband_rsi_lower&quot;],
    [&quot;h4_open&quot;,&quot;h4_high&quot;, &quot;h4_low&quot;, &quot;h4_close&quot;, &quot;h4_rsi&quot;, &quot;h4_bband_price_upper&quot;,  &quot;h4_bband_price_middle&quot;,  &quot;h4_bband_price_lower&quot;, 
     &quot;h4_bband_rsi_upper&quot;,  &quot;h4_bband_rsi_middle&quot;, &quot;h4_bband_rsi_lower&quot;]
         ]

for lst_series, lst_keys, resampler in zip(series_to_resample, data_keys, resampler_dict_keys):
    for key, time_series in zip(lst_keys, lst_series):
        if key.lower().endswith(&apos;open&apos;):
            print(f&apos;Resampling {key} differently using vbt.resample_opening using &quot;{resampler}&quot; resampler&apos;)
            resampled_time_series = time_series.vbt.resample_opening(list_resamplers[resampler])
        else:
            resampled_time_series = time_series.vbt.resample_closing(list_resamplers[resampler])
        mtf_data[key] = resampled_time_series

cols_order = [&apos;m15_close&apos;, &apos;m15_rsi&apos;, &apos;m15_bband_price_upper&apos;,&apos;m15_bband_price_middle&apos;, &apos;m15_bband_price_lower&apos;,
              &apos;m15_bband_rsi_upper&apos;,&apos;m15_bband_rsi_middle&apos;, &apos;m15_bband_rsi_lower&apos;,
              &apos;h1_open&apos;, &apos;h1_high&apos;, &apos;h1_low&apos;, &apos;h1_close&apos;, &apos;h1_rsi&apos;,
              &apos;h1_bband_price_upper&apos;, &apos;h1_bband_price_middle&apos;, &apos;h1_bband_price_lower&apos;, 
              &apos;h1_bband_rsi_upper&apos;, &apos;h1_bband_rsi_middle&apos;, &apos;h1_bband_rsi_lower&apos;,              
              &apos;h4_open&apos;, &apos;h4_high&apos;, &apos;h4_low&apos;, &apos;h4_close&apos;, &apos;h4_rsi&apos;,
              &apos;h4_bband_price_upper&apos;, &apos;h4_bband_price_middle&apos;, &apos;h4_bband_price_lower&apos;, 
              &apos;h4_bband_rsi_upper&apos;, &apos;h4_bband_rsi_middle&apos;, &apos;h4_bband_rsi_lower&apos;
              ]                 
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="double-bollinger-bandstrategy-conditions">Double Bollinger Band - Strategy Conditions</h3>
<pre><code class="language-python">required_cols = [&apos;m15_close&apos;,&apos;m15_rsi&apos;,&apos;m15_bband_rsi_lower&apos;, &apos;m15_bband_rsi_upper&apos;,
                 &apos;h4_low&apos;, &quot;h4_rsi&quot;, &quot;h4_bband_price_lower&quot;, &quot;h4_bband_price_upper&quot; ]

## Higher values greater than 1.0 are like moving up the lower RSI b-band, 
## signifying if the lowerband rsi is anywhere around 1% of the lower b-band validate that case as True
bb_upper_fract = 0.99
bb_lower_fract = 1.01

## Long Entry Conditions
# c1_long_entry = (mtf_data[&apos;h1_low&apos;] &lt;= mtf_data[&apos;h1_bband_price_lower&apos;])
c1_long_entry = (mtf_data[&apos;h4_low&apos;] &lt;= mtf_data[&apos;h4_bband_price_lower&apos;])
c2_long_entry = (mtf_data[&apos;m15_rsi&apos;] &lt;= (bb_lower_fract * mtf_data[&apos;m15_bband_rsi_lower&apos;]) )


## Long Exit Conditions
# c1_long_exit =  (mtf_data[&apos;h1_high&apos;] &gt;= mtf_data[&apos;h1_bband_price_upper&apos;])
c1_long_exit = (mtf_data[&apos;h4_high&apos;] &gt;= mtf_data[&apos;h4_bband_price_upper&apos;])
c2_long_exit = (mtf_data[&apos;m15_rsi&apos;] &gt;= (bb_upper_fract * mtf_data[&apos;m15_bband_rsi_upper&apos;]))       

## Strategy conditions check - Using m15 and h4 data 
mtf_data[&apos;entries&apos;] = c1_long_entry &amp; c2_long_entry
mtf_data[&apos;exits&apos;]  = c1_long_exit &amp; c2_long_exit

mtf_data[&apos;signal&apos;] = 0   
mtf_data[&apos;signal&apos;] = np.where( mtf_data[&apos;entries&apos;], 1, 0)
mtf_data[&apos;signal&apos;] = np.where( mtf_data[&apos;exits&apos;] , -1, mtf_data[&apos;signal&apos;])
</code></pre>
<p>After the above <code>np.where</code>, we can use this <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html"><code>pd.df.where</code></a> to return a pandas object</p>
<pre><code class="language-python">mtf_data[&apos;signal&apos;] = mtf_data[&apos;entries&apos;].vbt.wrapper.wrap(mtf_data[&apos;signal&apos;])
mtf_data[&apos;signal&apos;] = mtf_data[&apos;exits&apos;].vbt.wrapper.wrap(mtf_data[&apos;signal&apos;])
print(mtf_data[&apos;signal&apos;])
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/Mtf_DF_signals_column.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="1446" height="670" srcset="http://localhost:2368/content/images/size/w600/2023/01/Mtf_DF_signals_column.png 600w, http://localhost:2368/content/images/size/w1000/2023/01/Mtf_DF_signals_column.png 1000w, http://localhost:2368/content/images/2023/01/Mtf_DF_signals_column.png 1446w" sizes="(min-width: 720px) 720px"><figcaption><code>Signal</code> Column for Multiple Forex Pair Symbols</figcaption></figure><!--kg-card-begin: markdown--><h3 id="cleaning-and-resampling-entries-and-exits">Cleaning and Resampling <code>entries</code> and <code>exits</code></h3>
<pre><code class="language-python">entries = mtf_data[&apos;signal&apos;] == 1.0
exits = mtf_data[&apos;signal&apos;] == -1.0

## Clean redundant and duplicate signals
clean_entries, clean_exits = entries.vbt.signals.clean(exits)
print(f&quot;Total nr. of Signals in Clean_Entries and Clean_Exits&quot;)
pd.DataFrame(data = {&quot;Entries&quot;:clean_entries.vbt.signals.total(),
                    &quot;Exits&quot;: clean_exits.vbt.signals.total()})
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/CleanEntries_Exits_M15.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="774" height="520" srcset="http://localhost:2368/content/images/size/w600/2023/01/CleanEntries_Exits_M15.png 600w, http://localhost:2368/content/images/2023/01/CleanEntries_Exits_M15.png 774w" sizes="(min-width: 720px) 720px"><figcaption>Symbol-wise Number of Entries and Exits on M15 timeframe</figcaption></figure><!--kg-card-begin: markdown--><p>We can resample the entries and exits for plotting purposes on H4 chart, but this always produces some loss in the nr. of signals as the entries / exits in our strategy is based on <code>M15</code> timeframe. So just be aware of this.</p>
<pre><code class="language-python">## Resample clean entries to H4 timeframe
clean_h4_entries = clean_entries.vbt.resample_apply(&quot;4h&quot;, &quot;any&quot;, wrap_kwargs=dict(dtype=bool))
clean_h4_exits = clean_exits.vbt.resample_apply(&quot;4h&quot;, &quot;any&quot;, wrap_kwargs=dict(dtype=bool))

print(f&quot;Total nr. of H4_Entry Signals:\n {clean_h4_entries.vbt.signals.total()}\n&quot;)
print(f&quot;Total nr. of H4_Exit Signals:\n {clean_h4_exits.vbt.signals.total()}&quot;)
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/CleanEntries_Exits_H4_Resampled.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="822" height="518" srcset="http://localhost:2368/content/images/size/w600/2023/01/CleanEntries_Exits_H4_Resampled.png 600w, http://localhost:2368/content/images/2023/01/CleanEntries_Exits_H4_Resampled.png 822w" sizes="(min-width: 720px) 720px"><figcaption>Symbol-wise Number of Entries and Exits on H4 timeframe</figcaption></figure><!--kg-card-begin: markdown--><h3 id="saving-data-to-pickle-file">Saving Data to <code>.pickle</code> file</h3>
<p>For the purposes of plotting, we will be saving various data like:</p>
<ul>
<li>price data across various timeframes</li>
<li>indicator data across various timeframes</li>
<li>entries &amp; exits</li>
<li>finally, the <code>vectorbt.portfolio</code> objects after running each type of portfolio simulation</li>
</ul>
<pre><code class="language-python">## Save Specific Data to pickle file for plotting purposes
price_data = {&quot;h4_data&quot;: h4_data, &quot;m15_data&quot; : m15_data}
vbt_indicators = {&apos;m15_rsi&apos;: m15_rsi,&apos;m15_price_bbands&apos;: m15_bbands, &apos;m15_rsi_bbands&apos; : m15_bbands_rsi,
                  &apos;h4_rsi&apos;: h4_rsi, &apos;h4_price_bbands&apos;:h4_bbands, &apos;h4_rsi_bbands&apos; : h4_bbands_rsi}

entries_exits_data = {&apos;clean_entries&apos; : clean_entries, &apos;clean_exits&apos; : clean_exits}

print(type(h4_data), &apos;||&apos; ,type(m15_data))
print(type(h4_bbands), &apos;||&apos;, type(h4_bbands_rsi), &apos;||&apos;, type(h1_rsi))
print(type(m15_bbands), &apos;||&apos;, type(m15_bbands_rsi), &apos;||&apos;, type(m15_rsi))

file_path1 = &apos;../vbt_dashboard/data/price_data&apos;
file_path2 = &apos;../vbt_dashboard/data/indicators_data&apos;
file_path3 = &apos;../vbt_dashboard/data/entries_exits_data&apos;


vbt.save(price_data, file_path1)
vbt.save(vbt_indicators, file_path2)
vbt.save(entries_exits_data, file_path3)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="multi-asset-portfolio-backtesting-simulation-using-vbtportfoliofromsignals">Multi-asset Portfolio Backtesting simulation using <code>vbt.Portfolio.from_signals()</code></h2>
<p>In this section, we will see different ways to run this <code>portfolio.from_signals()</code> simulation and save the results as <code>.pickle</code> files to be used in a <code>plotly-dash</code> data visualization dashboard later (in another tutorial).</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="1-asset-wise-discrete-portfolio-simulation">1.) Asset-wise Discrete Portfolio Simulation</h2>
<p>In this section we will see how to run the portfolio simulation for each asset in the portfolio independently. If we start with the default <code>from_signals()</code> function as we had from the <a href="https://qubitquants.pro/strategydev/index.html">previous tutorial</a>, the simulation is run for each symbol independently, which means the account balance is not connected between the various trades executed across symbols</p>
<pre><code class="language-python">pf_from_signals_v1 = vbt.Portfolio.from_signals(
    close = mtf_data[&apos;m15_close&apos;], 
    entries = mtf_data[&apos;entries&apos;], 
    exits = mtf_data[&apos;exits&apos;], 
    direction = &quot;both&quot;, ## This setting trades both long and short signals
    freq = pd.Timedelta(minutes=15), 
    init_cash = 100000
)

## Save portfolio simulation as a pickle file
pf_from_signals_v1.save(&quot;../vbt_dashboard/data/pf_sim_discrete&quot;)

## Load saved portfolio simulation from pickle file
pf = vbt.Portfolio.load(&apos;../vbt_dashboard/data/pf_sim_discrete&apos;)

## View Trading History of pf.simulation 
pf_trade_history = pf.trade_history
print(&quot;Unique Symbols:&quot;, list(pf_trade_history[&apos;Column&apos;].unique()) )
pf_trade_history
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/pf1_discrete_trade_history.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="2000" height="768" srcset="http://localhost:2368/content/images/size/w600/2023/01/pf1_discrete_trade_history.png 600w, http://localhost:2368/content/images/size/w1000/2023/01/pf1_discrete_trade_history.png 1000w, http://localhost:2368/content/images/size/w1600/2023/01/pf1_discrete_trade_history.png 1600w, http://localhost:2368/content/images/size/w2400/2023/01/pf1_discrete_trade_history.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Trade History for Portfolio Simulation Object</figcaption></figure><!--kg-card-begin: markdown--><p>We can view the portfolio simulation statistics as a dataframe by running the following code snippet</p>
<pre><code class="language-python">## View Portfolio Stats as a dataframe for pf_from_signals_v1 case
## pd.concat() operation concates the stats information acosss all assets
stats_df = pd.concat([pf.stats()] + [pf[symbol].stats() for symbol in symbols], axis = 1)
## Remove microsend level granularity information in TimeDelta Object
stats_df.loc[&apos;Avg Winning Trade Duration&apos;] = [x.floor(&apos;s&apos;) for x in stats_df.iloc[21]] 
stats_df.loc[&apos;Avg Losing Trade Duration&apos;] = [x.floor(&apos;s&apos;) for x in stats_df.iloc[22]]
stats_df = stats_df.reset_index() 
stats_df.rename(inplace = True, columns = {&apos;agg_stats&apos;:&apos;Agg_Stats&apos;, &apos;index&apos; : &apos;Metrics&apos; })  
stats_df
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/pf1_Stats.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="2000" height="957" srcset="http://localhost:2368/content/images/size/w600/2023/01/pf1_Stats.png 600w, http://localhost:2368/content/images/size/w1000/2023/01/pf1_Stats.png 1000w, http://localhost:2368/content/images/size/w1600/2023/01/pf1_Stats.png 1600w, http://localhost:2368/content/images/size/w2400/2023/01/pf1_Stats.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Symbol-wise Simulation Statistics&#xA0;</figcaption></figure><!--kg-card-begin: markdown--><p>The <code>Agg_Stats</code> column is basically the metrics aggregated across the various symbols which you can validate by running the following code and comparing the output with the above dataframe print out</p>
<pre><code class="language-python">print(&quot;Mean Total Return [%] (across cols):&quot;, np.round(np.mean(stats_df.iloc[[7]].values.tolist()[0][1:]), 4) )
print(&quot;Mean Total Orders (across cols):&quot;, np.round(np.mean(stats_df.iloc[[13]].values.tolist()[0][1:]), 4) )
print(&quot;Mean Sortino Ratio (across cols):&quot;, np.round(np.mean(stats_df.iloc[[28]].values.tolist()[0][1:]), 4) )
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-python">Mean Total Return [%] (across cols): 0.3675
Mean Total Orders (across cols): 479.125
Mean Sortino Ratio (across cols): 0.1084
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="description-of-a-few-parameter-settings-for-pffromsignals">Description of a few Parameter settings for <code>pf.from_signals()</code></h3>
<p>We will see a short description of the new parameters of <code>vbt.Portfolio.from_signals()</code> function which we will be using henceforth in the rest of this tutorial. <br> But I would like to point out that the <code>from_signals()</code> function in VectorBT Pro is very exhaustive in its capabilities and feature set, thus it is beyond the scope of this blog post to cover every parameter of this function along with multitude of settings. So please refer the documentation for this. <br><br><br>
<strong>a.)</strong> <code>size</code> : Specifies the position size in units. For any fixed size, you can set to any number to buy/sell some fixed amount or value. For any target size, you can set to any number to buy/sell an amount relative to the current position or value. If you set this to <code>np.nan</code> or <code>0</code> it will get skipped (or close the current position in the case of setting <code>0</code> for any target size). Set to <code>np.inf</code> to buy for all cash, or <code>-np.inf</code> to sell for all free cash. A point to remember setting to <code>np.inf</code> may cause the scenario for the portfolio simulation to become heavily weighted to one single instrument. So use a sensible size related. <br><br><br>
<strong>b.)</strong> <code>init_cash</code> : Initial capital per column (or per group with cash sharing). By setting it to <code>auto</code> the initial capital is automatically decided based on the position size you specify in the above <code>size</code> parameter.<br><br><br>
<strong>c.)</strong> <code>cash_sharing</code> : Accepts a boolean (<code>True</code> or <code>False</code>) value to specify whether cash sharing is to be disabled or if enabled then cash is shared across all the assets in the portfolio or cash is shared within the same group.<br>
If <code>group_by</code> is None and <code>cash_sharing</code> is True, <code>group_by</code> becomes True to form a single group with cash sharing. <strong>Example:</strong><br>
Consider three columns (3 assets), each having $100 of starting capital. If we built one group of two columns and one group of one column, the init_cash would be <code>np.array([200, 100])</code> with cash sharing enabled and <code>np.array([100, 100, 100])</code> without cash sharing. <br><br></p>
<p><strong>d.)</strong> <code>call_seq</code> : Default sequence of calls per row and group. Controls the sequence in which <code>order_func_nb</code> is executed within each segment. For more details of this function kindly refer the documentation. <br><br></p>
<p><strong>e.)</strong> <code>group_by</code> : can be boolean, integer, string, or sequence to call multi-level indexing and can accept both level names and level positions. In this tutorial I will be setting <code>group_by = True</code> to treat the entire portfolio simulation in a unified manner for all assets in congruence with <code>cash_sharing = True</code>. When I want to create custom groups with specific symbols in each group then I will be setting <code>group_by = 0</code> to specify the level position (in multi-index levels) as the first in the hierarchy.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="2-unified-portfolio-simulation">2.) Unified Portfolio Simulation</h2>
<p>In this section, we run the portfolio simulation treating the entire portfolio as a singular asset by enabling the following parameters in the <code>pf.from_signals()</code>:<br></p>
<ul>
<li><code>cash_sharing = True</code></li>
<li><code>group_by = True</code></li>
<li><code>call_seq = &quot;auto&quot;</code></li>
<li><code>size = 100000</code></li>
</ul>
<pre><code class="language-python">pf_from_signals_v2 = vbt.Portfolio.from_signals(
    close = mtf_data[&apos;m15_close&apos;], 
    entries = mtf_data[&apos;entries&apos;], 
    exits = mtf_data[&apos;exits&apos;],    
    direction = &quot;both&quot;, ## This setting trades both long and short signals
    freq = pd.Timedelta(minutes=15), 
    init_cash = &quot;auto&quot;,
    size = 100000,
    group_by = True,
    cash_sharing = True,
    call_seq = &quot;auto&quot;
)

## Save portfolio simulation as a pickle file
pf_from_signals_v2.save(&quot;../vbt_dashboard/data/pf_sim_single&quot;)

## Load portfolio simulation from pickle file
pf = vbt.Portfolio.load(&apos;../vbt_dashboard/data/pf_sim_single&apos;)
pf.stats()
</code></pre>
<p>Now in this case since the entire portfolio is simulated in a unified manner for all symbols with cash sharing set to True, we get only one <code>pd.Series</code> object for the portfolio simulation stats.<br></p>
<p><strong>Output</strong><br></p>
<pre><code class="language-python">Start                         2019-01-01 22:00:00+00:00
End                           2023-01-16 06:45:00+00:00
Period                               1475 days 09:00:00
Start Value                               781099.026861
Min Value                                  751459.25085
Max Value                                 808290.908182
End Value                                 778580.017067
Total Return [%]                              -0.322496
Benchmark Return [%]                           0.055682
Total Time Exposure [%]                       99.883504
Max Gross Exposure [%]                        99.851773
Max Drawdown [%]                               4.745308
Max Drawdown Duration                 740 days 04:15:00
Total Orders                                       3833
Total Fees Paid                                     0.0
Total Trades                                       3833
Win Rate [%]                                  63.006536
Best Trade [%]                                  4.06637
Worst Trade [%]                               -7.984396
Avg Winning Trade [%]                          0.200416
Avg Losing Trade [%]                          -0.336912
Avg Winning Trade Duration    1 days 12:07:11.327800829
Avg Losing Trade Duration     3 days 22:03:11.201716738
Profit Factor                                  1.007163
Expectancy                                     0.858292
...
Sharpe Ratio                                  -0.015093
Calmar Ratio                                  -0.016834
Omega Ratio                                    0.999318
Sortino Ratio                                 -0.021298
Name: group, dtype: object
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="3-grouped-portfolio-simulation">3.) Grouped Portfolio Simulation</h2>
<p>In this section, we run the portfolio simulation by combining the 8 currency pairs into two groups <code>USDPairs</code> and <code>NonUSDPairs</code> respectively, along with the following parameter settings in the <code>pf.from_signals()</code>:<br></p>
<ul>
<li><code>cash_sharing = True</code></li>
<li><code>group_by = True</code></li>
<li><code>call_seq = &quot;auto&quot;</code></li>
<li><code>size = 100000</code></li>
</ul>
<pre><code class="language-python">print(&quot;Symbols:&quot;,list(pf_from_signals_v2.wrapper.columns))
grp_type = [&apos;USDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;USDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;USDPairs&apos;, &apos;USDPairs&apos;, &apos;USDPairs&apos;]
unique_grp_types = list(set(grp_type))
print(&quot;Group Types:&quot;, grp_type)
print(&quot;Nr. of Unique Groups:&quot;, unique_grp_types)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-python">Symbols: [&apos;AUDUSD&apos;, &apos;EURGBP&apos;, &apos;EURUSD&apos;, &apos;GBPAUD&apos;, &apos;GBPJPY&apos;, &apos;GBPUSD&apos;, &apos;USDCAD&apos;, &apos;USDJPY&apos;]
Group Types: [&apos;USDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;USDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;USDPairs&apos;, &apos;USDPairs&apos;, &apos;USDPairs&apos;]
Nr. of Unique Groups: [&apos;USDPairs&apos;, &apos;NonUSDPairs&apos;]
</code></pre>
<p>VectorBT expects the group labels to be in a <em>monolithic, sorted</em> array, that is our group must be in a monolithic sorted order like: <br> <code>[USDPairs, USDPairs, USDPairs, USDPairs, USDPairs, NonUSDPairs, NonUSDPairs, NonUSDPairs]</code> not a random order like:<br> <code>[&apos;USDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;USDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;NonUSDPairs&apos;, &apos;USDPairs&apos;, &apos;USDPairs&apos;, &apos;USDPairs&apos;]</code>.  So<br>
we create a small method <code>reorder_columns</code> that takes a pandas object and reorders it by sorting columns levels by the level you want to group-by, as a way of preparing the dataframe before it&apos;s getting passed to the <code>from_signals()</code> method.. <br></p>
<pre><code class="language-python">def reorder_columns(df, group_by):
    return df.vbt.stack_index(group_by).sort_index(axis=1, level=0)
</code></pre>
<p>Thereafter, we pass <code>group_by=0</code> (first level) to the <code>pf.from_signals()</code> method before we&apos;re running the simulation, since we appended <code>grp_type</code> list of level names, as the top-most level to the columns of each dataframe, thus making it the first in the hierarchy.<br>
<br></p>
<pre><code class="language-python">pf_from_signals_v3 = vbt.Portfolio.from_signals(
    close = reorder_columns(mtf_data[&quot;m15_close&quot;], group_by = grp_type),
    entries = reorder_columns(mtf_data[&apos;entries&apos;], group_by = grp_type),
    exits = reorder_columns(mtf_data[&apos;exits&apos;], group_by = grp_type),
    direction = &quot;both&quot;, ## This setting trades both long and short signals
    freq = pd.Timedelta(minutes=15), 
    init_cash = &quot;auto&quot;,
    size = 100000,
    group_by = 0,
    cash_sharing=True,
    call_seq=&quot;auto&quot;
)

## Save portfolio simulation as a pickle file
pf_from_signals_v3.save(&quot;../vbt_dashboard/data/pf_sim_grouped&quot;)

## Load portfolio simulation from a pickle file
pf = vbt.Portfolio.load(&apos;../vbt_dashboard/data/pf_sim_grouped&apos;)

## View Trading History of pf.simulation 
pf_trade_history = pf.trade_history
print(&quot;Unique Symbols:&quot;, list(pf_trade_history[&apos;Column&apos;].unique()) )
pf_trade_history
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><strong>Output</strong>:</p>
<pre><code class="language-python">Unique Symbols: [(&apos;NonUSDPairs&apos;, &apos;EURGBP&apos;), (&apos;NonUSDPairs&apos;, &apos;GBPAUD&apos;), (&apos;NonUSDPairs&apos;, &apos;GBPJPY&apos;), (&apos;USDPairs&apos;, &apos;AUDUSD&apos;), (&apos;USDPairs&apos;, &apos;EURUSD&apos;), (&apos;USDPairs&apos;, &apos;GBPUSD&apos;), (&apos;USDPairs&apos;, &apos;USDCAD&apos;), (&apos;USDPairs&apos;, &apos;USDJPY&apos;)]
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/pf3_trading_history.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="2000" height="722" srcset="http://localhost:2368/content/images/size/w600/2023/01/pf3_trading_history.png 600w, http://localhost:2368/content/images/size/w1000/2023/01/pf3_trading_history.png 1000w, http://localhost:2368/content/images/size/w1600/2023/01/pf3_trading_history.png 1600w, http://localhost:2368/content/images/size/w2400/2023/01/pf3_trading_history.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Trading History for <code>Grouped</code> Portfolio Simulation</figcaption></figure><!--kg-card-begin: markdown--><pre><code class="language-python"># For pf_from_signals_v3 case
stats_df = pd.concat([pf[grp].stats() for grp in unique_grp_types], axis = 1) 
stats_df.loc[&apos;Avg Winning Trade Duration&apos;] = [x.floor(&apos;s&apos;) for x in stats_df.iloc[21]]
stats_df.loc[&apos;Avg Losing Trade Duration&apos;] = [x.floor(&apos;s&apos;) for x in stats_df.iloc[22]]
stats_df = stats_df.reset_index() 
stats_df.rename(inplace = True, columns = {&apos;agg_stats&apos;:&apos;Agg_Stats&apos;, &apos;index&apos; : &apos;Metrics&apos; })  
stats_df
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2023/01/pf3_stats_df.png" class="kg-image" alt="VectorBT Pro - MultiAsset Portfolio Simulation" loading="lazy" width="1162" height="1330" srcset="http://localhost:2368/content/images/size/w600/2023/01/pf3_stats_df.png 600w, http://localhost:2368/content/images/size/w1000/2023/01/pf3_stats_df.png 1000w, http://localhost:2368/content/images/2023/01/pf3_stats_df.png 1162w" sizes="(min-width: 720px) 720px"><figcaption>Group-wise Statistics for Grouped Portfolio Simulation</figcaption></figure><p>This concludes the tutorial for multi-asset portfolio simulation. I hope this is useful in your backtesting studies and workflow. If there are any issues or fixes, please leave a git issue in the link below to the jupyter notebook.</p><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/QubitQuants/vectorbt_pro_tutorials/blob/main/MultiAsset_PortfolioSimulation.ipynb" class="kg-btn kg-btn-accent">See Project Code</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Custom Dashboard for Portfolio Simulation and Strategy Visualisation]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>In this tutorial, we will see how to create a customized dashboard using <code>dash</code> and <code>plotly</code> to visualize the portfolio simulation and strategy development in separate tabs.</p>
<blockquote>
<p>To generate the data for this tutorial, you need to follow the steps in the <a href="https://qubitquants.github.io/multi_asset_portfolio_simulation/index.html">Multi-Asset Portfolio Simulation tutorial</a> OR, for quick reference,</p></blockquote>]]></description><link>http://localhost:2368/vbt_dashboard/</link><guid isPermaLink="false">643c151fe770773c74f2e601</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[plotly-dash]]></category><category><![CDATA[plotly]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Sun, 22 Jan 2023 15:55:43 GMT</pubDate><media:content url="http://localhost:2368/content/images/2023/01/VectorBT---Dashboard-Cover-Image.png" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="http://localhost:2368/content/images/2023/01/VectorBT---Dashboard-Cover-Image.png" alt="VectorBT Pro - Custom Dashboard for Portfolio Simulation and Strategy Visualisation"><p>In this tutorial, we will see how to create a customized dashboard using <code>dash</code> and <code>plotly</code> to visualize the portfolio simulation and strategy development in separate tabs.</p>
<blockquote>
<p>To generate the data for this tutorial, you need to follow the steps in the <a href="https://qubitquants.github.io/multi_asset_portfolio_simulation/index.html">Multi-Asset Portfolio Simulation tutorial</a> OR, for quick reference, you can look up <a href="https://github.com/diliprk/vectorbt_pro_dashboard/tree/main/data">this ReadMe file</a>.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Please watch this YouTube video below that explains the details about this dashboard</p><figure class="kg-card kg-embed-card kg-card-hascaption"><iframe width="200" height="113" src="https://www.youtube.com/embed/Mek2Q6JZwTw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen title="VectorBT Pro - Custom Plotly Dashboard"></iframe><figcaption>Custom plotly dashboard for vectorBT Portfolio Simulation and Strategy Visualisation</figcaption></figure><p>To try out this dashboard at your end, please checkout the Git Repo link below. Feel free to contribute (by <em>forking</em> and creating a <em>pull request</em>) to this dashboard if you want to add more features or share your vectorBT study with the community.</p><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/diliprk/vectorbt_pro_dashboard" class="kg-btn kg-btn-accent">See Project Code &#x27BF;</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals]]></title><description><![CDATA[<p></p><!--kg-card-begin: markdown--><p>In this blog we will see how to visualize our Double Bollinger Band strategy along with the indicators and the cleaned entries/exits from the simulation. You will master your <code>VectorBT Pro</code> plotting skills by creating your own <code>plot_strategy()</code> function and learn how to go from a basic plot</p>]]></description><link>http://localhost:2368/vbt_plot_strategy/</link><guid isPermaLink="false">643c151fe770773c74f2e600</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[Signal Cleaning]]></category><category><![CDATA[plotly]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Wed, 30 Nov 2022 17:49:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2022/12/PostFeatureImage-1.png" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2022/12/PostFeatureImage-1.png" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals"><p></p><!--kg-card-begin: markdown--><p>In this blog we will see how to visualize our Double Bollinger Band strategy along with the indicators and the cleaned entries/exits from the simulation. You will master your <code>VectorBT Pro</code> plotting skills by creating your own <code>plot_strategy()</code> function and learn how to go from a basic plot like this &#x2B07;</p>
<p><img src="http://localhost:2368/content/images/2022/12/H4_OHLCV_Only.svg" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><strong>TO this <code>Fancy</code> Advanced Plot &#x1F389; &#x1F60E;</strong> with stacked figures, entries/exits and layered indicators <br><br>
<img src="http://localhost:2368/content/images/2022/12/Final_Strategy_Plot.svg" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="plottingbasics-%F0%9F%91%B6">Plotting - Basics &#x1F476;</h2>
<p>As before we will start with the global settings we will use everywhere for our plotting like this dark theme and figure / width.</p>
<pre><code class="language-python">## Global Plot Settings for vectorBT
vbt.settings.set_theme(&quot;dark&quot;)
vbt.settings[&apos;plotting&apos;][&apos;layout&apos;][&apos;width&apos;] = 1280
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="ohlcv-plot">OHLCV Plot</h3>
<p>The code to get a basic OHLCV plot is shown below, to get custom plot titles and other attributes you pass it in the <code>kwargs</code>. To make some sensible visualization and not get a super condensed plot we will use <code>.iloc</code> to slice a small sample of the dataframe.</p>
<pre><code class="language-python">## Plot OHLCV data first
kwargs1 = {&quot;title_text&quot; : &quot;OHLCV Plot&quot;, &quot;title_font_size&quot; : 18}
h4_ohlc_sample = h4_df[[&quot;Open&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Close&quot;]].iloc[100:200]#.dropna()
f = h4_ohlc_sample.vbt.ohlcv.plot(**kwargs1)
f.show()
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/H4_OHLCV_Only.svg" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<p>This gives the plot you saw earlier, and yes we see some ugly gaps in the candlestick data, which we will see how to fix later. Let&apos;s try to add the Bollinger Bands indicator on top of this basic candlestick plot</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="ohlcv-plot-with-bollinger-bands">OHLCV Plot with Bollinger Bands</h3>
<pre><code class="language-python">h4_bbands.iloc[100:200].plot(fig = f,
                            lowerband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Lower&apos;), 
                            upperband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Upper&apos;),
                            middleband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Middle&apos;)).show()
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/H4_OHLCV_with_2BB.svg" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<p>The fundamental concept you have to understand in layering elements on a figure is to reference the parent figure, notice how the <code>fig = f</code> in the above Bollinger Band plot is referencing the parent figure object <code>f</code> we first created. Also notice that child objects inherit the styling and other attributes <code>kwargs1</code> you passed to the parent object. You can ofcourse over-ride them by placing another <code>**kwargs</code> in the <code>plot()</code> function call.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="adding-rsi-on-stacked-subplots">Adding RSI on Stacked SubPlots</h3>
<p>So we learnt how to add an indicator to the figure, but what if we want to create stacked subplots, like adding an RSI Indicator below the previous plot. This is essentially done using the <code>vbt.make_subplots()</code> function and the use of the <code>add_trace_kwargs</code> argument inside the <code>plot()</code> function.</p>
<pre><code class="language-python">kwargs1 = {&quot;title_text&quot; : &quot;H4 OHLCV with BBands on Price and RSI&quot;, &quot;title_font_size&quot; : 18, 
           &quot;legend&quot; : dict(yanchor=&quot;top&quot;,y=0.99, xanchor=&quot;right&quot;,x= 0.25)}

fig = vbt.make_subplots(rows=2,cols=1, shared_xaxes=True, vertical_spacing=0.1)

## Sliced Data
h4_price = h4_df[[&quot;Open&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Close&quot;]]
indices = slice(100,200)
h4_price.iloc[indices].vbt.ohlcv.plot(add_trace_kwargs=dict(row=1, col=1),  fig=fig, **kwargs1) 
h4_bbands.iloc[indices].plot(add_trace_kwargs=dict(row=1, col=1),fig=fig,
                            lowerband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Lower&apos;), 
                            upperband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Upper&apos;),
                            middleband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Middle&apos;))

h4_rsi.iloc[indices].rename(&quot;RSI&quot;).vbt.plot(add_trace_kwargs=dict(row=2, col=1),fig=fig, **kwargs1 )

h4_bbands_rsi.iloc[indices].plot(add_trace_kwargs=dict(row=2, col=1),limits=(25, 75),fig=fig,
                            lowerband_trace_kwargs=dict(fill=None, name = &apos;BB_RSI_Lower&apos;), 
                            upperband_trace_kwargs=dict(fill=None, name = &apos;BB_RSI_Upper&apos;),
                            middleband_trace_kwargs=dict(fill=None, name = &apos;BB_RSI_Middle&apos;),
                            # xaxis=dict(rangeslider_visible=True) ## Without Range Slider
                            )

fig.update_xaxes(rangebreaks=[dict(values=dt_breaks)])
fig.layout.showlegend = False
fig.show()
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><img src="http://localhost:2368/content/images/2022/12/Stacked_RSI_Plot.svg" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><h2 id="plottingadvanced-%F0%9F%92%AA">Plotting - Advanced &#x1F4AA;</h2>
<p>In this section, we will see how to create your own <code>plot_strategy</code> with all the customizations you would want. Please read the inline comments in the code block below to understand the inner workings and details of the various commands</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">def plot_strategy(slice_lower : str, slice_upper: str, df : pd.DataFrame , rsi : pd.Series,
                  bb_price : vbt.indicators.factory, bb_rsi : vbt.indicators.factory,  
                  pf: vbt.portfolio.base.Portfolio, entries: pd.Series = None, 
                  exits: pd.Series = None,
                  show_legend : bool = True):
    &quot;&quot;&quot;Creates a stacked indicator plot for the 2BB strategy.
    Parameters
    ===========
    slice_lower : str, start date of dataframe slice in yyyy.mm.dd format
    slice_upper : str, start date of dataframe slice in yyyy.mm.dd format
    df          : pd.DataFrame, containing the OHLCV data
    rsi         : pd.Series, rsi indicator time series in same freq as df
    bb_price    : vbt.indicators.factory.talib(&apos;BBANDS&apos;), computed on df[&apos;close&apos;] price
    bb_rsi      : vbt.indicators.factory.talib(&apos;BBANDS&apos;) computer on RSI
    pf          : vbt.portfolio.base.Portfolio, portfolio simulation object from VBT Pro
    entries     : pd.Series, time series data of long entries
    exits       : pd.Series, time series data of long exits
    show_legend : bool, switch to show or completely hide the legend box on the plot
    
    Returns
    =======
    fig         : plotly figure object
    &quot;&quot;&quot;
    kwargs1 = {&quot;title_text&quot; : &quot;H4 OHLCV with BBands on Price and RSI&quot;, 
               &quot;title_font_size&quot; : 18,
               &quot;height&quot; : 960,
               &quot;legend&quot; : dict(yanchor=&quot;top&quot;,y=0.99, xanchor=&quot;left&quot;,x= 0.1)}
    fig = vbt.make_subplots(rows=2,cols=1, shared_xaxes=True, vertical_spacing=0.1)
    ## Filter Data according to date slice
    df_slice = df[[&quot;Open&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Close&quot;]][slice_lower : slice_upper]
    bb_price = bb_price[slice_lower : slice_upper]
    rsi = rsi[slice_lower : slice_upper]
    bb_rsi = bb_rsi[slice_lower : slice_upper]

    ## Retrieve datetime index of rows where price data is NULL
    # retrieve the dates that are in the original datset
    dt_obs = df_slice.index.to_list()
    # Drop rows with missing values
    dt_obs_dropped = df_slice[&apos;Close&apos;].dropna().index.to_list()
    # store  dates with missing values
    dt_breaks = [d for d in dt_obs if d not in dt_obs_dropped]

    ## Plot Figures
    df_slice.vbt.ohlcv.plot(add_trace_kwargs=dict(row=1, col=1),  fig=fig, **kwargs1) ## Without Range Slider
    rsi.rename(&quot;RSI&quot;).vbt.plot(add_trace_kwargs=dict(row=2, col=1), trace_kwargs = dict(connectgaps=True), fig=fig) 

    bb_line_style = dict(color=&quot;white&quot;,width=1, dash=&quot;dot&quot;)
    bb_price.plot(add_trace_kwargs=dict(row=1, col=1),fig=fig, **kwargs1,
                lowerband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Lower&apos;, connectgaps=True, line = bb_line_style), 
                upperband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Upper&apos;, connectgaps=True, line = bb_line_style),
                middleband_trace_kwargs=dict(fill=None, name = &apos;BB_Price_Middle&apos;, connectgaps=True) )

    bb_rsi.plot(add_trace_kwargs=dict(row=2, col=1),limits=(25, 75),fig=fig,
                lowerband_trace_kwargs=dict(fill=None, name = &apos;BB_RSI_Lower&apos;, connectgaps=True,line = bb_line_style), 
                upperband_trace_kwargs=dict(fill=None, name = &apos;BB_RSI_Upper&apos;, connectgaps=True,line = bb_line_style),
                middleband_trace_kwargs=dict(fill=None, name = &apos;BB_RSI_Middle&apos;, connectgaps=True, visible = False))
    
    ## Plots Long Entries / Exits and Short Entries / Exits
    pf[slice_lower:slice_upper].plot_trade_signals(add_trace_kwargs=dict(row=1, col=1),fig=fig,
                                                   plot_close=False, plot_positions=&quot;lines&quot;)

    ## Plot Trade Profit or Loss Boxes
    pf.trades.direction_long[slice_lower : slice_upper].plot(
                                        add_trace_kwargs=dict(row=1, col=1),fig=fig,
                                        plot_close = False,
                                        plot_markers = False
                                        )
                                        

    pf.trades.direction_short[slice_lower : slice_upper].plot(
                                            add_trace_kwargs=dict(row=1, col=1),fig=fig,
                                            plot_close = False,
                                            plot_markers = False
                                            )

    if (entries is not None) &amp; (exits is not None):
        ## Slice Entries and Exits
        entries = entries[slice_lower : slice_upper]
        exits = exits[slice_lower : slice_upper]
        ## Add Entries and Long Exits on RSI in lower subplot
        entries.vbt.signals.plot_as_entries(rsi, fig = fig,
                                                add_trace_kwargs=dict(row=2, col=1),
                                                trace_kwargs=dict(name = &quot;Long Entry&quot;, 
                                                                  marker=dict(color=&quot;limegreen&quot;)
                                                                  ))  

        exits.vbt.signals.plot_as_exits(rsi, fig = fig, 
                                            add_trace_kwargs=dict(row=2, col=1),
                                            trace_kwargs=dict(name = &quot;Short Entry&quot;, 
                                                              marker=dict(color=&quot;red&quot;),
                                                            #   showlegend = False ## To hide this from the legend
                                                              )
                                            )

    fig.update_xaxes(rangebreaks=[dict(values=dt_breaks)])
    fig.layout.showlegend = show_legend  
    # fig.write_html(f&quot;2BB_Strategy_{slice_lower}_to_{slice_upper}.html&quot;)
    
    return fig
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">slice_lower = &apos;2019.11.01&apos;
slice_higher = &apos;2019.12.31&apos;

fig = plot_strategy(slice_lower, slice_higher, h4_data.get(), h4_rsi, 
                           h4_bbands, h4_bbands_rsi, pf,
                           clean_h4_entries, clean_h4_exits,
                           show_legend = True)

# fig.show_svg()
fig.show()
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><img src="http://localhost:2368/content/images/2022/12/Final_Strategy_Plot.svg" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><strong>Notes</strong>:</p>
<ul>
<li>We are using the H4 timeframe data for our plotting, as the <code>15T</code> baseline data series results in a very dense looking plot which slows down the interactive plot.</li>
<li>We are passing a slice of the time series dataframe in order to avoid a dense, highly cluttered plot. You can make this interactive also if you were to use <code>plotly-dash</code> (a topic for another blog post perhaps &#x1F603; )</li>
<li>The gaps in the OHLCV candlesticks on weekends are fixed by storing the dates with missing values in the <code>dt_breaks</code> variable and passing this in the <code>rangebreaks=[dict(values=dt_breaks)]</code> argument in the <code>fig.update_xaxes()</code> method to filter our the missing dates in the x-axes.</li>
<li>We fixed the gaps occuring in the bollinger bands (due to weekend market closures) by using the <code>connectgaps = True</code> argument in each <code>_trace_kwargs</code> of the bollinger bands.</li>
<li>Note, that you may wonder why we are naming the legends entries and exits in the RSI subplot below as <code>Long Entries</code> and <code>Short Entries</code> and not four distinct labels as in the first subplot.
<ul>
<li>This is because since we set <code>direction = both</code> in the <code>pf.simulation</code> the Short Entry is basically an Exit for the previous Long position and similarly, a Long Entry is basically an exit for the previous short position. This type of nomenclature setting makes the plot also usable for other settings like when you would want to set <code>direction = longonly</code> in the <code>pf.simulation</code> in which case you can just call these legend items <code>Long Entries</code> and <code>Long Exits</code> on the RSI subplot.</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><h2 id="cleaning-entries-and-exits">Cleaning <code>entries</code> and <code>exits</code></h2>
<p>You might have noticed in the last code block we were using <code>clean_h4_entries</code> and <code>clean_h4_exits</code>. Lets understand why we did that? Before we plot any entries and exits for visual analysis, it is imperative to clean them. We will continue with the entries and exits at the end of our previous tutorial <code>Strategy Development and Signal Generation</code> in order to explain how we can go about  <code>cleaning</code> and <code>resampling</code> entry &amp; exit signals.</p>
<pre><code class="language-python">entries = mtf_df.signal == 1.0
exits = mtf_df.signal == -1.0
</code></pre>
<p>The total nr. of actual signals in the entries and exits array is computed by the <code>vbt.signals.total()</code> accessor method.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">print(f&quot;Length of Entries (array): {len(entries)} || Length of Exits (array): {len(exits)}&quot; )
print(f&quot;Total Nr. of Entry Signals: {entries.vbt.signals.total()} || \
        Total Nr. of Exit Signals: {exits.vbt.signals.total()}&quot;)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-python">Length of Entries (array): 105188 || Length of Exits (array): 105188
Total Nr. of Entry Signals: 2135 || Total Nr. of Exit Signals: 1568
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="why-do-you-want-to-clean-the-entries-and-exits">Why do you want to clean the <code>entries</code> and <code>exits</code>?</h3>
<p>From the print statement output we can see that in the entire length of the dataframe <code>105188</code> on <code>15T</code> frequency, we can see that the total number of raw entry and raw exit signals is 2135 and 1568 respectively, which is prior to any cleaning. Currently there are many duplicate signals in the entries and exits, and this discrepancy between entries and exits need to be resolved by cleaning.</p>
<p>Cleaning entry and exit signals is easily done by <code>vbt.signals.clean()</code> accessor and after cleaning each entry signal has a corresponding exit signal. When we validate the total number of clean entry and clean exit signals using the <code>vbt.signals.total()</code> method now, we can now see the cleaned entry and exit signals total to be 268 and 267 respectively.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Clean redundant and duplicate signals
clean_entries, clean_exits = entries.vbt.signals.clean(exits)
print(f&quot;Length of Clean_Entries Array: {len(clean_entries)} || Length of Clean_Exits Array: {len(clean_exits)}&quot; )
print(f&quot;Total nr. of Entry Signals in Clean_Entry Array: {clean_entries.vbt.signals.total()} || \
        Total nr. of Exit Signals in Clean_Exit Array: {clean_exits.vbt.signals.total()}&quot;)
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-python">Length of Clean_Entries Array: 105188 || Length of Clean_Exits Array: 105188
Total nr. of Entry Signals in Clean_Entry Array: 268 || Total nr. of Exit Signals in Clean_Exit Array: 267
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<p>Could you think of a reason why there is a difference of one signal between the <code>clean_entry</code> and <code>clean_exit</code> signals ?</p>
<ul>
<li>This is happening because the most recent (entry) position that was last opened, has not been closed out.</li>
</ul>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="cleaning-signalsvisual-difference">Cleaning Signals - Visual Difference</h3>
<p>The below plots will make it easier when understanding what happens if we use uncleaned signals<br>
<strong>Uncleaned Entries &amp; Exits on our RSI Plot</strong><br>
<img src="http://localhost:2368/content/images/2022/12/unCleaned_RSI.png" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<p><strong>Cleaned Entries &amp; Exits on our RSI plot</strong><br>
<img src="http://localhost:2368/content/images/2022/12/Cleaned_RSI.png" alt="VectorBT Pro - Plotting Indicators and Visualising Strategy with Cleaned Signals" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="resampling-entries-and-exits-to-h4-timeframe">Resampling <code>entries</code> and <code>exits</code> to H4 timeframe</h2>
<p>Resampling any entries/exits is <strong>only</strong> required when we are concerned with analyzing (plotting, counting etc.) and visualizing our strategy and entries/exits on a timeframe different from the baseline frequency of our strategy. It is always recommended to <strong>first clean the raw entries/exits</strong> array and then do the resampling.</p>
<p><strong>When do we need to <code>upsample</code> and <code>downsample</code> entries &amp; exits?</strong></p>
<ul>
<li><em>Downsampling</em> of entries/exists is required if we want to do any visual analysis on a timeframe <strong>higher</strong> than that our baseline frequency of our strategy.
<ul>
<li>For eg, in the below code we show a case of Downsampling  our entries/exits on the 15m timeframe to H4 timeframe. Downsampling comes with the <code>risk</code> of <strong>information loss</strong>.</li>
</ul>
</li>
<li><em>Upsampling</em> of entries/exits is required, if we want to do any visual analysis on a timeframe <strong>lower</strong> than that our baseline frequency of our strategy.
<ul>
<li>For example, you have some crossover on 4h frequency and you want to combine the signals with some other crossover on 15 min frequency, then you would need to upsample signals from 4h-&gt;15min, which would cause no problems because there is no information loss in upsampling</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">clean_h4_entries = clean_entries.vbt.resample_apply(&quot;4h&quot;, &quot;any&quot;, wrap_kwargs=dict(dtype=bool))
clean_h4_exits = clean_exits.vbt.resample_apply(&quot;4h&quot;, &quot;any&quot;, wrap_kwargs=dict(dtype=bool))

print(f&quot;Length of H4_Entries (array): {len(clean_h4_entries)} || Length of H4_Exits (array): {len(clean_h4_exits)}&quot; )
print(f&quot;Total nr. of H4_Entry Signals: {clean_h4_entries.vbt.signals.total()} || \
        Total nr. of H4_Exit Signals: {clean_h4_exits.vbt.signals.total()}&quot;)
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-python">Length of H4_Entries (array): 6575 || Length of H4_Exits (array): 6575
Total nr. of H4_Entry Signals: 263 || Total nr. of H4_Exit Signals: 263
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="information-loss-during-downsampling">Information Loss during downsampling</h3>
<p>From the above output we see the nr. of signals on the <code>clean_h4_entries</code> and <code>clean_h4_exits</code> as 263 respectively, this shows a loss of information during this Downsampling process. This information loss occurs because by aggregating signals during downsampling, our data becomes less granular. <br></p>
<p>&#x2B50; <strong>Key Points</strong> <br></p>
<ul>
<li><strong>How information loss occurs during downsampling of entries/exits?</strong> <br>
<ul>
<li>Let&apos;s say we have <code>[entry, entry, exit, exit, entry, entry]</code> in our signal array, after cleaning we&apos;ll get <code>[entry, exit, entry]</code>, but after aggregating the original signal sequence you&apos;ll get just <code>{entry:4 ; exit:2}</code>, which clearly cannot after cleaning produce the same sequence as on the smaller (more granular) timeframe.</li>
<li>The problem here is that the information loss occured during <code>downsampling</code> the cleaned entries and exits, ignores any exit that could have closed the position if you back tested on the original timeframe (<code>15T</code> in our example), that is why we end up seeing 263 || 263 in the above print statement.</li>
</ul>
</li>
<li>After downsampling if we want to retrace the order of signals and we want to investigate &quot;<em>Which signal came first in the original timeframe</em> ?&quot;, we encounter a irresolvible problem. We can&apos;t resample 1m (minutely) data to one year timeframe and then expect the signal count to be the same even though our new data is all fitting in only one bar (1D candle).</li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>By changing the method to <code>sum</code> and removing the <code>wrap_kwargs</code> argument in the <code>vbt.resample_apply()</code> method we can aggregate the signals and show the aggregated nr. of signals.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## sum() will aggregate the signals
h4_entries_agg = clean_entries.vbt.resample_apply(&quot;4h&quot;, &quot;sum&quot;)
h4_exits_agg = clean_exits.vbt.resample_apply(&quot;4h&quot;, &quot;sum&quot;)

## h4_extries_agg is not a vbt object so vbt.signals.total() accessor will not work 
## and thus we use the pandas sum() method in the print statement below
print(f&quot;Length of H4_Entries (array): {len(h4_entries_agg)} || Length of H4_Exits (array): {len(h4_exits_agg)}&quot; )
print(f&quot;Aggregated H4_Entry Signals: {int(h4_entries_agg.sum())} || Aggregated H4_Exit Signals: {int(h4_exits_agg.sum())}&quot;)
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-python">Length of H4_Entries (array): 6575 || Length of H4_Exits (array): 6575
Aggregated H4_Entry Signals: 268   || Aggregated H4_Exit Signals: 267
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Though the result of this aggregation shows the same result we got above when printing the <code>clean_entries.vbt.signals.total()</code> and <code>clean_exits.vbt.signals.total()</code>, this does not help us in inferring the true order of the signals and the information loss created by downsampling cannot be compensated by aggregation.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<p><strong>Do we have to resample entries/exits for running the backtesting simulation?</strong> <br><br>
When you are doing portfolio simulation (backtesting), using the <code>from_signals()</code> which we see in the previous blog post - <a href="https://qubitquants.pro/strategydev/">Strategy Development and Signal Generation</a>, the <code>from_signals</code> method automatically cleans the entries and exits , therefore there is no reason to do resampling or cleaning of any entries and exits.<br>
Irrespective of whether we use the clean entries and exits or just the regular entries and exits in the simulation/backtest when running <code>from_signals()</code> it will make no difference. You can try this for yourself and see the results will be the same.</p>
</blockquote>
<!--kg-card-end: markdown--><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/QubitQuants/vectorbt_pro_tutorials/blob/c679b6edf5bfecdbea1107daeb0ca86ed6f14377/Comprehensive_VectorBT_Basics_Final.ipynb" class="kg-btn kg-btn-accent">See Project Code</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Strategy Development and Signal Generation]]></title><description><![CDATA[<!--kg-card-begin: markdown--><h2 id="strategy-development-and-signal-generation">Strategy Development and Signal Generation</h2>
<p>Strategy Development usually involves multiple trial and error research, where we check for various combinations of technical indicators and price levels to generate entry and exit signals. It is very easy to generate entry and exit signals in VectorBT which is just a <code>bool</code> array</p>]]></description><link>http://localhost:2368/strategydev/</link><guid isPermaLink="false">643c151fe770773c74f2e5ff</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[algorithmic trading]]></category><category><![CDATA[signal generation]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Mon, 28 Nov 2022 11:09:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1635236198091-33d5aa8466cc?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDQxfHxjaGFydCUyMGFuYWx5c2lzfGVufDB8fHx8MTY3MDU4MDI5OQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="strategy-development-and-signal-generation">Strategy Development and Signal Generation</h2>
<img src="https://images.unsplash.com/photo-1635236198091-33d5aa8466cc?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDQxfHxjaGFydCUyMGFuYWx5c2lzfGVufDB8fHx8MTY3MDU4MDI5OQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Strategy Development and Signal Generation"><p>Strategy Development usually involves multiple trial and error research, where we check for various combinations of technical indicators and price levels to generate entry and exit signals. It is very easy to generate entry and exit signals in VectorBT which is just a <code>bool</code> array for <code>entries</code> and <code>exits</code>. If you have different criteria for your LONGS and SHORTS, you can create separate boolean arrays for <code>long_entries</code>, <code>long_exits</code>, <code>short_entries</code> and <code>short_exits</code>.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="double-bollinger-band-strategy-conditions">Double Bollinger Band Strategy Conditions</h3>
<p>For the rest of this tutorial we will be using the indicators and other elements created in the previous tutorial - <a href="https://qubitquants.pro/aligning-mtf-data/index.html">Aligning MTF time series Data with Resampling</a>, for our customized <code>MTF</code> adaptation of this <a href="https://abouttrading.substack.com/p/the-double-bollinger-trading-strategy"><em>Double Bollinger Band</em> Strategy</a> on the H4 and 15m timeframes. In our implementation we will be using the same conditions for a short entry as a long exit and a short exit signal will use the same conditions as a long entry.</p>
<h5 id="long-condition-%E2%86%97"><strong>Long Condition</strong> &#x2197;</h5>
<p>In our adaptation of this Double Bollinger Band Strategy, a long (buy) signal is generated whenever the H4 market (Low) price goes below its lower Bollinger band, and the 15m RSI goes below its lower Bollinger band.</p>
<blockquote>
<p>Here are the two conditions ( <code>c1_long_entry</code> and <code>c2_long_entry</code> ) that would qualify a long entry</p>
</blockquote>
<pre><code class="language-python">## The two variables `bb_upper_fract` and `bb_lower_fract` are simply some adjustment parameters for the RSI bollinger bands and they are explained at the end of this article.

bb_upper_fract = 0.99
bb_lower_fract = 1.01

c1_long_entry = (mtf_df[&apos;h4_low&apos;] &lt;= mtf_df[&apos;h4_bband_price_lower&apos;])
c2_long_entry = (mtf_df[&apos;m15_rsi&apos;] &lt;= (bb_lower_fract * mtf_df[&apos;m15_bband_rsi_lower&apos;]))
</code></pre>
<h5 id="short-condition-%E2%86%98"><strong>Short Condition</strong> &#x2198;</h5>
<p>Likewise, a long exit ( and also the short (sell) signal ) is generated whenever the H4 market (High) price breaks its upper Bollinger band, and the 15m RSI breaks above its upper Bollinger band.</p>
<blockquote>
<p>Here are the two conditions ( <code>c1_long_exit</code> and <code>c2_long_exit</code> ) that would qualify as a long exit (and also as a short entry )</p>
</blockquote>
<pre><code class="language-python">c1_long_exit =  (mtf_df[&apos;h4_high&apos;] &gt;= mtf_df[&apos;h4_bband_price_upper&apos;])
c2_long_exit = (mtf_df[&apos;m15_rsi&apos;] &gt;= (bb_upper_fract * mtf_df[&apos;m15_bband_rsi_upper&apos;]))
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>As seen below the <code>entry</code> and <code>exit</code> criteria can be added as two seperate columns in the <code>mtf_df</code> pandas dataframe, simply by chaining multiple conditions using the bitwise <code>&amp;</code> operator.</p>
<pre><code class="language-python">## Strategy conditions check - Using m15 and h4 data 
mtf_df[&apos;entry&apos;] = c1_long_entry &amp; c2_long_entry
mtf_df[&apos;exit&apos;]  = c1_long_exit &amp; c2_long_exit
</code></pre>
<p>The <code>entries</code> and <code>exits</code> are boolean arrays and in order to represent them in a numerical format we will create a new column called <code>signal</code> in <code>mtf_df</code> that will read <code>1</code> where the entry conditions have been satisfied and <code>-1</code> where the exit conditions have been satisfied, or <code>0</code> otherwise.</p>
<pre><code class="language-python">mtf_df[&apos;signal&apos;] = 0   
mtf_df[&apos;signal&apos;] = np.where( mtf_df[&apos;entry&apos;] ,1, 0)
mtf_df[&apos;signal&apos;] = np.where( mtf_df[&apos;exit&apos;] ,-1, mtf_df[&apos;signal&apos;])
</code></pre>
<p>The entries and exits series can be extracted from <code>mtf_df[&apos;signal&apos;]</code> which will then be used to run the simulation/backtest</p>
<pre><code class="language-python">entries = mtf_df.signal == 1.0
exits = mtf_df.signal == -1.0
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>To run the backtest we use the following code , when the direction is set to <code>both</code>, the long exit is categorised as a short entry, as to close out the long position a short must be initiated and likewise, the short exit is treated as a long entry</p>
<pre><code class="language-python">pf = vbt.Portfolio.from_signals(
    close = mtf_df[&apos;m15_close&apos;], 
    entries = entries, 
    exits = exits, 
    direction = &quot;both&quot;, ## This setting trades both long and short signals
    freq = pd.Timedelta(minutes=15), 
    init_cash = 100000
)
</code></pre>
<pre><code class="language-python">pf_stats = pf.stats()
print(&quot;Total Returns    [%]:&quot;, round(pf_stats[&apos;Total Return [%]&apos;], 2))
print(&quot;Maximum Drawdown [%]: &quot;, round(pf_stats[&apos;Max Drawdown [%]&apos;],2))
print(pf_stats)
</code></pre>
<p><strong>Output</strong></p>
<pre><code class="language-python">Total Returns    [%]: 33.27
Maximum Drawdown [%]:  11.57
Start                         2019-08-27 00:00:00+00:00
End                           2022-08-26 16:45:00+00:00
Period                                365 days 05:40:00
Start Value                                    100000.0
Min Value                                  92520.879497
Max Value                                  133314.96609
End Value                                 133266.736753
Total Return [%]                              33.266737
Benchmark Return [%]                          -3.833225
Total Time Exposure [%]                       99.856448
Max Gross Exposure [%]                       107.104183
Max Drawdown [%]                              11.572446
Max Drawdown Duration                  94 days 06:30:00
Total Orders                                        535
Total Fees Paid                                     0.0
Total Trades                                        535
Win Rate [%]                                  59.550562
Best Trade [%]                                 2.797026
Worst Trade [%]                               -3.578342
Avg Winning Trade [%]                          0.384536
Avg Losing Trade [%]                           -0.42807
Avg Winning Trade Duration    0 days 13:10:31.132075471
Avg Losing Trade Duration     0 days 21:07:20.277777777
Profit Factor                                  1.320807
Expectancy                                    62.387577
Sharpe Ratio                                   1.868003
Calmar Ratio                                   0.867506
Omega Ratio                                    1.021671
Sortino Ratio                                  2.691066
dtype: object
</code></pre>
<!--kg-card-end: markdown--><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">In the <code>pf.stats</code> printout, one might wonder why <code>Period</code> is 365 days, when the dataset <code>start</code> and <code>end</code> period is for 3 years and there are atleast (262 * 3) 786 tradings days in the 3 year calendar? <br><br><code>Period</code><em> in stats measures the number of bars multiplied by frequency, that is, the real duration of backtest and is not to be confused with calendar duration</em></div></div><!--kg-card-begin: markdown--><p>We can see all the trades that were executed during this backtest simulation by using</p>
<pre><code class="language-python">pf.trade_history()
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/pf_trade_history.png" alt="VectorBT Pro - Strategy Development and Signal Generation" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="plottingportfolio-simulations">Plotting - Portfolio Simulations</h3>
<p>It is a good practise to set the theme and plot dimensions that we would like to commonly use for all our plotting in the beginning. VectorBT uses <code>plotly</code> (a python package) for all its plotting capabilities.</p>
<pre><code class="language-python">## Global Plot Settings for vectorBT
vbt.settings.set_theme(&quot;dark&quot;)
vbt.settings[&apos;plotting&apos;][&apos;layout&apos;][&apos;width&apos;] = 1280
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Since our backtest simulation was run on 15m timeframe (as it was our baseline frequency) we resamply the <code>pf.plot()</code> to save time and also avoid seeing a dense  plot. The below SVG static plot was generated using the <code>show_svg()</code> function, but you can also <code>show_png()</code> to render the plot as a static rasterized image or use <code>show()</code> to show an interactive toolbar along with a dynamic interactive plot with hovertools etc.</p>
<blockquote>
<p>The important thing to remember is to use one of the <code>show()</code> method after the <code>plot()</code> in order to render the figure correctly.</p>
</blockquote>
<pre><code class="language-python"># pf.plot().show() ## This takes slightly long (10 secs) as it uses 15m timeframe index
pf.resample(&quot;1d&quot;).plot().show_svg()
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/pf_plot_resampled_1d.svg" alt="VectorBT Pro - Strategy Development and Signal Generation" loading="lazy"></p>
<p>The plot includes three sub-plots that captures at a glance most of the trading performance stats we would like to see like</p>
<ul>
<li>Open and closed positions at various price points</li>
<li>The <code>PnL</code> of each order</li>
<li>The cummulative returns of our strategy compared to the benchmark returns of just holding the instrument</li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We can also isolate <code>pf.orders</code> from the above <code>pf.plot</code> to just show the orders and pass a custom <code>kwargs</code> argument to give a custom title for the plot.</p>
<pre><code class="language-python">kwargs = {&quot;title_text&quot; : &quot;Orders - Daily chart&quot;, &quot;title_font_size&quot; : 18}
pf.orders.resample(&quot;1d&quot;).plot(xaxis=dict(rangeslider_visible=False),**kwargs).show()
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/Orders_1D_Isolated.svg" alt="VectorBT Pro - Strategy Development and Signal Generation" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="max-drawdown">Max Drawdown</h3>
<p>Understanding and Visualization of Drawdown is a very important part of any strategy development and fortunately, for us VectorBT has a very convenient method to visualize DrawDown</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">print(f&quot;Max Drawdown [%]: {pf.stats()[&apos;Max Drawdown [%]&apos;]}&quot;)
print(f&quot;Max Drawdown Duration: {pf.stats()[&apos;Max Drawdown Duration&apos;]}&quot;)
pf.drawdowns.plot(**{&quot;title_text&quot; : &quot;Drawdowns Plot&quot;}).show()
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-python">Max Drawdown [%]: 11.572445827440356
Max Drawdown Duration: 94 days 06:30:00
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/DrawDownPlot_Interactive.png" alt="VectorBT Pro - Strategy Development and Signal Generation" loading="lazy"></p>
<blockquote>
<ul>
<li>The above Drawdown plot below shows only the top 5 drawdowns.</li>
<li>The max drawdown duration of 94 days includes, 73 days for the declination phase and 21 days for the recovery phase in the max. peak drawdown. If you use the <code>.show()</code> method to get an interactive plot you can see this in the hover information when you hover over the plotted figure.</li>
</ul>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="underwater-plot">UnderWater Plot:</h3>
<p>VectorBT also allows us to plot an underwater plot, which is basically just an alternative way of visualizing drawdown and shows the relative drawdown ( <code>time-to-time</code> ) from the previous peak balance</p>
<pre><code class="language-python">kwargs = {&quot;title_text&quot; : &quot;Underwater Plot&quot;,&apos;title_x&apos;: 0.5}
pf.plot_underwater(**kwargs).show()
</code></pre>
<p><img src="http://localhost:2368/content/images/2022/12/UnderWaterPlot.svg" alt="VectorBT Pro - Strategy Development and Signal Generation" loading="lazy"></p>
<!--kg-card-end: markdown--><p>To adjust various aspects and parameters of the plot (eg: Title, position etc.) , one should always refer the Plotly Documentation Reference : <a href="https://plotly.com/python/reference/layout/">https://plotly.com/python/reference/layout/</a></p><!--kg-card-begin: markdown--><h2 id="summarystrategy-exploration">Summary - Strategy Exploration</h2>
<p>&#x1F4A1; <strong>Why we use <code>bb_upper_fract</code> and <code>bb_lower_fract</code>?</strong></p>
<p>To readily understand what these two adjustment variables are you can try running the code see what happens when you see both of these variables equal to 1 , you will essentially get fewer number of signals.</p>
<p>The <code>bb_upper_fract</code> and <code>bb_lower_fract</code> can simply be thought of as parameters that reduce the gap between the upper bound and the high price and the lower bound and the low price.</p>
<p>Reducing this gap results in price more frequently touching the new upper bound and the new lower bound thus resulting in more signals generated.</p>
<p>&#x1F4A1; <strong>What will happen if we try other timeframe combinations?</strong></p>
<p>Well in the strategy explained above we used <code>H4</code> and <code>m15</code> but you may have the idea &#x1F4AD; to use <code>H1</code> instead of <code>H4</code>, thinking that it would result in more signals and perhaps also more profit &#x1F4B5; &#x1F911; ?</p>
<pre><code class="language-python">## Long Entry Conditions
c1_long_entry = (mtf_df[&apos;h1_low&apos;] &lt;= mtf_df[&apos;h1_bband_price_lower&apos;])
c2_long_entry = (mtf_df[&apos;m15_rsi&apos;] &lt;= (bb_lower_fract * mtf_df[&apos;m15_bband_rsi_lower&apos;]) )
 
 
## Long Exit Conditions
c1_long_exit =  (mtf_df[&apos;h1_high&apos;] &gt;= mtf_df[&apos;h1_bband_price_upper&apos;])
c2_long_exit = (mtf_df[&apos;m15_rsi&apos;] &gt;= (bb_upper_fract * mtf_df[&apos;m15_bband_rsi_upper&apos;]))
</code></pre>
<p>Yes &#x2705; that is true we get more signals ,take a look at the results obtained when we execute the above &#x261D; code. Would you be happy with these results ?</p>
<pre><code class="language-python">Total Returns    [%]: -16.21
Maximum Drawdown [%]:  28.17
</code></pre>
<h3 id="key-takeaways-%E2%9A%A1">Key Takeaways &#x26A1;</h3>
<ul>
<li>
<p>Ultimately strategy development and signal generation is an art, that is dependent on variety of different elements like:</p>
<ul>
<li>Timeframes</li>
<li>Indicators and their parameter values</li>
<li>Fundamental and Economic data etc.</li>
</ul>
</li>
<li>
<p>Its imperative that you study &#x1F4DA; the rules and parameters of your strategy carefully before backtesting.</p>
</li>
</ul>
<!--kg-card-end: markdown--><p>Good Luck &#xA0;&#x270C;&#xFE0F; on your strategy development journey, let us know in the comments below if you happen to discover any profitable variations of this strategy</p><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/QubitQuants/vectorbt_pro_tutorials/blob/c679b6edf5bfecdbea1107daeb0ca86ed6f14377/Comprehensive_VectorBT_Basics_Final.ipynb" class="kg-btn kg-btn-accent">See Project Code</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Aligning MTF time series Data with Resampling]]></title><description><![CDATA[<blockquote>Software Requirements : vectorbtpro, python3</blockquote><p><strong>Resampling</strong> of the market data is needed for strategies that involve multiple time frames, often referred to as &#x201C;<em>top down analysis</em>&#x201D; or &#x201C;<em>Multi Time Frame</em> (MTF) analysis&#x201D;. There are two types of resampling, called <strong>upsampling</strong> and <strong>downsampling</strong>.<br><br>Before thinking of <em><code>upsampling</code></em> and</p>]]></description><link>http://localhost:2368/aligning-mtf-data/</link><guid isPermaLink="false">643c151fe770773c74f2e5fc</guid><category><![CDATA[python]]></category><category><![CDATA[algorithmic trading]]></category><category><![CDATA[vectorBT]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Sat, 26 Nov 2022 08:30:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1637561696264-bca8c24878e5?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDl8fGFsaWdubWVudCUyMHZlY3RvcnxlbnwwfHx8fDE2NzAwMDAwOTQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<blockquote>Software Requirements : vectorbtpro, python3</blockquote><img src="https://images.unsplash.com/photo-1637561696264-bca8c24878e5?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDl8fGFsaWdubWVudCUyMHZlY3RvcnxlbnwwfHx8fDE2NzAwMDAwOTQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="VectorBT Pro - Aligning MTF time series Data with Resampling"><p><strong>Resampling</strong> of the market data is needed for strategies that involve multiple time frames, often referred to as &#x201C;<em>top down analysis</em>&#x201D; or &#x201C;<em>Multi Time Frame</em> (MTF) analysis&#x201D;. There are two types of resampling, called <strong>upsampling</strong> and <strong>downsampling</strong>.<br><br>Before thinking of <em><code>upsampling</code></em> and <em><code>downsampling</code></em> time-series data, let&apos;s use the analogy of an UltraHD (4K) &#xA0;television to better understand these terms intuitively. When you feed a 1080p video source to a 4K TV it will <em>Upsample</em> the pixels, giving you a high resolution image. Essentially, you will get a high granularity (finer, hi-res image) from a low granularity (coarse, low-res image). The opposite ( <em>downsampling </em>) happens when you play a 4K video file on an old &#x1F4FA; HD TV.<br><br>In the context of time series data,</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><strong>Downsampling</strong> means going from high frequency time-series data (holds more information about the price within a time interval) to low frequency time-series data (holds less information about the price within the same time interval)<br><strong>Example</strong>: 15 Minute Data &#x2192; 1 Hour Data</div></div><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><strong>Upsampling</strong> means going from a low frequency time-series data (holds less information about the price within a time interval) to a higher frequency (holds more information about the price within a time interval)<br><strong>Example</strong> : 1 Hour Data &#x2192; 15 Minute Data</div></div><p>In multi-time frame strategy analysis, we have to deal with the problem of integrating time series data (eg: <code>close</code> price) from multiple time frames.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2022/12/Merge_How-1.svg" class="kg-image" alt="VectorBT Pro - Aligning MTF time series Data with Resampling" loading="lazy" width="1507" height="458"><figcaption>How to merge timeseries data with different frequencies?</figcaption></figure><p>To make our data-analytics and back-testing simulation process easier, we usually like to have a single time-series dataframe ( <code>mtf_df</code> ) which contains all the values from whatever time-frames we require (eg: 5m, 15min, 1h. 4h, 1D, 1W etc.) . This MTF dataframe will have a <em>base-line</em> frequency which will typically be the highest frequency (i.e highest granularity or the lowest timeframe time-series data, eg: 5m ) with which you want to do your signal generation for the strategy. The process of creating this MTF dataframe with resampled data is called <em><strong>Alignment</strong></em>.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://localhost:2368/content/images/2022/12/Merged_DFs-1.svg" class="kg-image" alt="VectorBT Pro - Aligning MTF time series Data with Resampling" loading="lazy" width="2326" height="505"><figcaption>Aligned and upsampled data frame</figcaption></figure><p>In alignment, we basically merge the MTF time-series &#xA0;<em>resampled</em> data into a single dataframe using <code>ffill()</code> and <code>shift()</code> operations. This is very easily done using <code>vbt.resampler()</code> objects and using those resampler objects as an argument in <code>vbt.resample_opening()</code> function for <strong>open</strong> price and <code>vbt.resample_closing()</code> when dealing with <strong>close</strong>, <strong>high</strong>, <strong>low</strong> prices and indicators.</p><hr><!--kg-card-begin: markdown--><h2 id="loading-and-resampling-data">Loading and Resampling Data</h2>
<p>Loading the data using <code>vbt.HDF</code> functionality of the <code>1-minute</code> granularity</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Import Required Libaries
import vectorbtpro as vbt
import pandas as pd

## Load m1 data
m1_data = vbt.HDFData.fetch(&apos;../data/GU_OHLCV_3Y.h5&apos;)
m1_data.wrapper.index #pandas doaesn&apos;t recognise the frequency because of missing timestamps
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-python">DatetimeIndex([&apos;2019-08-27 00:00:00+00:00&apos;, &apos;2019-08-27 00:01:00+00:00&apos;,
               &apos;2019-08-27 00:02:00+00:00&apos;, &apos;2019-08-27 00:03:00+00:00&apos;,
               &apos;2019-08-27 00:04:00+00:00&apos;, &apos;2019-08-27 00:05:00+00:00&apos;,
               &apos;2019-08-27 00:06:00+00:00&apos;, &apos;2019-08-27 00:07:00+00:00&apos;,
               &apos;2019-08-27 00:08:00+00:00&apos;, &apos;2019-08-27 00:09:00+00:00&apos;,
               ...
               &apos;2022-08-26 16:50:00+00:00&apos;, &apos;2022-08-26 16:51:00+00:00&apos;,
               &apos;2022-08-26 16:52:00+00:00&apos;, &apos;2022-08-26 16:53:00+00:00&apos;,
               &apos;2022-08-26 16:54:00+00:00&apos;, &apos;2022-08-26 16:55:00+00:00&apos;,
               &apos;2022-08-26 16:56:00+00:00&apos;, &apos;2022-08-26 16:57:00+00:00&apos;,
               &apos;2022-08-26 16:58:00+00:00&apos;, &apos;2022-08-26 16:59:00+00:00&apos;],
              dtype=&apos;datetime64[ns, UTC]&apos;, name=&apos;time&apos;, length=1122468, freq=None)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Resampling (<code>Downsampling</code>) the Data from 1 Minute Timeframe / Granularity to other Timeframes/Granularities.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><blockquote>
<ul>
<li>Converting 1 Minute (<code>M1</code>) to 15 Minute (<code>M15</code>)</li>
<li>Converting 1 Minute (<code>M1</code>) to 1 Hour (<code>H1</code>)</li>
<li>Converting 1 Minute (<code>M1</code>) to 4 Hours (<code>H4</code>)</li>
</ul>
</blockquote>
<p>This resampling uses the <code>vbt.resample()</code> method for the downsampling operations, after which we see the frequency is identified correctly as <code>15T</code> (15 mins)</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">m15_data = m1_data.resample(&apos;15T&apos;)
h1_data = m1_data.resample(&quot;1h&quot;)
h4_data = m1_data.resample(&apos;4h&apos;)
print(m15_data.wrapper.index)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code class="language-python">DatetimeIndex([&apos;2019-08-27 00:00:00+00:00&apos;, &apos;2019-08-27 00:15:00+00:00&apos;,
               &apos;2019-08-27 00:30:00+00:00&apos;, &apos;2019-08-27 00:45:00+00:00&apos;,
               &apos;2019-08-27 01:00:00+00:00&apos;, &apos;2019-08-27 01:15:00+00:00&apos;,
               &apos;2019-08-27 01:30:00+00:00&apos;, &apos;2019-08-27 01:45:00+00:00&apos;,
               &apos;2019-08-27 02:00:00+00:00&apos;, &apos;2019-08-27 02:15:00+00:00&apos;,
               ...
               &apos;2022-08-26 14:30:00+00:00&apos;, &apos;2022-08-26 14:45:00+00:00&apos;,
               &apos;2022-08-26 15:00:00+00:00&apos;, &apos;2022-08-26 15:15:00+00:00&apos;,
               &apos;2022-08-26 15:30:00+00:00&apos;, &apos;2022-08-26 15:45:00+00:00&apos;,
               &apos;2022-08-26 16:00:00+00:00&apos;, &apos;2022-08-26 16:15:00+00:00&apos;,
               &apos;2022-08-26 16:30:00+00:00&apos;, &apos;2022-08-26 16:45:00+00:00&apos;],
              dtype=&apos;datetime64[ns, UTC]&apos;, name=&apos;time&apos;, length=105188, freq=&apos;15T&apos;)
</code></pre>
<!--kg-card-end: markdown--><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text"><strong>How can the user tell which <code>resample()</code> method was used in the above operation, is it <code>pandas</code> or <code>vbt.resample()</code> ?</strong><br>If the object you are resampling is of class <code>vbt</code> then the numba-compiled <code>resample()</code> function of VectorBT will be used automatically. If the resampled object is a <code>pandas.Series</code> or <code>pandas.DataFrame</code> then the pandas resample() method will be used automatically.</div></div><hr><!--kg-card-begin: markdown--><p>As seen in the code below the respective (OHLC) can be obtained using the <code>.get()</code> method.</p>
<pre><code class="language-python"># Obtain all the closing  prices using the .get() method
m15_close = m15_data.get()[&apos;Close&apos;]

## h1 data
h1_open  = h1_data.get()[&apos;Open&apos;]
h1_close = h1_data.get()[&apos;Close&apos;]
h1_high  = h1_data.get()[&apos;High&apos;]
h1_low   = h1_data.get()[&apos;Low&apos;]

## h4 data
h4_open  = h4_data.get()[&apos;Open&apos;]
h4_close = h4_data.get()[&apos;Close&apos;]
h4_high  = h4_data.get()[&apos;High&apos;]
h4_low   = h4_data.get()[&apos;Low&apos;]
</code></pre>
<p>OR, you can can also simply follow the pandas convention like <code>resampled_data.column_name</code> to retrieve the column data</p>
<pre><code class="language-python"># Obtain all the closing  prices using the .get() method
m15_close = m15_data.close

## h1 data
h1_open  = h1_data.open
h1_close = h1_data.close
h1_high  = h1_data.high
h1_low   = h1_data.low

## h4 data
h4_open  = h4_data.open
h4_close = h4_data.close
h4_high  = h4_data.high
h4_low   = h4_data.low
</code></pre>
<p>The OHLC for both the <code>H4</code> 4-Hourly Candle Data as well as the closing price for the 15m Candle Data was obtained.</p>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><h2 id="multi-time-frame-indicator-creation">Multi-Time Frame Indicator Creation</h2>
<p>VectorBT has a built-in method called <code>vbt.talib()</code> which calls the required indicator from <strong>talib</strong> library and runs it on the specified time-series data (Eg: <code>Close</code> Price or another indicator). We will now create the following indicators (<em>manually</em>) on the <code>M15</code>, <code>H1</code> and <code>H4</code> timeframes using the :</p>
<ul>
<li><code>RSI</code> of 21 period</li>
<li><code>BBANDS</code> Bolllinger Bands</li>
<li><code>BBANDS_RSI</code> Bollinger Bands on the RSI</li>
</ul>
<pre><code class="language-python">rsi_period = 21

## 15m indicators
m15_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = rsi_period).run(m15_close, skipna=True).real.ffill()
m15_bbands = vbt.talib(&quot;BBANDS&quot;).run(m15_close, skipna=True)
m15_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(m15_rsi, skipna=True)

## h4 indicators
h1_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = rsi_period).run(h1_close, skipna=True).real.ffill()
h1_bbands = vbt.talib(&quot;BBANDS&quot;).run(h1_close, skipna=True)
h1_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(h1_rsi, skipna=True)

## h4 indicators
h4_rsi = vbt.talib(&quot;RSI&quot;, timeperiod = rsi_period).run(h4_close, skipna=True).real.ffill()
h4_bbands = vbt.talib(&quot;BBANDS&quot;).run(h4_close, skipna=True)
h4_bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(h4_rsi, skipna=True)
</code></pre>
<p>When <code>talib()</code> creates the RSI indicator time-series, it is known to create it with NaNs (null-values), so it is a good idea to run <code>ffill()</code>, <em>forward filling</em> operation to fill the missing values. On this note, it is also a good idea in general, to investigate the talib results and compare it with the original time-series data (<code>Close</code> Price) for abnormal number of <code>NaN</code> values and then decide on <code>ffill()</code> operation</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We will now initialize the empty dict called <code>data</code> and fill it with key - value pairs of the 15m time-series data.</p>
<pre><code class="language-python">## Initialize  dictionary
data = {}

col_values = [
    m15_close, m15_rsi, m15_bbands.upperband, m15_bbands.middleband, m15_bbands.lowerband, 
    m15_bbands_rsi.upperband, m15_bbands_rsi.middleband, m15_bbands_rsi.lowerband
    ]

col_keys = [
    &quot;m15_close&quot;, &quot;m15_rsi&quot;, &quot;m15_bband_price_upper&quot;,  &quot;m15_bband_price_middle&quot;, &quot;m15_bband_price_lower&quot;, 
    &quot;m15_bband_rsi_upper&quot;,  &quot;m15_bband_rsi_middle&quot;, &quot;m15_bband_rsi_lower&quot;
         ]

# Assign key, value pairs for method of time series data to store in data dict
for key, time_series in zip(col_keys, col_values):
    data[key] = time_series.ffill()
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="alternative-one-liner-method-of-indicator-creation">Alternative (<strong>One-Liner</strong>) Method of Indicator Creation</h3>
<p>VectorBT also offers a more convenient one-liner method of creating this multi-time frame indicators</p>
<pre><code class="language-python">rsi_period = 21

rsi = vbt.talib(&quot;RSI&quot;, timeperiod=rsi_period).run(
    m15_data.get(&quot;Close&quot;), 
    timeframe=[&quot;15T&quot;, &quot;1H&quot; , &quot;4H&quot;], 
    skipna=True, 
    broadcast_kwargs=dict(wrapper_kwargs=dict(freq=&quot;15T&quot;))
).real

bbands_price = vbt.talib(&quot;BBANDS&quot;).run(
    m15_data.get(&quot;Close&quot;), 
    timeframe=[&quot;15T&quot;, &quot;1H&quot;, &quot;4H&quot;], 
    skipna=True,
    broadcast_kwargs=dict(wrapper_kwargs=dict(freq=&quot;15T&quot;))
)

bbands_rsi = vbt.talib(&quot;BBANDS&quot;).run(
    rsi,
    timeframe=vbt.Default([&quot;15T&quot;, &quot;1H&quot; ,&quot;4H&quot;]),
    skipna=True,
    per_column=True,
    broadcast_kwargs=dict(wrapper_kwargs=dict(freq=&quot;15T&quot;))
)

</code></pre>
<p><strong>Note</strong> : The method of indicator creation shown above using <code>talib(&apos;IndicatorName&apos;).run</code> with <code>broadcast_kwargs</code> argument automatically does the <a href="https://github.com/polakowo/vectorbt.pro/blob/df5370824c9368406c0a06ddd0befeb56727e4c4/vectorbtpro/indicators/factory.py#L2868"><code>ffill()</code> operation</a>. This one liner method doesn&apos;t resample to <code>15T</code> only because of <code>broadcast_kwargs</code> argument, in fact, using <code>broadcast_kwargs</code> we just provide vbt with the true frequency of your data in case this frequency cannot be inferred from data. Without specifying it the method will still work (we will just get a warning if frequency cannot be inferred) <br> So here we we specify the <code>broadcast_kwargs</code> argument, because <code>m15_data.get(&quot;Close&quot;)</code> contains gaps and pandas cannot infer its frequency as <code>15T</code>, this approach works only because of the <code>timeframe</code> argument and because indicators always return outputs of the same index as their inputs, such that we&apos;re forced to resample it back to the original frequency. If pandas can infer the frequency of the input series, we don&apos;t need to specify <code>broadcast_kwargs</code> argument at all.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Initialize  dictionary
data = {}

## Assign key, value pairs for method 2 of Automated One-liner MTF indicator creation method
col_values = [
    [m15_close.ffill(), rsi[&apos;15T&apos;], bbands_price[&apos;15T&apos;].upperband, bbands_price[&apos;15T&apos;].middleband, bbands_price[&apos;15T&apos;].lowerband, bbands_rsi[&apos;15T&apos;].upperband, bbands_rsi[&apos;15T&apos;].middleband, bbands_rsi[&apos;15T&apos;].lowerband],
    [rsi[&apos;1H&apos;], bbands_price[&apos;1H&apos;].upperband, bbands_price[&apos;1H&apos;].middleband, bbands_price[&apos;1H&apos;].lowerband, bbands_rsi[&apos;1H&apos;].upperband, bbands_rsi[&apos;1H&apos;].middleband, bbands_rsi[&apos;1H&apos;].lowerband],
    [rsi[&apos;4H&apos;], bbands_price[&apos;4H&apos;].upperband, bbands_price[&apos;4H&apos;].middleband, bbands_price[&apos;4H&apos;].lowerband, bbands_rsi[&apos;4H&apos;].upperband, bbands_rsi[&apos;4H&apos;].middleband, bbands_rsi[&apos;4H&apos;].lowerband]
    ]

col_keys = [
    [&quot;m15_close&quot;, &quot;m15_rsi&quot;, &quot;m15_bband_price_upper&quot;,  &quot;m15_bband_price_middle&quot;, &quot;m15_bband_price_lower&quot;,  &quot;m15_bband_rsi_upper&quot;,  &quot;m15_bband_rsi_middle&quot;, &quot;m15_bband_rsi_lower&quot;], 
    [&quot;h1_rsi&quot;, &quot;h1_bband_price_upper&quot;,  &quot;h1_bband_price_middle&quot;,  &quot;h1_bband_price_lower&quot;,  &quot;h1_bband_rsi_upper&quot;,  &quot;h1_bband_rsi_middle&quot;, &quot;h1_bband_rsi_lower&quot;],
    [&quot;h4_rsi&quot;, &quot;h4_bband_price_upper&quot;,  &quot;h4_bband_price_middle&quot;,  &quot;h4_bband_price_lower&quot;,  &quot;h4_bband_rsi_upper&quot;,  &quot;h4_bband_rsi_middle&quot;, &quot;h4_bband_rsi_lower&quot; ],
         ]

## Assign key, value pairs for method 2 of Automated One-liner MTF indicator creation method
for lst_series, lst_keys in zip(col_values, col_keys):
    for key, time_series in zip(lst_keys, lst_series):
        data[key] = time_series
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="alignment-up-sampling">Alignment &amp; Up-sampling</h2>
<p>Let&apos;s now see what is <code>resampler</code> in VectorBT. Resampler is an instance of the Resampler class, which simply stores a source index and frequency, and a target index and frequency. The <code>vbt.resampler()</code> method can just work with the source index and target index and can automatically infer the source and target frequency. In contrast to Pandas, vectorbt can also accept an arbitrary target index for resampling</p>
<pre><code class="language-python">Resampler(
    source_index,
    target_index,
    source_freq=None,
    target_freq=None,
    silence_warnings=None
)

</code></pre>
<p>where the arguments, are <br><br>
<code>source_index</code> :&#x2002;is <code>index_like</code>, Index being resampled.<br>
<code>target_index</code> :&#x2002;is <code>index_like</code> ,Index resulted from resampling.<br>
<code>source_freq</code>  :&#x2002;<code>frequency_like</code> or <code>bool</code>, Frequency or date offset of the source index. Set to <code>False</code> to force-set the frequency to None.<br>
<code>target_freq</code>  :&#x2002;<code>frequency_like</code> or <code>bool</code>,  Frequency or date offset of the target index. Set to <code>False</code> to force-set the frequency to None.<br>
<code>silence_warnings</code> :&#x2002;<code>bool</code>, Whether to silence all warnings.</p>
<p>We will now create a custom function called <code>create_resamplers()</code> using this <code>vbt.Resampler()</code> function to create a resampler object to convert <code>H4</code> time-series</p>
<pre><code class="language-python">def create_resamplers(result_dict_keys_list : list, source_indices : list,  
                      source_frequencies :list, target_index : pd.Series, target_freq : str):
    &quot;&quot;&quot;
    Creates a dictionary of vbtpro resampler objects.

    Parameters
    ==========
    result_dict_keys_list : list, list of strings, which are keys of the output dictionary
    source_indices        : list, list of pd.time series objects of the higher timeframes
    source_frequencies    : list(str), which are short form representation of time series order. Eg:[&quot;1D&quot;, &quot;4h&quot;]
    target_index          : pd.Series, target time series for the resampler objects
    target_freq           : str, target time frequency for the resampler objects

    Returns
    ===========
    resamplers_dict       : dict, vbt pro resampler objects
    &quot;&quot;&quot;
    
    
    resamplers = []
    for si, sf in zip(source_indices, source_frequencies):
        resamplers.append(vbt.Resampler(source_index = si,  target_index = target_index,
                                        source_freq = sf, target_freq = target_freq))
    return dict(zip(result_dict_keys_list, resamplers))
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Using this function we can create a dictionary of <code>vbt.Resampler</code> objecters stored by appropriately named keys.</p>
<pre><code class="language-python">## Create Resampler Objects for upsampling
src_indices = [h1_close.index, h4_close.index]
src_frequencies = [&quot;1H&quot;,&quot;4H&quot;] 
resampler_dict_keys = [&quot;h1_m15&quot;,&quot;h4_m15&quot;]

list_resamplers = create_resamplers(resampler_dict_keys, src_indices, src_frequencies, m15_close.index, &quot;15T&quot;)

print(list_resamplers)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><strong>Output</strong>:</p>
<pre><code class="language-python">{&apos;h1_m15&apos;: &lt;vectorbtpro.base.resampling.base.Resampler at 0x16c83de70&gt;,
 &apos;h4_m15&apos;: &lt;vectorbtpro.base.resampling.base.Resampler at 0x16c5478e0&gt;}
</code></pre>
<p>The output shows that two <code>vbt.Resampler</code> class objects have been created in memory.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>The <code>resample_closing()</code> and <code>resample_opening()</code> operations don&apos;t require any <code>ffill()</code> operations and they automatically align the source time-series data to the target frequency, which in our case is <code>15T</code> (15 mins)</p>
<pre><code class="language-python">## Add H1 OLH data - No need to do ffill() on resample_closing as it already does that by default
data[&quot;h1_open&quot;] = h4_open.vbt.resample_opening(list_resamplers[&apos;h1_m15&apos;])

## Add H4 OLH data - No need to do ffill() on resample_closing as it already does that by default
data[&quot;h4_open&quot;] = h4_open.vbt.resample_opening(list_resamplers[&apos;h4_m15&apos;])
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We use <code>resample_opening</code> only if information in the array happens exactly at the beginning of the bar (such as open price), and <code>resample_closing</code> if information happens after that (such as high, low, and close price). You can see the effect of this <code>resample_opening</code> operation with the <code>print() </code>statements below:</p>
<pre><code class="language-python">print(h4_open.info()) ## Before resampling pandas series

&lt;class &apos;pandas.core.series.Series&apos;&gt;
DatetimeIndex: 6575 entries, 2019-08-27 00:00:00+00:00 to 2022-08-26 16:00:00+00:00
Freq: 4H
Series name: Open
Non-Null Count  Dtype  
--------------  -----  
4841 non-null   float64
dtypes: float64(1)
memory usage: 102.7 KB
None

print(data[&quot;h4_open&quot;].info()) ## After resampling pandas series

&lt;class &apos;pandas.core.series.Series&apos;&gt;
DatetimeIndex: 105188 entries, 2019-08-27 00:00:00+00:00 to 2022-08-26 16:45:00+00:00
Freq: 15T
Series name: Open
Non-Null Count   Dtype  
--------------   -----  
105188 non-null  float64
dtypes: float64(1)
memory usage: 1.6 MB
None
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">## Use along with  Manual indicator creation method for MTF
series_to_resample = [
    [h1_high, h1_low, h1_close, h1_rsi, 
    h1_bbands.upperband, h1_bbands.middleband, h1_bbands.lowerband,
    h1_bbands_rsi.upperband, h1_bbands_rsi.middleband, h1_bbands_rsi.lowerband], 
    [h4_high, h4_low, h4_close, h4_rsi,
    h4_bbands.upperband, h4_bbands.middleband, h4_bbands.lowerband, 
    h4_bbands_rsi.upperband, h4_bbands_rsi.middleband, h4_bbands_rsi.lowerband]
    ]

data_keys = [
    [&quot;h1_high&quot;, &quot;h1_low&quot;, &quot;h1_close&quot;, &quot;h1_rsi&quot;, 
    &quot;h1_bband_price_upper&quot;, &quot;h1_bband_price_middle&quot;,&quot;h1_bband_price_lower&quot;, 
     &quot;h1_bband_rsi_upper&quot;,  &quot;h1_bband_rsi_middle&quot;, &quot;h1_bband_rsi_lower&quot;],
    [&quot;h4_high&quot;, &quot;h4_low&quot;, &quot;h4_close&quot;, &quot;h4_rsi&quot;, 
    &quot;h4_bband_price_upper&quot;, &quot;h4_bband_price_middle&quot;, &quot;h4_bband_price_lower&quot;, 
     &quot;h4_bband_rsi_upper&quot;,  &quot;h4_bband_rsi_middle&quot;, &quot;h4_bband_rsi_lower&quot;]
     ]

## Create resampled time series data aligned to base line frequency (15min)

for lst_series, lst_keys, resampler in zip(series_to_resample, data_keys, resampler_dict_keys):
    for key, time_series in zip(lst_keys, lst_series):
        resampled_time_series = time_series.vbt.resample_closing(list_resamplers[resampler])
        data[key] = resampled_time_series
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="alignment-and-resampling-when-using-one-liner-method-of-indicator-creation-br">Alignment and Resampling when using <em>one-liner</em> method of indicator creation <br></h3>
<p>In this method, we have already dealt with resampling and aligning the indicators, so all we have to do is just resample the open and closing prices of the respective timeframes required.</p>
<pre><code class="language-python">## Resample prices to match base_line frequency (`15T`)

series_to_resample = [
    [h1_open, h1_high, h1_low, h1_close],
    [h4_open, h4_high, h4_low, h4_close]
    ]

data_keys = [
    [&quot;h1_open&quot;, &quot;h1_high&quot;, &quot;h1_low&quot;, &quot;h1_close&quot;],
    [&quot;h4_open&quot;, &quot;h4_high&quot;, &quot;h4_low&quot; ,&quot;h4_close&quot;]
    ]

## Create resampled time series data aligned to base line frequency (15min)

for lst_series, lst_keys, resampler in zip(series_to_resample, data_keys, resampler_dict_keys):
    for key, time_series in zip(lst_keys, lst_series):
        if key.lower().endswith(&apos;open&apos;):
            print(f&apos;Resampling {key} differently using vbt.resample_opening using &quot;{resampler}&quot; resampler&apos;)
            resampled_time_series = time_series.vbt.resample_opening(list_resamplers[resampler])
        else:
            resampled_time_series = time_series.vbt.resample_closing(list_resamplers[resampler])
        data[key] = resampled_time_series
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="creating-the-master-dataframe">Creating The Master DataFrame</h2>
<p>Now that we have resampled the various time series to the different timeframes, created and run our indicators, we can finally create the composite <code>mtf_df</code> dataframe from this data which is properly aligned to the baseline frequency (in our case <code>15T</code>) that will allow us to properly create the <code>Buy/Long</code> and <code>Sell/Short</code> conditions for whichever MTF (Multi Time Frame) Strategy that we indend to backtest.</p>
<pre><code class="language-python">cols_order = [&apos;m15_close&apos;, &apos;m15_rsi&apos;, &apos;m15_bband_price_upper&apos;,&apos;m15_bband_price_middle&apos;, &apos;m15_bband_price_lower&apos;,
              &apos;m15_bband_rsi_upper&apos;,&apos;m15_bband_rsi_middle&apos;, &apos;m15_bband_rsi_lower&apos;,
              &apos;h1_open&apos;, &apos;h1_high&apos;, &apos;h1_low&apos;, &apos;h1_close&apos;, &apos;h1_rsi&apos;,
              &apos;h1_bband_price_upper&apos;, &apos;h1_bband_price_middle&apos;, &apos;h1_bband_price_lower&apos;, 
              &apos;h1_bband_rsi_upper&apos;, &apos;h1_bband_rsi_middle&apos;, &apos;h1_bband_rsi_lower&apos;,              
              &apos;h4_open&apos;, &apos;h4_high&apos;, &apos;h4_low&apos;, &apos;h4_close&apos;, &apos;h4_rsi&apos;,
              &apos;h4_bband_price_upper&apos;, &apos;h4_bband_price_middle&apos;, &apos;h4_bband_price_lower&apos;, 
              &apos;h4_bband_rsi_upper&apos;, &apos;h4_bband_rsi_middle&apos;, &apos;h4_bband_rsi_lower&apos;
              ]

## construct a multi-timeframe dataframe
mtf_df = pd.DataFrame(data)[cols_order]
display(mtf_df)            
</code></pre>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://localhost:2368/content/images/2022/12/mtf_df.png" class="kg-image" alt="VectorBT Pro - Aligning MTF time series Data with Resampling" loading="lazy" width="2000" height="711" srcset="http://localhost:2368/content/images/size/w600/2022/12/mtf_df.png 600w, http://localhost:2368/content/images/size/w1000/2022/12/mtf_df.png 1000w, http://localhost:2368/content/images/size/w1600/2022/12/mtf_df.png 1600w, http://localhost:2368/content/images/size/w2400/2022/12/mtf_df.png 2400w" sizes="(min-width: 1200px) 1200px"><figcaption>Final aligned and resampled, pandas MultiTimeFrame DataFrame</figcaption></figure><!--kg-card-begin: markdown--><p>The <code>mtf_df</code> multi-time frame master dataframe will have the following columns each of which will help us define the logic of the strategy.</p>
<ol>
<li><code>m15_close</code> : 15 Minute Closing Price</li>
<li><code>m15_rsi</code> : RSI values on the <code>m15</code>closing price of period 21</li>
<li><code>m15_bband_price_upper</code>: The upper bollinger band on <code>m15</code> closing price</li>
<li><code>m15_bband_price_middle</code>: The middle bollinger band on <code>m15</code> closing price</li>
<li><code>m15_bband_price_lower</code> : The lower bollinger band on <code>m15</code> closing price</li>
<li><code>m15_bband_rsi_upper</code> : The Upper Bollinger Band on the <code>M15</code> RSI Values</li>
<li><code>m15_bband_rsi_middle</code> : The Middle Bollinger Band on the <code>M15</code> RSI Values</li>
<li><code>m15_bband_rsi_lower</code>: The Lower Bollinger band on the <code>M15</code> RSI Values</li>
<li><code>h1_open</code>:  The opening price of the <code>H1</code> candle</li>
<li><code>h1_high</code>: The High Price of the <code>H1</code> Candle</li>
<li><code>h1_low</code>:  The Low Price of the <code>H1</code> Candle</li>
<li><code>h1_close</code>: The Closing Price of the <code>H1</code> Candle</li>
<li><code>h1_rsi</code> : RSI Values on the <code>H1</code> closing price of period 21</li>
<li><code>h1_bband_price_upper</code>: The Upper Bollinger Band On <code>H1</code> Closing Price</li>
<li><code>h1_bband_price_middle</code>: The Middle Bollinger Band On <code>H1</code> Closing Price</li>
<li><code>h1_bband_price_lower</code>:The Lower Bollinger Band On <code>H1</code> Closing Price</li>
<li><code>h1_bband_rsi_upper</code>: The Upper Bollinger Band on the <code>H1</code> RSI Value</li>
<li><code>h1_bband_rsi_middle</code>: The Middle Bollinger Band on the <code>H1</code> RSI Value</li>
<li><code>h1_bband_rsi_lower</code>: The Lower Bollinger Band on the <code>H1</code> RSI Value</li>
<li><code>h4_open</code>:  The opening price of the <code>H4</code> candle</li>
<li><code>h4_high</code>: The High Price of the <code>H4</code> Candle</li>
<li><code>h4_low</code>:  The Low Price of the <code>H4</code> Candle</li>
<li><code>h4_close</code>: The Closing Price of the <code>H4</code> Candle</li>
<li><code>h4_rsi</code> : RSI Values on the <code>H4</code> closing price of period 21</li>
<li><code>h4_bband_price_upper</code>: The Upper Bollinger Band On <code>H4</code> Closing Price</li>
<li><code>h4_bband_price_middle</code>: The Middle Bollinger Band On <code>H4</code> Closing Price</li>
<li><code>h4_bband_price_lower</code>:The Lower Bollinger Band On <code>H4</code> Closing Price</li>
<li><code>h4_bband_rsi_upper</code>: The Upper Bollinger Band on the <code>H4</code> RSI Value</li>
<li><code>h4_bband_rsi_middle</code>: The Middle Bollinger Band on the <code>H4</code> RSI Value</li>
<li><code>h4_bband_rsi_lower</code>: The Lower Bollinger Band on the <code>H4</code> RSI Value</li>
</ol>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class="language-python">print(mtf_df.info())

&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
DatetimeIndex: 105188 entries, 2019-08-27 00:00:00+00:00 to 2022-08-26 16:45:00+00:00
Freq: 15T
Data columns (total 33 columns):
 #   Column                  Non-Null Count   Dtype  
---  ------                  --------------   -----  
 0   m15_close               105188 non-null  float64
 1   m15_rsi                 105167 non-null  float64
 2   m15_bband_price_upper   105184 non-null  float64
 3   m15_bband_price_middle  105184 non-null  float64
 4   m15_bband_price_lower   105184 non-null  float64
 5   m15_bband_rsi_upper     105163 non-null  float64
 6   m15_bband_rsi_middle    105163 non-null  float64
 7   m15_bband_rsi_lower     105163 non-null  float64
 8   h1_open                 105188 non-null  float64
 9   h1_high                 105185 non-null  float64
 10  h1_low                  105185 non-null  float64
 11  h1_close                105185 non-null  float64
 12  h1_rsi                  105101 non-null  float64
 13  h1_bband_price_upper    105169 non-null  float64
 14  h1_bband_price_middle   105169 non-null  float64
 15  h1_bband_price_lower    105169 non-null  float64
 16  h1_bband_rsi_upper      105085 non-null  float64
 17  h1_bband_rsi_middle     105085 non-null  float64
 18  h1_bband_rsi_lower      105085 non-null  float64
 19  h4_open                 105188 non-null  float64
 20  h4_high                 105173 non-null  float64
 21  h4_low                  105173 non-null  float64
 22  h4_close                105173 non-null  float64
 23  h4_rsi                  104837 non-null  float64
 24  h4_bband_price_upper    105109 non-null  float64
 25  h4_bband_price_middle   105109 non-null  float64
 26  h4_bband_price_lower    105109 non-null  float64
 27  h4_bband_rsi_upper      104773 non-null  float64
 28  h4_bband_rsi_middle     104773 non-null  float64
...
 32  signal                  105188 non-null  int64  
dtypes: bool(2), float64(30), int64(1)
memory usage: 29.9 MB
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="summary">Summary</h2>
<p>In general, the resampling and alignment steps for creating a multi-time frame (MTF) dataframe can be summarized in the below diagram.</p>
<ol>
<li>We start with the highest granularity of OHLCV data possible (1m) and then downsample the data to higher timeframes (5m, 15m, 1h, 4h etc.)</li>
<li>We then create the indicators on the multiple time frames required but at this juncture we don&apos;t forward fill the price data. After the indicator is created we can <code>ffill()</code> the resulting series if we are going with the manual method of indicator creation.</li>
<li>In order to create the composite, merged MTF dataframe we employ <code>resample_opening()</code> on the open price or <code>resample_closing()</code> on every other time series, with the appropriate <code>vbt.Resampler()</code> objects, so that all the time-series are aligned to the base-line frequency time series.</li>
</ol>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2022/12/Resampling-and-Alignment---FlowChart-_4LightBG.svg" class="kg-image" alt="VectorBT Pro - Aligning MTF time series Data with Resampling" loading="lazy"><figcaption>Steps for MultiTimeFrame DataFrame creation</figcaption></figure><div class="kg-card kg-button-card kg-align-center"><a href="https://github.com/QubitQuants/vectorbt_pro_tutorials/blob/c679b6edf5bfecdbea1107daeb0ca86ed6f14377/Comprehensive_VectorBT_Basics_Final.ipynb" class="kg-btn kg-btn-accent">See Project Code</a></div>]]></content:encoded></item><item><title><![CDATA[VectorBT Pro - Tutorial Series]]></title><description><![CDATA[<p>This article is an introduction to a series of tutorials on <a href="https://vectorbt.pro/">VectorBT Pro</a> and will serve as a <em>Table of Contents</em> to the entire series of our VectorBT tutorials and will be regularly updated whenever a new blog post is published in our VectorBT tutorial series. To run the code</p>]]></description><link>http://localhost:2368/vbt-tuts-toc/</link><guid isPermaLink="false">643c151fe770773c74f2e5fb</guid><category><![CDATA[vectorBT]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Mon, 14 Nov 2022 07:00:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2022/12/VBTlogo-1.svg" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2022/12/VBTlogo-1.svg" alt="VectorBT Pro - Tutorial Series"><p>This article is an introduction to a series of tutorials on <a href="https://vectorbt.pro/">VectorBT Pro</a> and will serve as a <em>Table of Contents</em> to the entire series of our VectorBT tutorials and will be regularly updated whenever a new blog post is published in our VectorBT tutorial series. To run the code in these tutorials, you would need to buy access to vectorBT pro from <strong>Oleg Polakow</strong> and <code>import vectorbtpro as vbt</code> in your code.</p><!--kg-card-begin: html--><h1 style="text-align: center;">TABLE OF CONTENTS</h1><!--kg-card-end: html--><!--kg-card-begin: markdown--><h2 id="1-comprehensive-basics">1. Comprehensive Basics</h2>
<!--kg-card-end: markdown--><p> The tutorials in this chapter will use a toy strategy called the <code><a href="https://abouttrading.substack.com/p/the-double-bollinger-trading-strategy">Double Bollinger Band Strategy</a></code> to illustrate the vectorBT concepts </p><ul><li><strong><a href="https://qubitquants.github.io/aligning-mtf-data/index.html">Aligning Multi-Time Frame time series Data with Resampling</a></strong><br>Learn about the creation of multi-time frame (MTF) time-series data and their alignment using <code>resampling</code> methods. </li><li><strong><a href="https://qubitquants.github.io/strategydev/index.html">Strategy Development &amp; Signal Generation using</a></strong> <code>vbt.portfolio.from_signals()</code> <br>Learn how to create signals based on multiple confluences / criterion and exploration of backtesting (simulation) results with a variety of methods and plots from <code>vbt.portfolio</code> module.</li><li><strong><a href="https://qubitquants.github.io/vbt_plot_strategy/index.html">Plotting Indicators and Visualising Strategy with Cleaned Signals</a></strong><br>Learn basic plotting techniques available in VectorBT Pro and also advanced techniques like creating your own <code>plot_strategy()</code> function with all the major functionalities one would typically need.</li><li><strong><a href="https://qubitquants.github.io/multi_asset_portfolio_simulation/index.html">Multi Asset Portfolio Simulation</a></strong><br>Learn about various types of portfolio simulations for multiple assets, that is possible in VectorBT Pro . <br><strong>Bonus</strong>: <a href="https://qubitquants.github.io/multi_asset_data_acquisition/index.html">Multi Asset Data Acquisition</a> of multiple Forex pairs with <code>Dukascopy</code></li><li><strong><a href="https://qubitquants.github.io/customsim_0/index.html">Custom Simulator 0: Fundamental Functions</a></strong><br>In this tutorial , you will learn about creating basic functions that will then in turn be used as part of a running a BackTest of a strategy using a custom simulator.</li><li><strong><u><a href="https://qubitquants.github.io/customsim_1/index.html">Custom Simulator 1: Candlestick Strategy Basics</a></u></strong><br>In this tutorial you will implement the fundamental functions on a simple candlestick strategy.</li><li><strong><u><a href="https://qubitquants.github.io/customsim_2/index.html">Custom Simulator 2: Candlestick Strategy + StopLoss +TakeProfit</a></u></strong><br>In this tutorial we develop on the previous post implementing a StopLoss and TakeProfit to our simple candlestick strategy.</li><li><strong><a href="https://qubitquants.github.io/customsim_3/index.html">Custom Simulator 3: Candlestick Strategy,SL,TP and Partial Profits</a></strong><br>In this tutorial we add to our strategy the idea of taking partial profits and moving the stop loss to break even after a certain predefined risk to reward ratio has been met.</li></ul><hr><!--kg-card-begin: markdown--><h2 id="2-advanced">2. Advanced</h2>
<!--kg-card-end: markdown--><ul><li><strong><a href="https://qubitquants.github.io/vbt_dashboard/index.html">Create Customized dashboard for Simulation and Strategy </a></strong><br>Create your own customized dashboard using <code>dash</code> (from <code>plotly</code>) to visualize the vectorBT portfolio simulation and strategy development with entries and exits.</li><li><strong><a href="https://qubitquants.github.io/parameter-optimization/index.html">Parameter Optimization</a></strong><br>Learn how to run a parameter optimization process on a strategy with multiple parameter combinations and also do cross validation of the parameter optimization across multiple train &amp; test splits of the market data.</li><li><strong><a href="https://qubitquants.github.io/discretionary-signals-bactesting/index.html">Discretionary Signals Backtesting</a></strong><br>Learn how to run a backtest simulation on extracted discretionary signals, by creating your own custom simulator and order management function.</li></ul><p><strong>Want to Contribute?</strong><br>If you would like to contribute any articles to this blog reach out to us on <a href="https://www.linkedin.com/groups/14112759/">Linkedin</a><br>Have suggestions for tutorial topics, leave them in the comments below!</p><p>Many thanks to <a href="https://github.com/polakowo">Oleg Polakow</a>, for his continuing support to VectorBT Pro</p>]]></content:encoded></item><item><title><![CDATA[MT5PyBot  - Account Monitor & Data Visualisation Dashboard]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>In this presentation we will see the details of the <code>Account Monitor</code> and the required infrastructure for the same. Thereafter we will also see the visualization of the trading strategy&#x2019;s performance metrics in a data visualization dashboard and finally a demo of the dashboard.</p>
<p><strong>MongoDB ChangeStreams and WebSockets</strong></p>]]></description><link>http://localhost:2368/plotly-dashboard/</link><guid isPermaLink="false">643c151fe770773c74f2e5fe</guid><category><![CDATA[python]]></category><category><![CDATA[plotly]]></category><category><![CDATA[plotly-dash]]></category><category><![CDATA[mongoDB]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Mon, 05 Sep 2022 09:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1592495989226-03f88104f8cc?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDV8fGdyYXBofGVufDB8fHx8MTY3MDE3MjIyMg&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1592495989226-03f88104f8cc?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDV8fGdyYXBofGVufDB8fHx8MTY3MDE3MjIyMg&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="MT5PyBot &#x1F916; - Account Monitor &amp; Data Visualisation Dashboard"><p>In this presentation we will see the details of the <code>Account Monitor</code> and the required infrastructure for the same. Thereafter we will also see the visualization of the trading strategy&#x2019;s performance metrics in a data visualization dashboard and finally a demo of the dashboard.</p>
<p><strong>MongoDB ChangeStreams and WebSockets</strong> - <a href="https://community.plotly.com/t/mongodb-websocket-and-dash-plot/64808">https://community.plotly.com/t/mongodb-websocket-and-dash-plot/64808</a></p>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/qYkeeI56dew?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen title="Account Monitor and Data Visualization Dashboard"></iframe></figure><!--kg-card-begin: html--><iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTKjq1PEwo5KRhtk8SDtVXR9Cnli4j8s9omoUt5W1t6mNsLr9Jn15YEeLR3CNc30YX91OhLKDeHE6Kl/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder="0" width="1920" height="540" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[MT5PyBot - Strategy and AlgoBot in Action]]></title><description><![CDATA[<p>In this presentation we will see a description of the Double Bollinger Band Strategy and a code walkthrough of the strategy module. In the second half we will also see the Algorithmic Trading Bot in action on an AWS Windows EC2 instance trading the Double Bollinger Band Strategy.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/vAH8sOWM5eI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen title="Strategy and AlgoBot in Action"></iframe></figure><!--kg-card-begin: html--><iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTA8Bjc2JZT6SB5WSUyM8Hs15pDFY1Ev6Kb6Dy9MXNnC7QDGFGnoQPHwR8OLa1HfEKG8UPPdUA8Zx6j/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder="0" width="1920" height="510" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><!--kg-card-end: html-->]]></description><link>http://localhost:2368/strategy_algobot_action/</link><guid isPermaLink="false">643c151fe770773c74f2e5fd</guid><category><![CDATA[algorithmic trading]]></category><category><![CDATA[metatrader5]]></category><category><![CDATA[python]]></category><category><![CDATA[aws]]></category><category><![CDATA[ec2]]></category><dc:creator><![CDATA[Dilip Rajkumar]]></dc:creator><pubDate>Wed, 31 Aug 2022 14:14:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2022/12/runningbot.png" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2022/12/runningbot.png" alt="MT5PyBot &#x1F916;- Strategy and AlgoBot in Action"><p>In this presentation we will see a description of the Double Bollinger Band Strategy and a code walkthrough of the strategy module. In the second half we will also see the Algorithmic Trading Bot in action on an AWS Windows EC2 instance trading the Double Bollinger Band Strategy.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/vAH8sOWM5eI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen title="Strategy and AlgoBot in Action"></iframe></figure><!--kg-card-begin: html--><iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTA8Bjc2JZT6SB5WSUyM8Hs15pDFY1Ev6Kb6Dy9MXNnC7QDGFGnoQPHwR8OLa1HfEKG8UPPdUA8Zx6j/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder="0" width="1920" height="510" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><!--kg-card-end: html-->]]></content:encoded></item></channel></rss>